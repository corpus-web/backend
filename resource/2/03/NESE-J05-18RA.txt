<title>Data trustworthiness signatures for nuclear reactor dynamics simulation</title>
<author>1,YeniLi,2,Hany S.Abdel-Khalik</author>
<Affiliation>1,School of Nuclear Engineering, Purdue University, 205 Gates Road, FLEX Lab, West Lafayette, 47906, USA</Affiliation>
<year>2021</year>
<Jounral>Progress in Nuclear Energy</Journal>
<Publishing_house>ELSEVIER</Publishing_house>
<Text_Collector>XiaFan，HEU</Text_Collector>
<DOI>doi.org/10.1016/j.pnucene.2020.103612</DOI>
<URL>https://www.sciencedirect.com/science/article/pii/S0149197020303577</URL>
Data trustworthiness signatures for nuclear reactor dynamics simulation
YeniLi,Hany S.Abdel-Khalik
School of Nuclear Engineering, Purdue University, 205 Gates Road, FLEX Lab, West Lafayette, 47906, USA
<Section>Highlights</Section>
Signature-based classifier is effective for the detection of stealthy FDI attacks.
Use both of dominant degrees of freedom (DOFs) and less dominant DOFs to construct signatures.
Randomized window placements on the temporal profile to identify the dominant degrees of freedom.
<Section>Abstract</Section>
With the increased reliance on digitization in industrial control systems, the need for effective monitoring techniques has risen dramatically. Specifically, there is now a growing concern about the so-called false data injection (FDI) attacks. These attacks aim to alter the raw sensors’ data to cause malicious outcomes. Any serious FDI algorithm is based on an intimate knowledge of the system and its associated physics models, which renders conventional outlier/anomaly detection techniques almost obsolete in the face of such attacks. Thus, a critical need has emerged to develop a new class of defense methods that are capable of detecting FDI attacks under the assumption that the attacker has a strong familiarity with the system and its physics modeling. This class of defense methods are denoted by model-based defenses which are premised on the assumption that the attacker, while having a good understanding of the system, does not have full privileged access to all proprietary data and historical records of operation. However, (s)he is assumed to be capable of learning system behavior using self-learning techniques during an initial lie-in-wait period. To defend against this scenario, we propose a new model-based randomized window algorithm that searches time-series data for signatures that can serve as classifiers between normal and FDI scenarios. The classifiers are based on the correlations between the dominant degrees of freedom (DOFs) and the less-dominant DOFs (expected to be very sensitive to the system details that are unknown to the attacker). For demonstration, RELAP5 models are employed to calculate representative nuclear reactor behavior during a number of transient scenarios. Falsified data are injected into the RELAP5-simulated behavior, and the proposed signature-identification algorithm is employed to detect the injected data.
Index Terms:Model-based defense;False data injection;Signature
<Section>1. Introduction</Section>
The adoption of digital technologies to support the operation and maintenance of industrial control systems, like nuclear reactors, is expected to have a wide range of benefits for optimum control, improved operational flexibility, predictive maintenance, and better inference of uncertainties, etc. Along with the benefits comes the risk of digital intrusion perpetrated by adversaries aiming to exploit any vulnerabilities to inflict damage on the system, ranging from temporary denial of service to irreparable system damage. To combat this threat, Information Technology (IT) defenses have been early adopted, e.g., perimeter defense like firewalls, passwords, routers, etc., and more modern methods like decoy network, network traffic analysis, etc. Given the frequency and sophistication of recent attacks, e.g., the 2010 Stuxnet against Iran, the 2015 Electric Grid attack against Ukraine, etc., a new type of defense, denoted by Operational Technology (OT) defense has been introduced as a new line of defense when IT defenses are bypassed (NIST, 2015).
OT defenses aim to protect the system at the physical process level by developing a level of awareness of the system's process variables' normal behavioral patterns. The idea is that if an attacker injects falsified data into the network, e.g., by falsifying the sensors' data or actuator commands, the OT defenses would detect the falsification and provide early alarms to the operators. The detection process requires a metric by which normal vs. falsified behavior could be distinguished. Many approaches have been proposed to design such metrics, often referred to as signatures. The signatures serve as fingerprints for the system, including its physics, and history of operation, where no two systems are identically the same, even if their initial design is the same. These signatures are designed to ensure consistency of the process variables used to describe/monitor the physical process.
A key challenge of signature-based methods is the ability to distinguish between normal and malicious behavior under various assumptions of the attacker's familiarity with the system. For example, when the attacker has little or no familiarity with the system, outlier/anomaly detection techniques present the most straightforward approach to detecting FDI attacks (Fawzy and Mokhtar, 2013) (Costa et al., 2015). In this scenario, each process variable has a prescribed range for variation, e.g., steam generator level, with deviations thereof -- as measured by one or two standard deviations -- signaling an abnormal behavior. This approach has the advantage of being simple to implement, however it does not provide enough information on the cause of the deviations.
Next, if the attacker has a basic understanding of the system behavior, outlier/anomaly techniques may not be effective because the attackers might know the preset values that trigger the outlier detection algorithm. In this scenario, another class of methods may be more effective, the so-called data-driven techniques, which rely on building predictive models for the system behavior (Smarra et al., 2018) (Li et al., 2020). Data-driven modeling implies that the physics models are not incorporated to guide the training of the models. Instead, auto-correlation-type regression techniques, and their more sophisticated neural-network implementations are employed to predict the present behavior as a function of past behavior (Pan and Duraisamy, 2018). When the predictions made by these models become inconsistent with observed behavior, an alarm is issued. Just like outlier/anomaly detection techniques, data-driven techniques are simple to implement.
Moreover, data-driven approaches need vast amounts of data, especially for complicated industrial systems, to ensure an accurate emulation of system behavior. Also, they can be customized with reasonable accuracy to recognize different equipment failure modes (Trunzeret al., 2018). This simplicity however also means that the learning process can be duplicated by an attacker during an initial lie-in-wait period. This follows because the mathematical machinery for data-driven techniques is well-understood and does not rely on any obscurity measures. Once learned, the attacker can proceed to making changes to the system state that respects the consistency between present and past behavior (Papernot et al. Goodfellow). One key disadvantage of pure data-driven learning is that it does not incorporate the physics in the learning process, which implies that if the raw sensors data are routinely falsified, one cannot rely on such methods to detect sophisticated FDI attacks.
The next logical OT defense is expected to rely on the formal physics description for the system in order to decide what normal behavior looks like. This OT defense is denoted as model-based, since it relies on a physics model to establish a basis for normal behavior. This type of defense is expected to be more resilient to an attacker who has a general understanding of system behavior but may not be able to exactly replicate it, because they do not have access to key proprietary data and historical operational details. This attack scenario is not farfetched, since almost all kinds of simulators for different types of nuclear reactors can be found via open access, such as Ph.D thesis, published reports and research papers, which provide the attacker with sufficient resources to obtain an approximate physics model. To address this type of attack scenario, the model-based approach derives its strength from the operational uniqueness and complex interactions between system components. Previous studies provide proof that pure data-driven learning is not generally capable of accurately learning system behavior, especially for complex systems like nuclear reactors (Li et al., 2018).
The next attack scenario, expected to be launched by state-sponsored organizations, the attacker will likely have access to high fidelity simulators for system behavior. For these attacks, the question becomes: will an OT model-based defense be able to detect signs of FDI attacks when the attackers can predict system behavior to a reasonable accuracy. This represents the focus of this manuscript which proposes the use of a model-based approach that analyzes system behavior for a wide range of conditions in search of signatures that are extremely difficult to be duplicated by an attacker. These signatures are based on the higher-order differences between the defender's model and that of the attacker, which can be gleaned via data mining techniques. These higher order effects are typically discarded by most data-driven techniques, and are attributed to sources of uncertainties that cannot be explained by the models. Coupling these higher order effects with the dominant behavior can be shown to establish signatures that are difficult to duplicate by the attacker. This is true whether basic or advanced learning methods are being employed such as generative adversarial networks (GANs) (Goodfellow et al., Warde-farley). This follows because GANs' generative model require a template of models that represent the basis for training their adversarial network. Without access to the definition of the higher order effects, expected to have extremely high dimensionality, it remains very difficult for the network to learn the higher order effects (Bau et al., 2020), and more critically, their relation to the lower order effects, as will be shown later in the discussion. Clearly, if the attacker has the same model employed by the OT defense, and knows the exact definition of the signatures, this defense can also be bypassed using simple as well as complex learning methods such as GAN. This extreme scenario is not considered here, and is discussed in another article (Sundaram et al. Ashy), under the context of active OT defense. The current manuscript focuses on a passive OT defense, where the passivity implies that the defense does not introduce any changes to the system. It only monitors the measured process variables and compares them to predicted values in search of signatures, as described earlier.
The rest of this paper is organized as follows. First, we provide a background on the current research on the OT defense and related data-driven techniques. Second, a mathematical development of the proposed randomized window decomposition (RWD) technique is elucidated. Third, the application of the RWD technique is exemplified using numerical simulations with the RELAP5 to demonstrate its ability to classify normal behavior from FDI attacks.
<Section>2. Background</Section>
The literature has significantly increased over the past decade to rise to the challenge of FDI attacks. Researchers have explored multiple venues to develop better understanding of FDI attacks. Some researchers have focused on demonstrating how the attacks can be launched. For example, Liu, et al. show that attackers are capable of constructing attacks that do not trigger outlier/anomaly detection techniques, referred to as stealthy FDI (Liu et al., 2011). R. Smith employs linear and nonlinear physics models to illustrate detectability of stealthy FDI attacks with respect to operating point changes, and confirms that when the attackers have more sophisticated resources, the probability of keeping attacks undetected will correspondingly increase (Smith, 2015). Sandberg et al. employ convex optimization tools to evaluate attacks, by taking deviations from the true model and attack goals to quantify the least efforts needed to achieve this type of attack, i.e., the minimum number of needed compromised sensors in a certain system (Sandberg and Johansson). Other researchers have focused on developing requirements to establish effective defense strategies. As few examples, Dan, et al. propose two data-driven algorithms to study the costs of specific attacks and the cost for implementing defenses (Dan and Sandberg, 2010). These two algorithms aim to find an optimum place for secure devices in order to maximize their effect in terms of security. Giani et al. introduce and characterize sparse cyberattacks to identify the minimum number of needed known-secure sensors to disable FDI attacks (Giani et al., 2011). This goal is accomplished by a countermeasure strategy based on state-estimation. Kim et al. suggest a subset selection algorithm to identify the key measurements to be protected when the defenders have limited resources, based on constructing attacking vectors developed for linearized measurement models (Kim and Poor, 2011). Eggers provides a data-based intrusion detection model and employs the historical plant data to quantitatively define the onset of an FDI attack vector consisted of a recurring pattern or a flatline with noise. This detection approach is constructed by a comparison study of moving-window and static-window based PCA and ICA (Shannon, 2018). Other researchers have focused on measuring the consequences of different compromised components, e.g., O. Vukovic et al. study several common attack vectors; investigate how a single compromised control center can affect state estimation by tracking the evolution of the number of outliers state estimations (Vuković and Dán, 2013). Meanwhile, some studies focus on signature development based on data-driven/physics-based defenses. Hadžiosmanovi'c et al. perform a data characterization phase approach based on the data behavior: continuously change, state reflection, or constant. These different groups of data are used to fit an autoregressive model, which aims to estimate the behaviors of a correlated system state (Hadžiosmanovi et al. Hartel). Urbina et al. propose a physics-based attack model together with its derived intrusion detection metric. This metric combines different detection schemes to measure and mitigate the impact of the proposed attack (Urbinaet al., 2016). Related works can be found in (Wang et al., 2014) (McLaughlin, 2013) (Yao, 2017).
The proposed algorithm for establishing model-based OT defenses is based on a novel idea to build signatures. The idea is that any learning algorithm, whether parametric or non-parametric, supervised or unsupervised, attempts to identify dominant behavior. For example, in reduced order modeling (ROM) relying on the use of singular value decomposition (SVD), an unsupervised learning approach, the dimensionality of the data is reduced by identifying the most dominant components. The criterion employed to select the number of dominant components is that the reconstructed data are close enough to the original data, with the closeness measured in terms of an error metric, e.g., Euclidean norm, whose magnitude is taken to be of the same order as the acceptable level of error in the process that generated the data. For example, if the data are generated using a physics model where the modeling uncertainties or the inherent noise sources are expected to be in the order of 0.1%, an acceptable criterion for the error metric magnitude would be in the order of 0.1% or less.
Unlike these popular techniques relying on dominant behavior, the proposed approach employs the higher order components (HOCs) which are typically discarded by standard learning techniques. The dominant components will be referred to as the low-order components (LOCs). In the statistical learning and data mining communities, the LOCs are typically referred to as dominant or influential degrees of freedom or principal components, e.g., the first few components in a principal component analysis or a discrete Fourier transform. In our approach, both the HOCs and LOCs are employed to build signature-based classifiers for normal and malicious behavior. This is essential, because the defender must look for signatures that are difficult to duplicate by the attacker.
The HOCs achieve that purpose because, unlike the LOCs, which can be captured using approximate models, they are expected to be sensitive to all specific details about system behavior, which are assumed unknown to the attacker. By way of an example, consider an event that results in an increase in the core flow rate, simulated using both an approximate model (that is available to the attacker) and a high fidelity model (owned by the defender). If one expands the resulting power distribution variations using a modal analysis, one would expect the first few modes to closely agree as predicted by both models, because essentially both models attempt to capture the dominant reactor behavior. The higher order modes however, representing the HOCs, will be discrepant due to the inherent differences between the two models, which are not all known to the attacker. Interestingly, these differences are not only sensitive to the “proprietary” design details but also to the modeling errors resulting from all modeling assumptions and numerical approximations inherent in the defender's model.
Both the LOCs and HOCs can be readily captured using ROM techniques. To put this in perspective, Fig. 1 shows the components of three typical sensors variations as projected onto the components identified by a typical ROM technique. The x-axis is an index for the respective components, and y may be thought of as a linear transformation of the variations over both space and time. The small components in the yellow box are discarded by ROM as very small (i.e., assumed below error criterion). The most dominant components in the blue box, i.e., LOCs, are the components expected to be known to the attacker, as they can be captured by approximate models. This leaves the intermediate components to serve as defense classifiers. Also, it is important to note that the space of HOCs for most reactor models is expected to be much larger than the space of LOCs. This has been repeatedly shown by earlier research, where the LOCs are several orders of magnitude smaller in number than the nominal dimensionality of the data (Bang et al., 2011).
Fig. 1. ROM components availability illustration.
In support of searching for signature-based classifiers, the application of ROM is essential to reduce the number of LOCs and HOCs employed to build classifiers. This follows because the majority of classification techniques suffer from the curse of dimensionality (Verleysen and François, 2005), that is an exponential increase in computational demands with the dimensions of the training data used to calculate the classifiers. This means that the defender must limit the number of HOCs terms employed in the construction of signatures. While a limitation at a first glance, this provides great strength for the proposed active OT defense, because now the attacker has to guess which of the vast number of HOCs have been used by the defender to design signatures. This is nearly an impossible task given the huge size of the HOCs space as discussed earlier.
To capture the LOCs and HOCs components, we rely on a new algorithm, randomized window decomposition (RWM), which is inspired by the DMD algorithm (Proctor et al., 2014) discussed below. The synthesis of signatures using the identified LOCs and HOCs is achieved using support vector machines (SVM). Each of these enabling algorithms is discussed next. The following section discussed the overall implementation of the RWD algorithm and associated signature-based classifier construction.
2.1. Dynamic mode decomposition (DMD)
Dynamic mode decomposition is a popular method intended initially to construct an analytic emulator (i.e., surrogate model) to be used in lieu of a dynamical system model (Proctor et al., 2014). For physics models exhibiting no feedback, one can show that an DMD-based emulator's predictions are exact. The implementation is seamlessly achieved by taking a time series generated by the physics model and turning it into a matrix by running a window of fixed size over the data, with the window size equal to the number of columns of the resulting matrix. Every row corresponds to a shift of the window over the time series by a fixed time step, typically taken to be a single time step. If the time signals have n time steps, and the window size is k wide, the resulting matrix, X would be k×(n-k+1), where (n-k+1) is taken as the collected dynamic modes along with the temporal data. If we take the first (n-k) columns to construct a new matrix X1, and the last (n-k) columns to obtain another matrix X2, which is the time-shifted snapshot matrix of X1, then the dynamic behavior can be modeled via a constant matrix A as given by Eq. (1)
(1)
Then apply truncated singular value decomposition on operator A, and get three matrices,  and . Then construct the reduced-order operator  in Eq. (2):
(2)
The eigen-decomposition of  in Eq. (3) yields eigenvalue and eigenvectors, which can be investigated to understand the fundamental characteristics of the underlying system, like unstable growth mode, etc.
(3)
The dynamic mode, Φ, is calculated by Eq. (4)
(4)
The basic assumption here is that the matrix A, representing the mathematical operator for the time evolution, is constant in time. For most practical problems, e.g., reactor analysis, the physics feedback forces the operator A to be a function of the time evolution of the solution. Several strategies to address this have been proposed (Kutz, 2019), but are outside the scope of this project.
The proposed RWD algorithm constructs a single matrix X by placing the window at random points over the temporal scale and over all the snapshots of the solution obtained from repeated randomized execution. No assumptions about the size of the time step are made as typically required by DMD. The total number of rows of the matrix are much smaller than the number of time steps and the number of executions. Our goal here is not to compare against DMD algorithm, since the objective is not to construct a surrogate model. Instead, the goal to efficiently identify a number of LOCs ad HOCs that can be used for signature-based classification of behavior.
2.2. Support vector machine (SVM)
Support vector machines (SVM) (Cortes and Vapnik, 1995) (SMOLA and SCHOLKOPF, 2004) are a class of machine learning techniques employed in our work to help construct classifiers to identify FDI attacks under both normal and abnormal conditions. SVM relies on a kernel to transform the data into higher dimensional space, where linear methods for classification become applicable. A radial basis function is employed in this work as the SVM's kernel. The RBF kernel is expressed by Eq. (5) (Vert et al., 2004), where N is the size of training data, γ is a parameter which decides how curvy the classifier's decision boundary could be, and C is a penalty weight. Therefore, when γ is very large, the boundary could be so curvy that the outliers could be classified as labeled but isolated from the correct cluster, and that is when overfitting occurs. When C is large, the penalty term is heavily weighted to avoid misclassification of data and leads to overfitting as well (Cortes and Vapnik, 1995). A comparison study is usually employed to find proper values for γ and C for not losing the generalization properties of the SMV when testing new data.
(5)
2.3. Randomized window decomposition (RWD)
The idea of RWD is to randomize the placement of the window over all the snapshots of the response's temporal behavior as opposed to a sequential movement of the window over a single time series as performed by DMD. Different size windows and different time step sizes can be employed. The longest window corresponds to the length of the time series, which reduces to conventional SVD decomposition, where the entire time series represents a single snapshot. Very short time windows are not expected to provide useful information about system behavior, given the small number of degrees of freedom available. Thus, some experimentation is required to identify a proper size window. From a defender viewpoint, this experimentation adds another level of obscurity to the design of the defense algorithm.
The input data processed by the RWD algorithms are snapshots of the time series for the given responses, obtained via multiple executions of the software under a wide range of conditions expected during normal and/or abnormal operation. This can be achieved by rerunning the simulation under different scenarios and randomly perturbing relevant initial and boundary conditions within expected ranges of variations. The ith simulation generates a temporal variation for a given response, denoted by yi, with y0 representing the reference temporal variation. The window size is denoted by w. Collect snapshots for the response of interest over time and aggregate in a matrix Gd of size t × L, where t is the number of time steps for the response of interest, and L is the number of model executions, with each execution generating a different temporal response based on perturbed initial and boundary conditions, i.e., the ith column of Gd is given by yi. Next, standardize the matrix Gd by subtracting and dividing by y0.
Given the attacker's familiarity with the system, we assume that the attacker can approximate the matrix Gd, denoted by Ga, where d and a refer respectively to defender and attacker.
1.
Employing a window of size w, randomly place the window over y0 to generate n0 random snapshots for the window values, and aggregate in a matrix D0 (w × n0). Generalization of this could be achieved by placing the window randomly over all the columns of the matrix Gd.
2.
Apply SVD on D to determine the rank rL (based on a defined tolerance), LOCs, and HOCs, captured in two matrices UL (w×rL), and UH(w×rH). The size of the HOCs matrix rH is arbitrary as those components are typically discarded by SVD as non-influential.
3.
Employing a window of the same size w, generate a matrix Di of size (w×n) corresponding to the ith column of the matrix Gd run, where n can in general be different from n0.
4.
Calculate the projection of each of the n windows from the Di matrix along the rL LOCs and the rH HOCs determined using D0. This generates two matrices of sizes rH × n and rL × n, denoted respectively by,  and .
5.
Repeat the above steps using the attacker matrix Ga to generate matrices  and .
6.
Using a binary SVM classifier, identify signatures to attack scenarios.
<Section>3. Application demonstration</Section>
This section applies the methodology described above to a number of representative scenarios during the operation of a nuclear Pressurized Water Reactor (PWR). The goal is to distinguish between normal behavior and FDI attacks. The system analyzed is a representative PWR model and a RELAP5 simulator is used for estimating system behavior during both steady state and transient scenarios.
3.1. Case study description
Generally speaking, an FDI attack could be introduced to both steady state and transient behavior, with transient behavior being the more likely approach to ensure the FDI signals could be masked as normal operational maneuvering. Hence for this study, we focus on transient behavior which is expected to be normally occurring to the operator. For nuclear reactors, this transient behavior could for example result from normal power maneuvering to meet the electric grid demand. Load-following operation is common for the nuclear industry. For example, both in the US and abroad, e.g., France and Germany, load-follow operational strategies have been adopted to increase the penetration of nuclear power to the overall energy demand (Lokhov, 2011) (Nuclear Engineering Agenc, 2011). A technically-savvy attacker will take advantage of this power maneuver to first learn system behavior and also to hide their FDI signals within the range of variations that is considered acceptable by the operators.
Regarding the specific reactor model used for demonstration, a RELAP5 model for a representative PWR reactor is used. It consists of a primary loop and a secondary loop producing a 50 MW as its peak power. The simulation time is set to 200 s when the system reaches a steady-state following an upset condition. All physics responses are output by RELAP5 every second. The nodalization of this model is shown in Fig. 2 (Peterson and Paulsen, 1995). Each number represents a given component of the system, where a component may designate an actual physical component, e.g., steam generator, pipe, etc., or a section thereof as dictated by the numerical scheme. To simulate possible response variations, either due to modeling or operational uncertainty, ten parameters associated with different components are selected for perturbations as shown in Table 1.
Fig. 2. Nodalization of RELAP5 model (source, ref (Peterson and Paulsen, 1995)).
Table 1. Perturbed parameter and range.
In general, the attacker is expected to insert changes to the time evolution at multiple points to achieve their goal of manipulating system state. However, for the sake of developing insight and assessing the efficacy of the proposed algorithm, we assume the attacker changes the trend within a single time window only, which represents a more challenging scenario for the OT defense, since the attack vector has subtle variation to the original measurements.
To simulate the attack, it is assumed that the attacker has access to a physics model that can approximate the behavior of the system to a reasonable accuracy. As mentioned earlier, this means both the attacker and the defender can approximate the same LOCs. To reproduce this scenario here, the RELAP5 is used as a basis for generating the time evolution of the various responses as would be done by the defender, collected in the matrix Gd. To simulate an attack that captures the LOCs, the time evolution within selected windows, randomly placed over the time horizon for the simulation, is converted to simple linear variations as shown in Fig. 5. The right graph shows a representative time evolution for a given response. It is hypothesized that the attack is inserted between the two vertical dashed red lines, where the trend is changed to be linear, which preserves the dominant behavior. Thus, each of the columns of the Ga matrix is assumed to contain a single attack placed randomly throughout the time horizon for the simulation.
As mentioned above, if one applies a modal analysis on the data simulated by the defender and the falsified data by the attacker, the first few modes, representing the LOCs, would show a high degree of agreement. Fig. 3 shows the relationship of LOCs from both models, where π1 and π2 represent first two components of the LOCs set. As mentioned earlier, this is not surprising when confronting an attacker with intimate knowledge of system behavior. This also raises concerns over pure data-driven techniques which rely solely on capturing dominant system behavior as a measure for data trustworthiness. On the contrary, the HOCs, shown in Fig. 4, will be discrepant because of the inherent differences between the defender and attacker models.
Fig. 3. LOCs produce by defender and attacker.
Fig. 4. HOCs produced by defender and attacker.
Fig. 5. Overall calculational scheme for proposed OT defense.
Next, regarding the choice of the LOCs and HOCs, one can include all LOCs components and an arbitrary number of HOCs to develop the SVM classifier. For this initial study, we focus on employing a single component from each set to help develop insight into the mechanics of the proposed OT defense. Thus, it is assumed that rL = 1 and rH = 1, representing a single LOC and a single HOC component. In this case, the matrices  and  reduce to two vectors, of length n, where n is the number of time windows placed over the time horizon of the simulation. The overall calculational process is shown in Fig. 5.
3.2. Numerical results
In this study, the proposed RWD algorithm is applied to distinguish between a normal operational scenario (denoted by “True” in the figures’ legends) and one manipulated by an FDI attack (denoted by “ATK”). The calculational scheme in Fig. 5 identifies two sets of components, the HOCs and LOCs, from which user-selected components are employed as training data for the SVM classifier. The symbol pi is used to identify the index of the selected components in each set. For example, the π5 HOC refers to the fifth component in the identified HOCs set. As mentioned earlier, the space of HOCs is expected to be much bigger than the space of LOCs, hence two different numerical experiments are developed to assess the impact of using different components from the set of HOCs components. Finally, the application of the RWD algorithm is currently being limited to a single response only, i.e., both the identified LOCs and HOCs do not take into account the correlations across difference responses, which will be explored in future work.
In the first numerical experiment, the π1 HOC is selected for classifier training. Fig. 6 shows a scatterplot of the selected HOC and LOC for the normal behavior and the FDI-manipulated behavior for the steam generation rate (“Sgen”) using a time window of 70 s (“wd = 70”). The blue dots (“True”) mark the normal behavior, and the red crosses (“Attack”) the FDI-manipulated behavior. The left subplot shows the evolution of the LOCs and HOCs over the time of the simulation. The right subplot condenses the time-evolution of the LOCs and HOCs components using a simple Euclidean norm.
Fig. 6. Feature of Steam Generation with Observation Window size = 70 (seconds).
These basic results demonstrate the potential of differentiating between normal and FDI scenarios, made possible via the use of HOCs in tandem with LOCs. One can envision many ways to apply the SVM classifiers on these training data. While the dimension of training datasets is dependent on the time window length, the high dimensional training data may defect the generality of classification and burden the training process. For illustration, we apply SVM on the Euclidean-condensed HOCs and LOCs as plotted in the right subplot of Fig. 6. The classification results for the steam generation are shown in Fig. 7 and Fig. 8  when the observation window size is 70 seconds, with the blue area representing normal operation and the red area representing the FDI attack, and the x and y axis representing the Euclidean norm of LOC and HOC respectively.
Fig. 7. Classification results for the norm of the feature of steam generation amount.
Fig. 8. Classification results for steam generation amount.
The two figures show results for different values of the SVM's parameters γ and C. Weak sensitivity to these parameters is noted. In Fig. 7, the values for these two parameters, noted on the graph, result in a 79% classification accuracy, meaning that 79% of the analyzed cases can be classified correctly. In Fig. 8, this accuracy of the classification changes slightly to 78%. This weak sensitivity is due to the fact that the HOCs and LOCs have been condensed using Euclidean norm prior to the application of SVM classifier. In general, one would expect different behavior for the classifier depending on the type and the manner in which the data have been preconditioned. An optimization of the classifier results is certainly needed, however these initial results are intended to show that HOCs provide a unique capability to identify FDI attacks when the LOCs can be accurately captured/learned by the attacker.
Next, Fig. 9 shows the change in the classification accuracy as the size of the attack window is changed. As one would intuitively think, the classification accuracy will generally improve as the attack window is increased, e.g. pressure and temperature at the secondary side of the steam generator; however, with some noted exceptions, e.g., average core temperature.
Fig. 9. Relationship between classification accuracy and window size (with low order HOC).
Next, the robustness of the HOCs is assessed with respect to process noise, expected to be inherent in all process parameters. The idea here is to assess whether the classification ability based on the use of HOCs will degrade under the presence of noise, expected to be inherent in all the measurements. Previous results employed the RELAP5 simulation results directly as a basis for the training of the classifier. The next set of results repeat the training of the SVM classifier, but now with all data, including both generated by the defender and the attacker, contaminated by white Gaussian noise. Fig. 10 compares the time evolution of the normal behavior vs. the FDI-manipulated behavior but now with the noise added. Fig. 11 compares the HOCs and LOCs as done before in Fig. 6, but now with the noise insertion. Compared to Figs. 7 and 12 shows a minor change, 1% increase in the classification accuracy, indicating the robustness of the RWD in FDI detection with white Gaussian noise. The robustness results from two reasons: (1) both LOC and HOC employed for classification contains little information of the noise; (2) the window size here is 70 s, 35% of the whole temporal profile, within which the noise takes relatively small effects on the response variation.
Fig. 10. Response comparison with white Gaussian noise.
Fig. 11. Feature of steam generation with white Gaussian noise.
Fig. 12. Classification accuracy with white Gaussian noise.
As mentioned earlier, the space of HOCs is expected to be much bigger than that of the LOCs, which provides an additional obscurity defense for the design of the OT defense. The idea is that the defender has a large palette of HOC components to choose from. To demonstrate this, the previous results are repeated but with a different HOC component. Specifically, the fourth component in the HOC set is used for classification, (i.e., th π4 HOC). Fig. 13 shows in a similar manner to Figs. 6 and 11 the relationship between the HOCs and LOCs for the normal and FDI scenarios.
Fig. 13. Feature of Steam Generation Amount with Observation Window size = 70 (seconds).
The corresponding classification results are shown in Fig. 14 for the same response, i.e., the steam generation amount with a window size of 70 s, with the blue area representing normal operation and the red area for the FDI attack. Fig. 15 shows the change in the classification accuracy as the size of the attack window is changed in a similar manner to the results shown in Fig. 9. For these scenarios, the same values for the SVM parameters γ and C are employed, with notable differences in the classification accuracy. Results indicate notable improvement in the classification accuracy as one employs π4 instead of π1 for the HOC set. The classification accuracy jumps to 95%. This result implies that the classification accuracy is intimately tied to the way the HOCs are employed to train the classifier. In general, one could use a functional form combining the HOCs components to maximize the classification accuracy.
Fig. 14. Classification results for the norm of the feature of steam generation amount.
Fig. 15. Relationship between classification accuracy and window size (with higher order HOC).
<Section>4. Conclusion</Section>
Industrial control systems are currently being upgraded with digital instrumentations for efficient control, operational convenience, and expeditious data traffic. Despite the numerous benefits of digitization, one must address the threats posed by potential adversaries looking for vulnerabilities to exploit. This manuscript presents a new OT defense to identify FDI attacks when the attacker has strong familiarity with the system, and has access to accurate models for dynamic system behavior. The idea is to rely on both dominant, referred to as the LOCs, as well as less dominant features, referred to as the HOCs, to derive signatures that can identify FDI attacks. This manuscript has helped introduce the basic idea and demonstrated its use to detect falsification in a single response using a single LOC and HOC components, and assuming the attack happens once over the time of the simulation. Results indicate the potential use of HOCs to build strong classifiers against FDI attacks which assume strong familiarity with the system. Future work will expand this work to develop LOCs and HOCs components across multiple responses, and will optimize the integration of HOCs components to maximize the classification accuracy.
<Section>Credit author statement</Section>
Yeni Li: Data curation, Formal analysis, Methodology, Investigation, Visualization, Validation, Writing - original draft, Writing - review & editing. Hany S. Abdel-Khalik: Conceptualization, Funding acquisition, Investigation, Methodology, Project administration, Resources, Supervision, Validation, Writing - review & editing.
<Section>Declaration of competing interest</Section>
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
<Section>Acknowledgement</Section>
This work has received support from multiple sources, including initially a Sandia LDRD contract, internal funding from Purdue University School of Nuclear Engineering, and more recently an NEUP grant from DOE. Y. Li, and H. S. Abdel-Khalik are with the School of Nuclear Engineering Purdue University, IN 47906 USA (email: li2181@purdue.edu; abdelkhalik@purdue.edu).
<Section>Appendix A. Supplementary data</Section>
The following is the Supplementary data to this article:
Multimedia component 1.
<Section>Research data for this article</Section>
The data was generated using an export-controlled code - RELAP5
Data not available / Other (please explain)
<Section>References</Section>
Bang et al., 2011
Y. Bang, H.S. Abdel-Khalik, J.M. Hite
Hybrid reduced order modeling applied to nonlinear models
Proc. 2011 Am. Control Conf. (March) (2011), pp. 1885-1891, 10.1002/nme
View Record in ScopusGoogle Scholar
Bau et al., 2020
D. Bau, S. Liu, T. Wang, J.-Y. Zhu, A. Torralba
Rewriting the rules of machine-generated art
In Proceedings Of the European Conference On Computer Vision, ECCV) (2020)
Google Scholar
Cortes and Vapnik, 1995
C. Cortes, V. Vapnik
Support-vector networks
Mach. Learn., 20 (1995), pp. 273-297
CrossRefView Record in ScopusGoogle Scholar
Costa et al., 2015
B.S.J. Costa, P.P. Angelov, L.A. Guedes
Fully unsupervised fault detection and identification based on recursive density estimation and self-evolving cloud-based classifier
Neurocomputing, 150 (2015), pp. 289-303, 10.1016/j.neucom.2014.05.086
ArticleDownload PDFView Record in ScopusGoogle Scholar
Dan and Sandberg, 2010
G. Dan, H. Sandberg
Stealth Attacks and Protection Schemes for State Estimators in Power Systems
(2010), pp. 214-219, 10.1109/SMARTGRID.2010.5622046
CrossRefView Record in ScopusGoogle Scholar
Fawzy and Mokhtar, 2013
A. Fawzy, H.M.O. Mokhtar
“Outliers detection and classification in wireless sensor networks,” Egypt
Informatics J, 14 (2) (2013), pp. 157-164, 10.1016/j.eij.2013.06.001
ArticleDownload PDFView Record in ScopusGoogle Scholar
Giani et al., 2011
A. Giani, E. Bitar, M. Garcia, M. Mcqueen
“Smart grid data integrity Attacks : characterizations and countermeasures π
IEEE Int. Conf. Smart Grid Commun. (2011), pp. 232-237, 10.1109/SmartGridComm.2011.6102324
025478 2011
CrossRefView Record in ScopusGoogle Scholar
Goodfellow et al., Warde-farley
I. J. Goodfellow, J. Pouget-abadie, M. Mirza, B. Xu, and D. Warde-farley, “Generative Adversarial Nets,” pp. 1–9.
Google Scholar
Hadžiosmanovi et al., Hartel
D. Hadžiosmanovi, R. Sommer, and P. H. Hartel, “Through the Eye of the PLC : Semantic Security Monitoring for Industrial Processes.”.
Google Scholar
Kim and Poor, 2011
T.T. Kim, H.V. Poor
Strategic protection against data injection attacks on power grids
IEEE Trans. Smart Grid, 2 (2) (2011), pp. 326-333, 10.1109/TSG.2011.2119336
CrossRefView Record in ScopusGoogle Scholar
Kutz, 2019
J.N. Kutz
Data-Driven Modeling & Scientific Computation
(2019)
Google Scholar
Li et al., 2018
Y. Li, E. Bertino, H. Abdel-Khalik
“Effectiveness of model-based defenses for digitally controlled industrial Systems : nuclear reactor case study
Nucl. Technol., 206 (1) (2018), pp. 82-93
View Record in ScopusGoogle Scholar
Li et al., 2020
Y. Li, H. Abdel-Khalik, A.J. Brunett, E. Jennings, T. Mui, R. Hu
ROM-based surrogate systems modeling of EBR-II
Nucl. Sci. Eng. (2020), 10.1080/00295639.2020.1840238
Google Scholar
Liu et al., 2011
Y. Liu, P. Ning, M.K. Reiter
False data injection attacks against state estimation in electric power grids
ACM Trans. Inf. Syst. Secur., 14 (1) (2011), 10.1145/1952982.1952995
Google Scholar
Lokhov, 2011
A. Lokhov
Load-follow Nucl. Power Plants (29) (2011), pp. 18-20
View Record in Scopus
McLaughlin, 2013
S. McLaughlin
CPS: stateful policy enforcement for control system device usage
In Proceedings Of the 29th Annual Computer Security Applications Conference (2013), pp. 109-118, 10.1145/2523649.2523673
CrossRefView Record in ScopusGoogle Scholar
Nuclear Engineering Agenc, 2011
Nuclear Engineering Agency
Technical and Economic Aspects of Load Following with Nuclear Power Plants
(2011)
Google Scholar
Pan and Duraisamy, 2018
S. Pan, K. Duraisamy
Long-time predictive modeling of nonlinear dynamical systems using neural networks
Complexity (2018), 10.1155/2018/4801012
Google Scholar
Papernot et al., Goodfellow
N. Papernot, P. Mcdaniel, and I. Goodfellow, “Practical Black-Box Attacks against Machine Learning.”.
Google Scholar
Peterson and Paulsen, 1995
M.P. Peterson, C.E. Paulsen
An Implicit Steady-State Initialization Package for the RELAP5 Computer Code
(1995)
Google Scholar
Proctor et al., 2014
J.L. Proctor, S.L. Brunton, J.N. Kutz
Dynamic mode decomposition with control
SIAM J. Appl. Dyn. Syst., 15 (1) (2014), pp. 142-161, 10.1137/15M1013857
View Record in ScopusGoogle Scholar
Sandberg and Johansson
H. Sandberg and K. H. Johansson, “On Security Indices for State Estimators in Power Networks.”.
Google Scholar
Shannon, 2018
L. Eggers Shannon
Adapting Anomaly Detection Techniques for Online Intrusion Detection in Nuclear Facilities
(2018)
Google Scholar
Smarra et al., 2018
F. Smarra, A. Jain, R. Mangharam, A. D'Innocenzo
Data-driven switched affine modeling for model predictive control
IFAC-PapersOnLine, 51 (16) (2018), pp. 199-204, 10.1016/j.ifacol.2018.08.034
ArticleDownload PDFView Record in ScopusGoogle Scholar
SMOLA and SCHOLKOPF, 2004
A.J. Smola, B. Schölkopf
A tutorial on support vector regression
Statistics and Computing, 14 (2004), pp. 199-222
View Record in ScopusGoogle Scholar
Sundaram et al., Ashy
A. Sundaram, H. S. Abdel-Khalik, and Oussama Ashy, “Exploratory Study into the Effectiveness of Active Monitoring Techniques.”.
Google Scholar
Trunzeret al., 2018
E. Trunzer, et al.
Failure mode classification for control valves for supporting data-driven fault detection
IEEE Int. Conf. Ind. Eng. Eng. Manag., 2017 (2018), pp. 2346-2350, 10.1109/IEEM.2017.8290311
Decem
View Record in ScopusGoogle Scholar
Urbinaet al., 2016
D.I. Urbina, et al.
Limiting the impact of stealthy attacks on industrial control systems
In Proceedings Of the 2016 ACM SIGSAC Conference On Computer And Communications Security - CCS’16 (2016), pp. 1092-1105, 10.1145/2976749.2978388
c
CrossRefView Record in ScopusGoogle Scholar
Verleysen and François, 2005
M. Verleysen, D. François
The curse of dimensionality in data mining and time series prediction
Lect. Notes Comput. Sci., 3512 (2005), pp. 758-770, 10.1007/11494669_93
CrossRefView Record in ScopusGoogle Scholar
Vert et al., 2004
J.-P. Vert, K. Tsuda, B. Scholkopf
“A Primer on Kernel Methods,” in Kernel Methods In Computational Biology
MIT Press (2004), pp. 35-70
View Record in ScopusGoogle Scholar
Vuković and Dán, 2013
O. Vuković, G. Dán
On the security of distributed power system state estimation under targeted attacks
In Proceedings Of the 28th Annual ACM Symposium On Applied Computing (2013), pp. 666-672, 10.1145/2480362.2480490
CrossRefView Record in ScopusGoogle Scholar
Wang et al., 2014
Y. Wang, Z. Xu, J. Zhang, L. Xu, H. Wang, G. Gu
SRID: state relation based intrusion detection for false data injection attacks in SCADA
Lect. Notes Comput. Sci., 8713 (2014), pp. 401-418, 10.1007/978-3-319-11212-1_23
LNCS, no. PART 2
CrossRefView Record in ScopusGoogle Scholar
Yao, 2017
D.D. Yao
“Orpheus : Enforcing Cyber-Physical Execution Semantics to Defend against Data-Oriented Attacks
(2017), pp. 315-326
CrossRefView Record in ScopusGoogle Scholar
NIST, 2015
NIST, “Improving critical infrastructure cybersecurity executive order 13636 preliminary cybersecurity framework”.
Google Scholar
Smith, 2015
R.S. Smith
Covert Misappropriation Control Systems
Control Syst (1) (2015), pp. 82-92
January 2015, 2015
CrossRefView Record in ScopusGoogle Scholar