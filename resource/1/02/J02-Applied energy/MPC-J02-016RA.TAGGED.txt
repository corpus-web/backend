<title> Cost-effective_JJ reinforcement_NN learning_VVG energy_NN management_NN for_IN plug-in_NP hybrid_JJ fuel_NN cell_NN and_CC battery_NN ships_NNS </title> <author> Wu_NP ,_, Peng_NP ;_: Partridge_NP ,_, Julius_NP ;_: Bucknall_NP ,_, Richard_NP </author> <Affiliation> 1_CD Marine_NP Research_NP Group_NP ,_, Department_NP of_IN Mechanical_NP Engineering_NP ,_, University_NP College_NP London_NP ,_, London_NP ;_: WC1E_NP 7JE_NP ,_, United_NP Kingdom_NP </Affiliation> <year> 2020_CD </year> <Jounral> Applied_NP Energy_NP ,_, </Journal> <Publishing_house> Elsevier_NP Ltd_NP </Publishing_house> <Text_Collector> Liu_NP Kai，HEU_NP </Text_Collector> <DOI> 10.1016/j_NP ._SENT 
apenergy.2020.115258_JJ </DOI> <URL> https_NNS :_: //www_NNS ._SENT 
sciencedirect_NNS ._SENT 
com/science/article/pii/S0306261920307704_NP ?_SENT 
via%3Dihub_NP </URL> <Section> Highlightst_NP </Section> •_NP Ship_NP hybrid_JJ system_NN optimal_JJ energy_NN management_NN is_VBZ solved_VVN by_IN reinforcement_NN learning_NN ._SENT 
•_JJ Real-world_NN profiles_NNS are_VBP applied_VVN to_TO generate_VV generic_JJ energy_NN management_NN strategy_NN ._SENT 
•_JJ Stochastic_JJ power_NN profiles_NNS can_MD influence_VV reinforcement_NN learning_VVG agent_NN performance_NN ._SENT 
•_NP Energy_NP management_NN strategy_NN achieves_VVZ near_IN optimal_JJ performance_NN in_IN unseen_JJ voyages_NNS ._SENT 
<Section> Abstract_JJ </Section> Hybrid_JJ fuel_NN cell_NN and_CC battery_NN propulsion_NN systems_NNS have_VHP the_DT potential_NN to_TO offer_VV improved_VVN emission_NN performance_NN for_IN coastal_JJ ships_NNS with_IN access_NN to_TO H2_JJ replenishment_NN and_CC battery_NN charging_VVG infrastructures_NNS in_IN ports_NNS ._SENT 
However_RB ,_, such_JJ systems_NNS could_MD be_VB constrained_VVN by_IN high_JJ power_NN source_NN degradation_NN and_CC energy_NN costs_NNS ._SENT 
Cost-effective_JJ energy_NN management_NN strategies_NNS are_VBP essential_JJ for_IN such_JJ hybrid_JJ systems_NNS to_TO mitigate_VV the_DT high_JJ costs_NNS ._SENT 
This_DT article_NN presents_VVZ a_DT Double_NP Q_NP reinforcement_NN learning_VVG based_VVN energy_NN management_NN system_NN for_IN such_JJ systems_NNS to_TO achieve_VV near-optimal_JJ average_JJ voyage_NN cost_NN ._SENT 
The_DT Double_NP Q_NP agent_NN is_VBZ trained_VVN using_VVG stochastic_JJ power_NN profiles_NNS collected_VVN from_IN continuous_JJ monitoring_NN of_IN a_DT passenger_NN ferry_NN ,_, using_VVG a_DT plug-in_NP hybrid_JJ fuel_NN cell_NN and_CC battery_NN propulsion_NN system_NN model_NN ._SENT 
The_DT energy_NN management_NN strategies_NNS generated_VVN by_IN the_DT agent_NN were_VBD validated_VVN using_VVG another_DT test_NN dataset_NN collected_VVN over_IN a_DT different_JJ period_NN ._SENT 
The_DT proposed_VVN methodology_NN provides_VVZ a_DT novel_JJ approach_NN to_TO optimal_JJ use_NN hybrid_JJ fuel_NN cell_NN and_CC battery_NN propulsion_NN systems_NNS for_IN ships_NNS ._SENT 
The_DT results_NNS show_VVP that_IN without_IN prior_JJ knowledge_NN of_IN future_JJ power_NN demands_NNS ,_, the_DT strategies_NNS can_MD achieve_VV near-optimal_JJ cost_NN performance_NN (_( 96.9_CD %_NN )_) compared_VVN to_TO those_DT derived_VVN from_IN using_VVG dynamic_JJ programming_NN with_IN the_DT equivalent_JJ state_NN space_NN resolution_NN ._SENT 
Keywords：Coastal_JJ ferry；Hybrid_JJ fuel_NN cell_NN and_CC battery；Continuous_JJ monitoring；Energy_JJ management_NN system；Reinforcement_NN learning_VVG <Section> 1._CD Introduction_NN </Section> The_DT hybridisation_NN of_IN Proton_NN Exchange_NP Membrane_NN Fuel_NN Cells_NNS (_( PEMFC_NP )_) [_SYM 1_CD ]_SYM with_IN lithium_NN batteries_NNS recharged_VVN from_IN shore-generated_JJ electrical_JJ power_NN [_SYM 2_CD ]_SYM may_MD potentially_RB offer_VV desirable_JJ emission_NN performance_NN for_IN coastal_JJ ships_NNS with_IN access_NN to_TO H2_JJ replenishing_VVG and_CC battery_NN charging_VVG infrastructures_NNS [_SYM 3_CD ]_SYM ._SENT 
By_IN utilising_VVG both_DT H2_JJ and_CC shore-generated_JJ electrical_JJ power_NN ,_, the_DT life-cycle_NN emission_NN performance_NN could_MD be_VB reduced_VVN significantly_RB [_SYM 3_CD ]_SYM ._SENT 
However_RB ,_, such_JJ hybrid_JJ systems_NNS are_VBP constrained_VVN by_IN high_JJ degradation_NN of_IN the_DT power_NN sources_NNS and_CC energy_NN costs_NNS [_SYM 4_CD ]_SYM ._SENT 
It_PP is_VBZ necessary_JJ to_TO improve_VV the_DT operational_JJ cost-effectiveness_NN of_IN such_JJ hybrid_JJ systems_NNS ._SENT 
In_IN a_DT hybrid_JJ propulsion_NN system_NN ,_, an_DT effective_JJ Energy_NP Management_NP System_NP (_( EMS_NP )_) is_VBZ crucial_JJ to_TO managing_VVG power_NN utilisation_NN from_IN the_DT multiple_JJ power_NN sources_NNS ._SENT 
The_DT EMS_NP determines_VVZ output_NN actions_NNS of_IN the_DT hybrid_JJ propulsion_NN system_NN under_IN certain_JJ operating_VVG conditions_NNS ._SENT 
However_RB ,_, it_PP is_VBZ challenging_VVG to_TO develop_VV effective_JJ EMS_NP for_IN hybrid_JJ systems_NNS since_IN they_PP need_VVP to_TO be_VB applied_VVN to_TO load_VV power_NN profiles_NNS that_WDT have_VHP not_RB been_VBN detailed_VVN in_IN advance_NN of_IN the_DT application_NN ._SENT 
For_IN a_DT hybrid_JJ system_NN with_IN an_DT energy_NN storage_NN device_NN the_DT problem_NN ,_, in_IN essence_NN ,_, is_VBZ that_IN of_IN sequential-decision_NN making_NN ,_, i._NP e._NP what_WP actions_NNS or_CC controls_NNS should_MD be_VB taken_VVN over_IN the_DT power_NN cycles_NNS to_TO achieve_VV optimal_JJ objectives_NNS (_( e._NP g._NP minimum_JJ operational_JJ costs_NNS ,_, minimum_JJ emissions_NNS or_CC a_DT weighted_JJ balance_NN )_) ._SENT 
For_IN hybrid_JJ road_NN vehicles_NNS ,_, standard_JJ driving_NN cycles_NNS can_MD be_VB used_VVN to_TO develop_VV such_JJ EMS_NP ._SENT 
However_RB ,_, for_IN hybrid_JJ ships_NNS ,_, such_JJ standard_JJ cycles_NNS do_VVP not_RB exist_VV and_CC actual_JJ power_NN demands_NNS over_IN a_DT series_NN of_IN voyages_NNS may_MD vary_VV significantly_RB due_JJ to_TO factors_NNS such_JJ as_IN sea_NN states_NNS ,_, weather_NN and_CC cargo_NN loading_NN conditions_NNS ._SENT 
In_IN recent_JJ years_NNS ,_, continuous_JJ monitoring_NN of_IN power_NN demands_NNS over_IN the_DT long_JJ term_NN provides_VVZ a_DT potential_JJ new_JJ approach_NN to_TO develop_VV effective_JJ EMS_NP for_IN such_JJ vessels_NNS [_SYM 5_CD ]_SYM ._SENT 
The_DT research_NN of_IN EMS_NP for_IN hybrid_JJ propulsion_NN systems_NNS is_VBZ primarily_RB driven_VVN by_IN road_NN vehicle_NN applications_NNS ._SENT 
Sulaiman_NP et_NP al_NP ._SENT 
[_SYM 6_CD ]_SYM provided_VVD a_DT comprehensive_JJ review_NN of_IN the_DT main_JJ EMS_NP categories_NNS for_IN hybrid_JJ fuel_NN cell_NN road_NN vehicles_NNS ._SENT 
Their_PP$ review_NN indicates_VVZ that_IN energy_NN management_NN strategies_NNS such_JJ as_IN rule-based_JJ ,_, fuzzy_JJ logic_NN ,_, Equivalent_JJ Consumption_NN Minimisation_NN Strategy_NN and_CC wavelet-based_JJ load_NN sharing_NN are_VBP the_DT main_JJ EMS_NP streams_NNS for_IN hybrid_JJ fuel_NN cell_NN road_NN vehicles_NNS ._SENT 
Wang_NP et_NP al_NP ._SENT 
[_SYM 7_CD ]_SYM developed_VVD a_DT rule-based_JJ on-line_JJ energy_NN management_NN strategy_NN for_IN hybrid_JJ fuel_NN cell_NN and_CC ultracapacitor_NN systems_NNS ._SENT 
Although_IN near-optimal_JJ fuel_NN economy_NN has_VHZ been_VBN achieved_VVN by_IN their_PP$ rule-based_JJ strategy_NN in_IN the_DT two_CD load_NN profiles_NNS under_IN investigation_NN ,_, the_DT performance_NN of_IN the_DT strategy_NN in_IN other_JJ profiles_NNS which_WDT can_MD vary_VV significantly_RB is_VBZ not_RB clear_JJ ._SENT 
Wang_NP et_NP al_NP ._SENT 
[_SYM 8_CD ]_SYM proposed_VVN an_DT energy_NN management_NN strategy_NN based_VVN on_IN velocity_NN prediction_NN for_IN three_CD typical_JJ non-plug_NN in_IN hybrid_JJ electric_JJ propulsion_NN structures_NNS ._SENT 
An_DT urban_JJ driving_NN cycle_NN was_VBD used_VVN to_TO calculate_VV the_DT state_NN transition_NN probabilities_NNS ;_: subsequently_RB ,_, dynamic_JJ programming_NN was_VBD employed_VVN to_TO generate_VV the_DT strategy_NN ._SENT 
Recently_RB ,_, machine_NN learning_NN EMS_NP has_VHZ been_VBN applied_VVN to_TO road_NN vehicles_NNS ._SENT 
Muñoz_NP et_NP al_NP ._SENT 
[_SYM 9_CD ]_SYM presented_VVD a_DT neural_JJ network_NN EMS_NP for_IN hybrid_JJ fuel_NN cell_NN and_CC battery_NN road_NN vehicles_NNS using_VVG supervised_JJ learning_NN ._SENT 
With_IN a_DT target_NN EMS_NP for_IN specific_JJ driving_NN cycles_NNS generated_VVN by_IN optimisation_NN approaches_NNS ,_, the_DT neural_JJ network_NN was_VBD subsequently_RB trained_VVN to_TO achieve_VV performance_NN similar_JJ to_TO that_DT achieved_VVN by_IN the_DT target_NN EMS_NP ._SENT 
The_DT actual_JJ performance_NN of_IN such_JJ EMS_NP when_WRB applied_VVN to_TO unknown_JJ driving_VVG cycles_NNS is_VBZ not_RB clear_JJ ._SENT 
Fletcher_NP et_NP al_NP ._SENT 
[_SYM 10_CD ]_SYM adopted_VVN stochastic_JJ dynamic_JJ programming_NN to_TO generate_VV optimal_JJ EMS_NP for_IN a_DT hybrid_JJ fuel_NN cell/battery_NN road_NN vehicle_NN ,_, accounting_NN for_IN the_DT fuel_NN cell_NN degradation_NN characteristics_NNS generalised_VVN from_IN experimental_JJ results_NNS ._SENT 
Their_PP$ EMS_NP was_VBD able_JJ to_TO reduce_VV the_DT cost_NN by_IN 12.3_CD %_NN due_JJ to_TO prolonged_JJ fuel_NN cell_NN lifetime_NN ._SENT 
However_RB ,_, the_DT accuracy_NN of_IN stochastic_JJ dynamic_JJ programming_NN is_VBZ limited_VVN by_IN its_PP$ resolution_NN due_JJ to_TO ‘_NN the_DT curse_NN of_IN dimensionality_NN ’_NP [_SYM 11_CD ]_SYM ._SENT 
More_RBR recently_RB ,_, Reinforcement_NN Learning_NP (_( RL_NP )_) approaches_NNS have_VHP been_VBN proposed_VVN for_IN hybrid_JJ diesel_JJ engine_NN and_CC battery_NN road_NN vehicles_NNS ._SENT 
Hu_NP et_NP al_NP ._SENT 
[_SYM 12_CD ]_SYM and_CC Wu_NP et_NP al_NP ._SENT 
[_SYM 13_CD ]_SYM implemented_VVN Deep_NP Q_NP Network_NP (_( DQN_NP )_) to_TO generate_VV EMS_NP for_IN standard_JJ driving_NN cycles_NNS ._SENT 
It_PP is_VBZ worth_JJ noting_VVG that_IN ,_, using_VVG a_DT limited_JJ number_NN of_IN driving_VVG cycles_NNS to_TO train_VV an_DT RL_NP agent_NN could_MD lead_VV to_TO the_DT generated_VVN EMS_NP only_RB performing_VVG satisfactorily_RB under_IN specific_JJ driving_NN cycles_NNS ._SENT 
Xiong_NP et_NP al_NP ._SENT 
[_SYM 14_CD ]_SYM proposed_VVN solving_VVG the_DT optimal_JJ power_NN split_NN problem_NN using_VVG Q-learning_NN with_IN Kullback-Leibler_NN divergence_NN ,_, indicating_VVG if_IN and_CC when_WRB to_TO update_VV the_DT EMS_NP over_IN time_NN ._SENT 
Their_PP$ results_NNS suggest_VVP that_IN updating_VVG the_DT EMS_NP over_IN time_NN may_MD further_RBR reduce_VV fuel_NN consumption_NN ._SENT 
However_RB ,_, such_PDT an_DT approach_NN requires_VVZ frequent_JJ updates_NNS of_IN the_DT EMS_NP ,_, and_CC the_DT updated_VVN EMS_NP may_MD not_RB perform_VV as_RB expected_VVN under_IN non-predicted_JJ future_JJ load_NN cycles_NNS ._SENT 
For_IN shipboard_NN applications_NNS ,_, it_PP is_VBZ rare_JJ to_TO find_VV an_DT intelligent_JJ EMS_NP which_WDT can_MD accommodate_VV non-predicted_JJ future_JJ voyages_NNS ._SENT 
Kalikatzarakis_NP et_NP al_NP ._SENT 
[_SYM 15_CD ]_SYM presented_VVN ‘_JJ Equivalent_JJ Consumption_NN Minimisation_NN Strategies_NNS ’_JJ for_IN shipboard_NN applications_NNS with_IN diesel_JJ engine_NN in_IN hybridisation_NN with_IN battery_NN and_CC shore_NN power_NN ._SENT 
Their_PP$ results_NNS indicate_VVP that_IN a_DT 6_CD %_NN fuel_NN saving_NN can_MD be_VB achieved_VVN compared_VVN to_TO the_DT rule-based_JJ method_NN ._SENT 
Bassam_NP et_NP al_NP ._SENT 
[_SYM 16_CD ]_SYM proposed_VVN a_DT multi-scheme_NP EMS_NP with_IN a_DT mix_NN of_IN several_JJ sub-EMSs_NP at_IN different_JJ states_NNS for_IN a_DT hybrid_JJ fuel_NN cell_NN passenger_NN ship_NN based_VVN on_IN an_DT eight-hour_NN profile_NN ._SENT 
Choi_NP et_NP al_NP ._SENT 
[_SYM 17_CD ]_SYM implemented_VVN a_DT load-following_NP EMS_NP for_IN their_PP$ hybrid_JJ fuel_NN cell_NN and_CC battery_NN boat_NN ,_, in_IN which_WDT the_DT fuel_NN cells_NNS operate_VVP at_IN a_DT designated_VVN power_NN setting_VVG while_IN the_DT batteries_NNS provide_VVP any_DT additional_JJ power_NN demand_NN ._SENT 
Han_NP et_NP al_NP ._SENT 
[_SYM 18_CD ]_SYM proposed_VVN a_DT rule-based_JJ EMS_NP tuned_VVN by_IN a_DT typical_JJ load_NN cycle_NN for_IN a_DT low_JJ power_NN passenger_NN ferry_NN ._SENT 
It_PP should_MD be_VB noted_VVN that_IN the_DT actual_JJ EMS_NP performance_NN was_VBD not_RB clear_JJ for_IN other_JJ load_NN cycles_NNS since_IN a_DT limited_JJ number_NN of_IN power_NN profiles_NNS were_VBD analysed_VVN in_IN these_DT studies_NNS ._SENT 
The_DT research_NN efforts_NNS mentioned_VVD above_RB have_VH been_VBN used_VVN to_TO successfully_RB develop_VV EMS_NP for_IN hybrid_JJ propulsion_NN systems_NNS ._SENT 
However_RB ,_, the_DT existing_JJ strategies_NNS were_VBD tuned_VVN with_IN a_DT limited_JJ number_NN of_IN load_NN profiles_NNS ._SENT 
The_DT actual_JJ performance_NN of_IN the_DT strategy_NN for_IN unknown_JJ future_JJ load_NN profiles_NNS ,_, for_IN both_DT road_NN and_CC ship_NN applications_NNS ,_, is_VBZ not_RB clear_JJ in_IN the_DT existing_JJ works_NNS ._SENT 
Although_IN novel_NN approaches_NNS such_JJ as_IN RL_NP have_VHP been_VBN applied_VVN to_TO develop_VV intelligent_JJ EMS_NP ,_, existing_VVG EMS_NP are_VBP often_RB tuned_VVN using_VVG a_DT limited_JJ number_NN of_IN load_NN profiles_NNS ._SENT 
There_EX is_VBZ a_DT lack_NN of_IN generic_JJ EMS_NP that_WDT can_MD accommodate_VV stochastic_JJ power_NN profiles_NNS with_IN high_JJ variations_NNS in_IN marine_JJ applications_NNS ._SENT 
The_DT remainder_NN of_IN this_DT article_NN proposes_VVZ a_DT novel_NN cost-effective_JJ EMS_NP that_WDT uses_VVZ reinforcement_NN learning_NN for_IN shipboard_NN plug-in_NN hybrid_JJ fuel_NN cell_NN and_CC battery_NN propulsion_NN systems_NNS ._SENT 
The_DT optimal_JJ energy_NN management_NN problem_NN will_MD be_VB modelled_VVN as_IN a_DT Markov_NP Decision_NN Process_NN (_( MDP_NN )_) ._SENT 
The_DT formulated_VVN MDP_NN is_VBZ solved_VVN through_IN the_DT use_NN of_IN a_DT Double_NP Q_NP reinforcement_NN learning_VVG agent_NN utilising_VVG real_JJ ship_NN stochastic_JJ power_NN profiles_NNS collected_VVD using_VVG continuous_JJ monitoring_NN ._SENT 
By_IN using_VVG continuous_JJ monitoring_NN data_NNS on_IN a_DT significant_JJ scale_NN ,_, the_DT policy_NN generated_VVN by_IN the_DT RL_NP agent_NN can_MD be_VB used_VVN directly_RB by_IN ships_NNS as_IN a_DT guide_NN strategy_NN of_IN the_DT EMS_NP to_TO achieve_VV long-term_JJ near-optimal_JJ cost_NN performance_NN without_IN prior_JJ knowledge_NN of_IN any_DT future_JJ power_NN demands_NNS ._SENT 
The_DT rest_NN of_IN this_DT article_NN is_VBZ organised_VVN as_RB follows_VVZ ._SENT 
Section_NN 2_CD details_NNS the_DT modelling_VVG of_IN the_DT hybrid_JJ PEMFC_NN and_CC battery_NN propulsion_NN system_NN ._SENT 
Section_NN 3_CD details_NNS the_DT parameters_NNS of_IN the_DT candidate_NN ship_NN to_TO which_WDT the_DT proposed_VVN EMS_NP will_MD be_VB applied_VVN ._SENT 
Section_NN 4_CD formulates_VVZ the_DT optimal_JJ energy_NN management_NN problem_NN using_VVG reinforcement_NN learning_VVG ,_, and_CC introduces_VVZ the_DT associated_VVN Double_NP Q_NP reinforcement_NN learning_VVG agent_NN ._SENT 
Section_NN 5_CD details_NNS the_DT agent_NN training_NN process_NN to_TO acquire_VV the_DT EMS_NP ._SENT 
Section_NN 6_CD presents_VVZ the_DT results_NNS by_IN applying_VVG the_DT Double_NP Q_NP EMS_NP to_TO training_NN and_CC validation_NN voyages_NNS ._SENT 
Section_NN 7_CD details_NNS the_DT authors_NNS ’_NN conclusions_NNS ._SENT 
<Section> 2._CD Plug-in_NN hybrid_JJ PEMFC_NN and_CC battery_NN propulsion_NN system_NN </Section> 2.1_CD ._SENT 
System_NN overview_NN The_DT work_NN in_IN this_DT article_NN is_VBZ a_DT continuation_NN of_IN the_DT research_NN detailed_VVN in_RB [_SYM 19_CD ]_SYM ._SENT 
In_IN that_DT work_NN ,_, the_DT hybrid_JJ plug-in_NN PEMFC_NN and_CC battery_NN propulsion_NN system_NN sizing_VVG has_VHZ been_VBN optimised_VVN based_VVN upon_IN a_DT proposed_VVN hybrid_JJ propulsion_NN system_NN model_NN for_IN a_DT specific_JJ vessel_NN operating_VVG on_IN a_DT particular_JJ route_NN ._SENT 
Fig_NN ._SENT 
1_CD provides_VVZ the_DT quasi-steady-state_JJ model_NN which_WDT has_VHZ been_VBN developed_VVN and_CC validated_VVN in_RB [_SYM 19_CD ]_SYM for_IN system_NN design_NN optimisation_NN and_CC intelligent_JJ EMS_NP development_NN ._SENT 
The_DT system_NN comprises_VVZ a_DT fuel_NN cell_NN ,_, battery_NN and_CC converters_NNS ._SENT 
The_DT EMS_NP manages_VVZ the_DT power_NN flows_VVZ between_IN the_DT power_NN sources_NNS and_CC the_DT load_NN ._SENT 
The_DT battery_NN can_MD discharge_VV or_CC be_VB charged_VVN through_IN the_DT bidirectional_JJ DC/DC_NN converter_NN ._SENT 
Fig_NN ._SENT 
1._CD Plug-in_NN hybrid_JJ PEMFC_NN and_CC battery_NN propulsion_NN system_NN top-level_JJ model_NN ._SENT 
The_DT energy_NN management_NN system_NN manages_VVZ the_DT power_NN flows_VVZ within_IN the_DT hybrid_JJ system_NN ._SENT 
2.2_CD ._SENT 
System_NN model_NN 2.2.1_CD ._SENT 
Power_NN converters_NNS The_DT efficiencies_NNS of_IN the_DT power_NN converter_NN for_IN the_DT fuel_NN cell_NN (_( η1_JJ )_) and_CC the_DT two_CD converting_VVG modes_NNS of_IN the_DT battery_NN power_NN converter_NN (_( η2_JJ for_IN dischraging_VVG and_CC η3_NN for_IN charging_VVG )_) are_VBP presented_VVN in_IN Fig_NN ._SENT 
2_LS [_SYM 19_CD ]_SYM ._SENT 
The_DT efficiencies_NNS of_IN the_DT power_NN converter_NN models_NNS are_VBP calculated_VVN as_IN the_DT percentage_NN ratios_NNS of_IN input_NN to_TO output_NN power_NN in_IN per_IN unit_NN terms_NNS ._SENT 
Note_NN that_IN the_DT bidirectional_JJ DC/DC_NN converter_NN works_VVZ at_IN different_JJ efficiencies_NNS in_IN battery_NN discharging_VVG and_CC charging_VVG modes_NNS ._SENT 
Fig_NN ._SENT 
2._CD Power_NP converter_NN efficiencies_NNS for_IN the_DT PEMFC_NN and_CC battery_NN ._SENT 
Note_NN that_IN the_DT converter_NN efficiency_NN models_NNS are_VBP representative_JJ of_IN achievable_JJ characteristics_NNS ,_, and_CC can_MD be_VB updated_VVN when_WRB actual_JJ converter_NN features_NNS are_VBP available_JJ for_IN actual_JJ engineering_NN applications_NNS ._SENT 
2.2.2_CD ._SENT 
PEMFC_NP model_NN The_DT input_NN to_TO the_DT fuel_NN cell_NN model_NN is_VBZ the_DT fuel_NN cell_NN per_IN unit_NN power_NN ,_, denoted_VVN by_IN pfc_NP ._SENT 
The_DT specific_JJ H2_NN consumption_NN is_VBZ calculated_VVN by_IN the_DT model_NN as_IN detailed_JJ in_IN Fig_NN ._SENT 
3._CD The_DT H2_JJ mass_NN flow_NN rate_NN ,_, ṁH2_NP ,_, can_MD be_VB calculated_VVN by_IN :_: @（1）_NN where_WRB ψfc_NN denotes_VVZ the_DT model_NN function_NN ,_, Pfc_NP is_VBZ the_DT fuel_NN cell_NN rated_VVN power_NN ._SENT 
PEMFC_NN degradation_NN is_VBZ subject_JJ to_TO factors_NNS such_JJ as_IN power_NN transients_NNS ,_, load_NN levels_NNS and_CC cycling_NN ._SENT 
In_IN this_DT study_NN ,_, the_DT fuel_NN cell_NN degradation_NN characteristics_NNS are_VBP based_VVN upon_IN the_DT work_NN of_IN Chen_NP et_CC al_NP ._SENT 
[_SYM 20_CD ]_SYM ,_, which_WDT have_VHP been_VBN adopted_VVN in_RB [_SYM 10_CD ]_SYM for_IN EMS_NP development_NN ._SENT 
At_IN each_DT time_NN step_NN ,_, the_DT cost_NN incurred_VVN through_IN fuel_NN cell_NN degradation_NN is_VBZ δfcPfcσfc_NP ,_, where_WRB δfc_NP is_VBZ the_DT inverse_NN of_IN the_DT total_JJ available_JJ fuel_NN cell_NN operating_VVG time_NN steps_NNS under_IN current_JJ operating_VVG conditions_NNS ,_, Pfc_NP is_VBZ fuel_NN cell_NN rated_VVN power_NN and_CC σfc_NN is_VBZ the_DT fuel_NN cell_NN price_NN per_IN kW_NNS ._SENT 
Fig_NN ._SENT 
3._CD PEMFC_NN specific_JJ H2_JJ consumption_NN and_CC system_NN efficiency_NN ._SENT 
The_DT PEMFC_NP model_NN outputs_NNS specific_JJ H2_NP consumption_NN based_VVN on_IN per_IN unit_NN power_NN input_NN ._SENT 
2.2.3_CD ._SENT 
Battery_NN model_NN As_IN shown_VVN in_IN Fig_NN ._SENT 
4a_NP ,_, the_DT scalable_JJ battery_NN model_NN is_VBZ developed_VVN by_IN connecting_VVG the_DT outputs_NNS from_IN individual_JJ cells_NNS in_IN series_NN and_CC parallel_JJ to_TO form_VV the_DT battery_NN stacks_NNS [_SYM 21_CD ]_SYM ._SENT 
Individual_JJ cell_NN open-circuit_NN voltage_NN is_VBZ a_DT function_NN of_IN battery_NN State_NN of_IN Charge_NP (_( SOC_NP )_) as_RB presented_VVN in_IN Fig_NN ._SENT 
4b_NP ._SENT 
The_DT battery_NN model_NN is_VBZ calibrated_VVN and_CC validated_VVN using_VVG experimental_JJ data_NNS from_IN [_SYM 22_CD ]_SYM ._SENT 
It_PP has_VHZ been_VBN assumed_VVN that_IN all_PDT the_DT battery_NN cells_NNS have_VHP identical_JJ characteristics_NNS and_CC the_DT resistances_NNS between_IN cells_NNS are_VBP negligible_JJ ._SENT 
An_DT averaged_VVN battery_NN degradation_NN function_NN δbat_NN is_VBZ adopted_VVN ,_, i._NP e._NP the_DT batteries_NNS are_VBP assured_VVN to_TO operate_VV for_IN a_DT fixed_VVN period_NN before_IN reaching_VVG the_DT end_NN of_IN life_NN ._SENT 
Note_NN that_IN δbat_NP is_VBZ the_DT inverse_NN the_DT of_IN total_JJ available_JJ battery_NN operating_VVG time_NN steps_NNS ._SENT 
Fig_NN ._SENT 
4._CD Battery_NP stack_VV model_NN and_CC individual_JJ cell_NN circuit_NN (_( a_DT )_) :_: the_DT outputs_NNS from_IN individual_JJ battery_NN cells_NNS are_VBP connected_VVN in_IN series_NN and_CC parallel_JJ to_TO form_VV the_DT battery_NN module_NN ,_, and_CC (_( b_LS )_) battery_NN individual_JJ cell_NN voltage_NN in_IN a_DT function_NN of_IN battery_NN SOC_NN ._SENT 
The_DT battery_NN works_VVZ either_RB in_IN discharging/floating_VVG or_CC charging_VVG modes_NNS ._SENT 
The_DT battery_NN output_NN power_NN is_VBZ :_: @（2）_NN where_WRB IB_NP and_CC VB_NP are_VBP battery_NN module_NN current_JJ and_CC terminal_JJ voltage_NN respectively_RB ,_, and_CC VB_NP is_VBZ a_DT linear_JJ function_NN of_IN individual_JJ battery_NN cell_NN terminal_NN output_NN voltage_NN Vt._NP The_DT cell_NN terminal_NN voltage_NN Vt_NP is_VBZ calculated_VVN by_IN :_: @（3）_NN where_WRB Voc_NN is_VBZ a_DT function_NN of_IN battery_NN SOC_NN as_IN shown_VVN in_IN Fig_NN ._SENT 
4b_NP ._SENT 
And_CC the_DT voltage_NN across_IN C1_JJ satisfies_NNS :_: @（4）_NN The_DT battery_NN SOC_NN change_NN over_IN a_DT period_NN t1_JJ to_TO t2_NN can_MD be_VB calculated_VVN by_IN :_: @（5）_NN where_WRB C(t_NP )_) is_VBZ battery_NN C-rate_NN ,_, ηb_NP is_VBZ battery_NN coulombic_JJ efficiency_NN ._SENT 
2.2.4_CD ._SENT 
System_NN dynamics_NNS The_DT action_NN of_IN the_DT battery_NN improves_VVZ system_NN efficiency_NN and_CC performance_NN by_IN load_NN levelling_VVG and_CC peak_NN shaving_NN ._SENT 
For_IN each_DT time_NN step_NN ,_, the_DT required_JJ battery_NN power_NN is_VBZ determined_VVN by_IN (_( see_VV Fig_NN ._SENT 
1_LS )_) :_: @（6a）_NP @（6b）_NP @（6c）_NP @（6d）_NP @（6e）_NP where_WRB P1_NN is_VBZ fuel_NN cell_NN power_NN delivered_VVN by_IN the_DT boost_NN converter_NN and_CC Pbat_NN is_VBZ battery_NN power_NN ,_, η1_JJ ,_, η2_JJ and_CC η3_JJ are_VBP the_DT fuel_NN cell_NN and_CC battery_NN converter_NN (_( charging_VVG and_CC discharging_VVG )_) efficiencies_NNS respectively_RB ,_, Pdem_NP is_VBZ the_DT total_JJ power_NN demand_NN ,_, Ps_NN is_VBZ the_DT shore_NN power_NN which_WDT is_VBZ only_RB applicable_JJ when_WRB the_DT vessel_NN is_VBZ in_IN port_NN ._SENT 
2.3_CD ._SENT 
Energy_NN management_NN system_NN The_DT EMS_NP determines_VVZ the_DT fuel_NN cell_NN power_NN output_NN change_NN through_IN measured_VVN inputs_NNS of_IN the_DT fuel_NN cell_NN ,_, battery_NN and_CC shore_VV power_NN states_NNS as_RB well_RB as_IN power_NN demand_NN (_( Fig_NN ._SENT 
1_LS )_) ._SENT 
The_DT proposed_VVN alternative_JJ hybrid_JJ propulsion_NN system_NN operates_VVZ in_IN two_CD modes_NNS ,_, i._NP e._NP sailing_NN and_CC port_NN modes_NNS :_: •_JJ in_IN port_JJ mode_NN ,_, the_DT EMS_NP sets_VVZ the_DT fuel_NN cell_NN power_NN output_NN to_TO zero_CD ,_, while_IN the_DT shore_NN connection_NN powers_NNS the_DT ship’s_NN load_NN and_CC recharges_VVZ the_DT battery_NN ;_: •_NN in_IN sailing_NN mode_NN ,_, the_DT shore_NN power_NN connection_NN is_VBZ no_RB longer_RBR available–the_JJ fuel_NN cell_NN and_CC battery_NN work_NN together_RB to_TO power_NN both_CC propulsion_NN and_CC auxiliary_JJ loads_NNS ._SENT 
The_DT battery_NN can_MD either_RB work_VV in_IN charging_VVG or_CC discharging_VVG modes_NNS ._SENT 
<Section> 3._CD The_DT candidate_NN ship_NN and_CC continuous_JJ monitoring_VVG data_NNS </Section> The_DT candidate_NN ship_NN and_CC its_PP$ route_NN are_VBP shown_VVN in_IN Fig_NN ._SENT 
5._CD The_DT historical_JJ power_NN profiles_NNS applied_VVN for_IN the_DT agent_NN training_NN were_VBD acquired_VVN from_IN [_SYM 5_CD ]_SYM (_( 1081_CD voyages_NNS in_IN total_NN ,_, from_IN 1_CD July_NP 2018_CD to_TO 31_CD August_NP 2018_CD )_) ._SENT 
Another_DT dataset_NN (_( 391_CD voyages_NNS in_IN total_NN )_) collected_VVN over_IN a_DT different_JJ period_NN (_( from_IN 1_CD September_NP 2018_CD to_TO 30_CD September_NP 2018_CD )_) will_MD be_VB used_VVN for_IN EMS_NP validation_NN ._SENT 
The_DT datasets_NNS were_VBD first_RB segregated_JJ into_IN voyages_NNS determined_VVN by_IN the_DT ship’s_NP speed_NN and_CC location_NN ._SENT 
It_PP should_MD be_VB noted_VVN that_IN the_DT power_NN profiles_NNS include_VVP both_DT propulsive_JJ and_CC auxiliary_JJ loads_NNS ._SENT 
Fig_NN ._SENT 
5._CD Candidate_NN ship_NN (_( a_DT )_) and_CC its_PP$ route_NN (_( b_LS )_) ._SENT 
The_DT candidate_NN ship_NN is_VBZ a_DT passenger_NN ferry_NN with_IN integrated_JJ full_JJ electric_JJ propulsion_NN system_NN ,_, and_CC operates_VVZ between_IN two_CD fixed_VVN ports_NNS ._SENT 
The_DT length_NN of_IN the_DT original_JJ time_NN step_NN of_IN the_DT power_NN profiles_NNS is_VBZ 15_CD s_NNS and_CC remains_VVZ unchanged_JJ ._SENT 
The_DT original_JJ power_NN values_NNS were_VBD smoothed_VVN with_IN a_DT Gaussian-weighted_JJ moving_VVG average_NN filter_NN to_TO reduce_VV measurement_NN noise_NN ._SENT 
The_DT moving_VVG average_JJ window_NN of_IN the_DT Gaussian_JJ filter_NN is_VBZ 4_CD ,_, and_CC the_DT standard_JJ deviation_NN is_VBZ calculated_VVN from_IN 1/5_CD of_IN the_DT total_JJ window_NN width_NN ._SENT 
Due_JJ to_TO the_DT large_JJ time_NN step_NN and_CC the_DT main_JJ focus_NN of_IN this_DT study_NN being_VBG energy_NN efficiency_NN and_CC emissions—instead_NN of_IN dynamic_JJ performance_NN ,_, the_DT direct_JJ current_JJ internal_JJ resistance_NN (_( R0+R1_JJ )_) of_IN the_DT battery_NN model_NN is_VBZ used_VVN in_IN the_DT subsequent_JJ simulations_NNS [_SYM 23_CD ]_SYM ._SENT 
On_IN the_DT candidate_NN ship_VV the_DT original_JJ diesel-electric_JJ system_NN will_MD be_VB replaced_VVN by_IN a_DT plug-in_NP hybrid_JJ PEMFC_NN and_CC battery_NN system_NN ,_, as_RB described_VVN in_IN Section_NP 2._CD The_DT ship’s_NN specifications_NNS are_VBP presented_VVN in_IN Table_NN 1._CD The_DT original_JJ system_NN featured_VVD an_DT integrated_JJ full_JJ electric_JJ propulsion_NN configuration_NN with_IN a_DT total_JJ installed_JJ diesel_NN engine_NN power_NN capacity_NN of_IN 4370_CD kW_NNS ._SENT 
The_DT ship_NN operates_VVZ between_IN two_CD fixed_VVN ports_NNS with_IN 8_CD round_NN trips_NNS (_( 16_CD voyages_NNS )_) per_IN day—each_NN voyage_NN takes_VVZ approximately_RB 1_CD h_NN [_SYM 5_CD ]_SYM ._SENT 
Table_NN 1._CD Candidate_NN ship_NN specifications_NNS ._SENT 
For_IN this_DT research_NN the_DT ship’s_NP battery_NN can_MD be_VB recharged_VVN in_IN both_DT ports_NNS ,_, and_CC the_DT shipboard_NN H2_NN storage_NN needs_VVZ to_TO be_VB replenished_VVN once_RB per_IN day_NN ._SENT 
The_DT intended_VVN fuel_NN cell_NN power_NN and_CC battery_NN capacity_NN for_IN the_DT alternative_JJ plug-in_NN hybrid_JJ PEMFC_NN and_CC battery_NN propulsion_NN system_NN are_VBP 2940_CD kW_NNS and_CC 581_CD kWh_NN respectively_RB ._SENT 
The_DT system_NN is_VBZ capable_JJ of_IN delivering_VVG a_DT regular_JJ service_NN power_NN of_IN 4683_CD kW_NNS and_CC a_DT peak_JJ power_NN of_IN 6720_CD kW_NNS ,_, corresponding_JJ to_TO battery_NN C-rates_NNS of_IN 3_CD and_CC 6_CD respectively_RB ._SENT 
Note_NN that_IN the_DT system_NN sizing_VVG has_VHZ been_VBN optimised_VVN in_IN the_DT authors_NNS ’_JJ earlier_JJR work_NN [_SYM 19_CD ]_SYM ._SENT 
The_DT adopted_VVN H2_NP Global_NP Warming_VVG Potential_JJ (_( GWP_NP )_) ,_, electricity_NN GWP_NN ,_, H2_JJ price_NN and_CC electricity_NN price_NN are_VBP set_VVN at_IN 1.5_CD kg_NN CO2_JJ kg−1_NN ,_, 0.166_CD kg_NN CO2_JJ kWh−1_NN ,_, 8.240_RB $_$ kg−1_JJ ,_, and_CC 0.089_CD $_$ kWh−1_JJ respectively_RB ._SENT 
The_DT battery_NN SOC_NN upper_JJ and_CC lower_JJR limits_NNS are_VBP limited_VVN to_TO upper_JJ and_CC lower_JJR values_NNS of_IN 0.90_CD and_CC 0.25_CD respectively_RB ,_, and_CC the_DT maximum_JJ C-rate_NN is_VBZ 6._CD Note_NN that_IN the_DT SOC_NN limits_NNS are_VBP soft_JJ constraints_NNS ,_, meaning_VVG they_PP can_MD be_VB exceeded_VVN if_IN this_DT is_VBZ deemed_VVN as_IN necessary_JJ ._SENT 
The_DT battery_NN needs_VVZ to_TO be_VB charged_VVN to_TO a_DT SOC_NN of_IN 0.9_CD prior_RB to_TO departure_NN ._SENT 
A_DT starting_VVG SOC_NN of_IN 0.90_CD affords_VVZ the_DT system_NN the_DT flexibility_NN to_TO excessive_JJ power_NN from_IN the_DT fuel_NN cells_NNS if_IN and_CC when_WRB required_VVN ._SENT 
SOC_NN below_IN 0.25_CD should_MD be_VB avoided_VVN to_TO provide_VV minimum_JJ charge_NN reservation_NN ,_, as_RB well_RB as_RB to_TO extend_VV battery_NN life_NN [_SYM 24_CD ]_SYM ._SENT 
<Section> 4._CD Reinforcement_NN learning_VVG based_VVN energy_NN management_NN system_NN </Section> This_DT section_NN formulates_VVZ the_DT optimal_JJ energy_NN management_NN problem_NN of_IN the_DT plug-in_NP hybrid_JJ PEMFC_NN and_CC battery_NN system_NN with_IN MDP_NN and_CC introduces_VVZ the_DT Double_NP Q_NP RL_NP agent_NN which_WDT will_MD be_VB applied_VVN to_TO solve_VV the_DT formulated_VVN MDP_NN ._SENT 
Table_NN 2_CD summaries_NNS the_DT RL_NP terminologies_NNS ,_, which_WDT will_MD be_VB used_VVN for_IN the_DT optimal_JJ energy_NN management_NN problem_NN in_IN the_DT subsequent_JJ sections_NNS ._SENT 
Note_NN that_IN a_DT policy_NN learned_VVN by_IN an_DT RL_NP agent_NN will_MD be_VB called_VVN as_IN the_DT energy_NN management_NN strategy_NN of_IN an_DT energy_NN management_NN system_NN ._SENT 
Table_NN 2._CD Summary_NN of_IN RL_NP terminologies_NNS in_IN the_DT optimal_JJ energy_NN management_NN problem_NN ._SENT 
Fig_NN ._SENT 
6_CD shows_NNS the_DT detailed_JJ MDP_NN agent-environment_NN interaction_NN framework_NN for_IN energy_NN management_NN problem_NN ._SENT 
The_DT environment_NN of_IN the_DT MDP_NN framework_NN includes_VVZ the_DT hybrid_JJ PEMFC_NN and_CC battery_NN system_NN model_NN and_CC historical_JJ voyage_NN data_NNS [_SYM 5_CD ]_SYM ._SENT 
Fig_NN ._SENT 
6._CD MDP_NN agent-environment_NN interaction_NN framework_NN ._SENT 
The_DT environment_NN of_IN the_DT framework_NN consists_VVZ of_IN the_DT hybrid_JJ PEMFC_NN and_CC battery_NN system_NN model_NN and_CC historical_JJ load_NN profiles_NNS collected_VVN via_IN continuous_JJ monitoring_NN ._SENT 
4.1_CD ._SENT 
Markov_NP decision_NN process_NN An_DT MDP_NN is_VBZ a_DT stochastic_JJ control_NN process_NN in_IN discrete_JJ time_NN space_NN ,_, which_WDT provides_VVZ a_DT mathematical_JJ framework_NN to_TO model_NN sequential-decision_NN making_VVG problems_NNS ._SENT 
Such_PDT a_DT process_NN can_MD be_VB represented_VVN by_IN a_DT tuple_NP S_NP ,_, A_NP ,_, P_NN ,_, R_NP ,_, where_WRB S_NP is_VBZ a_DT finite_JJ set_NN of_IN states_NNS ,_, A_DT is_VBZ a_DT finite_JJ set_NN of_IN actions_NNS ,_, P_NN is_VBZ the_DT state_NN transition_NN probability_NN ,_, i._NP e._NP Pss′_NP ,_, a=P[St+1=s′|St=s_NP ,_, At=a_NP ]_SYM ,_, and_CC r_NN is_VBZ a_DT reward_NN function_NN rss′_NN ,_, a=Ert+1|St=s_NP ,_, At=a_NP ._SENT 
The_DT action-value_JJ function_NN ,_, which_WDT is_VBZ also_RB called_VVN the_DT Q_NP function_NN ,_, for_IN an_DT episodic_JJ task_NN with_IN finite_JJ horizon_NN of_IN T_NN ,_, is_VBZ the_DT expected_VVN return_NN of_IN taking_VVG action_NN a_DT in_IN state_NN s_NNS following_VVG a_DT policy_NN π_NN :_: @（7）_NN Solving_VVG an_DT MDP_NN is_VBZ to_TO find_VV a_DT optimal_JJ policy_NN π∗_NN :_: @（8）_NN which_WDT leads_VVZ to_TO the_DT optimal_JJ action-value_JJ function_NN [_SYM 11_CD ]_SYM :_: @（9）_NN where_WRB γ∈[0,1_NN ]_SYM is_VBZ the_DT discount_NN rate_NN ._SENT 
As_IN shown_VVN in_IN Fig_NN ._SENT 
6_CD ,_, at_IN time_NN step_NN t_NN ,_, in_IN current_JJ state_NN st_NNS ,_, the_DT agent_NN takes_VVZ action_NN at_IN under_IN the_DT policy_NN π_NN ,_, and_CC observes_VVZ the_DT resulting_VVG next_JJ state_NN st+1_JJ and_CC immediate_JJ reward_NN rt+1_NN returned_VVN from_IN the_DT environment_NN ._SENT 
4.1.1_CD ._SENT 
States_NNS In_IN the_DT optimal_JJ energy_NN management_NN problem_NN ,_, the_DT states_NNS represent_VVP the_DT current_JJ system_NN status_NN ._SENT 
In_IN the_DT proposed_VVN system_NN ,_, such_JJ states_NNS are_VBP characterised_VVN by_IN shore_NN power_NN availability_NN ,_, spA_NP ,_, system_NN power_NN demand_NN ,_, Pdem_NP ,_, fuel_NN cell_NN power_NN level_JJ x∈[0,1_NN ]_SYM ,_, and_CC battery_NN SOC∈[0,1_NN ]_SYM ._SENT 
spA_NP is_VBZ binary_JJ ,_, i._NP e._NP spA=0_NP when_WRB the_DT ship_NN is_VBZ sailing_NN and_CC spA=1_NN when_WRB the_DT ship_NN is_VBZ in_IN port_NN ._SENT 
It_PP is_VBZ assumed_VVN that_IN the_DT transition_NN from_IN transit_NN to_TO port_NN can_MD be_VB done_VVN instantly_RB ,_, i._NP e._NP ,_, the_DT shore_NN power_NN is_VBZ immediately_RB available_JJ when_WRB the_DT ship_NN is_VBZ in_IN port_NN ._SENT 
Although_IN x_NN ,_, SOC_NP and_CC Pdem_NP are_VBP continuous_JJ physical_JJ parameters_NNS they_PP are_VBP however_RB divided_VVN into_IN discrete_JJ grids_NNS ._SENT 
Such_JJ that_IN the_DT gridded_VVD state_NN space_NN can_MD be_VB formulated_VVN by_IN looping_VVG through_IN all_DT possible_JJ state_NN combinations_NNS ._SENT 
As_IN each_DT of_IN the_DT state_NN parameters_NNS has_VHZ a_DT finite_JJ dimension_NN ,_, the_DT total_JJ number_NN of_IN states_NNS is_VBZ the_DT product_NN of_IN the_DT four_CD state_NN dimensions_NNS ._SENT 
Each_DT possible_JJ state_NN is_VBZ assigned_VVN with_IN a_DT unique_JJ state_NN index_NN sequentially_RB (_( i._NP e._NP from_IN 1_CD to_TO the_DT total_JJ number_NN of_IN states_NNS )_) ._SENT 
At_IN time_NN step_NN t_NN ,_, the_DT exact_JJ state_NN of_IN the_DT system_NN :_: @（10）_NP is_VBZ converted_VVN into_IN state_NN index_NN s(t_NP )_) ,_, which_WDT is_VBZ an_DT integer_NN ._SENT 
Note_NN that_IN the_DT environment_NN knows_VVZ the_DT actual_JJ state_NN sactual(t_NN )_) and_CC sactual(t+1_JJ )_) which_WDT results_VVZ from_IN taking_VVG action_NN a(t_NN )_) ,_, but_CC only_RB communicates_VVZ with_IN the_DT agent_NN using_VVG state_NN indices_NN ._SENT 
Such_PDT a_DT communication_NN format_NN is_VBZ designed_VVN intentionally_RB so_RB that_IN the_DT agent_NN can_MD record_VV the_DT learning_VVG process_NN into_IN tables_NNS ._SENT 
4.2_CD ._SENT 
Action_NN space_NN In_IN reinforcement_NN learning_NN ,_, the_DT agent_NN interacts_VVZ with_IN the_DT environment_NN by_IN taking_VVG actions_NNS in_IN various_JJ systems_NNS states_NNS ._SENT 
The_DT action_NN taken_VVN by_IN the_DT agent_NN is_VBZ the_DT control_NN of_IN fuel_NN cell_NN power_NN change_NN in_IN one_CD time_NN step_NN in_IN this_DT study_NN ._SENT 
The_DT action_NN space_NN is_VBZ defined_VVN as_IN a_DT tuple_NN of_IN possible_JJ fuel_NN cell_NN power_NN level_NN changes_NNS :_: @（11）_NN where_WRB a1_JJ <0 is the maximum decrease and an> 0_CD is_VBZ the_DT maximum_JJ increase_NN of_IN fuel_NN cell_NN power_NN output_NN in_IN a_DT time_NN step_NN ,_, am=0_NP indicates_VVZ fuel_NN cell_NN output_NN power_NN is_VBZ unchanged_JJ and_CC remains_VVZ constant_JJ ;_: all_DT other_JJ values_NNS of_IN a_DT represent_VVP changes_NNS of_IN power_NN within_IN the_DT range_NN of_IN a1_JJ ,_, an_DT ._SENT 
The_DT environment_NN overrides_VVZ an_DT action_NN when_WRB the_DT resulting_VVG fuel_NN cell_NN power_NN would_MD be_VB negative_JJ or_CC greater_JJR than_IN the_DT rated_VVN power_NN ._SENT 
When_WRB action_NN at∈A_NN is_VBZ chosen_VVN from_IN the_DT action_NN space_NN at_IN time_NN step_NN t_NN ,_, the_DT fuel_NN cell_NN power_NN level_NN at_IN t+1_NN will_MD be_VB :_: @（12）_NP 4.3_CD ._SENT 
Reward_VV The_DT environment_NN returns_VVZ reward_NN signal_NN rt+1_JJ to_TO the_DT agent_NN when_WRB action_NN at_IN is_VBZ taken_VVN by_IN the_DT agent_NN ._SENT 
The_DT value_NN of_IN rt+1_NN represents_VVZ how_WRB cost-effective_JJ at_IN is_VBZ at_IN state_NN st_NNS :_: @（13）_NN where_WRB the_DT negative_JJ reward_NN of_IN −1_JJ means_NNS the_DT agent_NN is_VBZ penalised_VVN if_IN the_DT next_JJ state_NN is_VBZ not_RB feasible_JJ or_CC fuel_NN cell_NN power_NN override_NN will_MD occur_VV ;_: the_DT tanh1costt+1_JJ function_NN normalises_VVZ the_DT cost_NN costt+1_JJ to_TO a_DT reward_NN signal_NN in_IN the_DT range_NN of_IN [_SYM 0,1_CD ]_SYM elsewhere_RB ._SENT 
Note_NN that_IN the_DT next_JJ state_NN is_VBZ not_RB feasible_JJ if_IN the_DT battery_NN is_VBZ over_RB charged/discharged_JJ or_CC C-rate_NN exceeds_VVZ the_DT system_NN limit_NN or_CC fuel_NN cell_NN power_NN is_VBZ not_RB reduced_VVN to_TO zero_VV when_WRB the_DT ship_NN is_VBZ in_IN port_NN (_( fuel_NN cells_NNS are_VBP not_RB switched_VVN off_RP to_TO avoid_VV unnecessary_JJ start/stop_NN cycling_NN degradations_NNS )_) ._SENT 
costt+1_JJ is_VBZ the_DT cost_NN incurred_VVN in_IN one_CD time_NN step_NN Δt_VVD due_JJ to_TO action_NN at_IN if_IN the_DT next_JJ state_NN is_VBZ feasible_JJ :_: @（14）_NP i._NP e._NP the_DT sum_NN of_IN H2_JJ cost_NN ,_, fuel_NN cell_NN degradation_NN cost_NN ,_, battery_NN average_NN degradation_NN cost_NN and_CC shore_VV power_NN cost_NN (_( only_RB when_WRB the_DT ship_NN is_VBZ in_IN port_NN )_) ,_, where_WRB σ_NN denotes_VVZ price_NN ._SENT 
The_DT sub-scripts_NP H2_NP ,_, fc_NP ,_, e_NN and_CC bat_NN denote_VVP H2_NN ,_, fuel_NN cell_NN ,_, electricity_NN and_CC battery_NN prices_NNS respectively_RB ._SENT 
Note_VV the_DT cost_NN costt+1_NN is_VBZ unpenalised_VVN since_IN the_DT negative_JJ reward_NN -1_CD includes_VVZ a_DT penalty_NN ._SENT 
To_TO better_RBR understand_VV the_DT impact_NN of_IN nonfeasible_JJ actions_NNS ,_, a_DT penalised_VVN cost_NN is_VBZ also_RB introduced_VVN in_IN the_DT following_VVG case_NN study_NN ._SENT 
The_DT penalised_VVN cost_NN is_VBZ costt+1+1_JJ whenever_WRB the_DT next_JJ state_NN is_VBZ not_RB feasible_JJ ,_, agent_NN action_NN is_VBZ overridden_VVN or_CC early_JJ termination_NN occurs_VVZ ._SENT 
4.4_CD ._SENT 
Double_JJ Q-learning_JJ agent_NN Q-learning_NN ,_, proposed_VVN by_IN Watkins_NP [_SYM 25_CD ]_SYM ,_, is_VBZ a_DT model-free_JJ approach_NN for_IN solving_VVG MDPs_NNS ,_, i._NP e._NP transition_NN probabilities_NNS P_NN are_VBP not_RB considered_VVN directly_RB during_IN agent_NN training_NN ._SENT 
It_PP is_VBZ also_RB an_DT off-policy_NP RL_NP method_NN ,_, i._NP e._NP the_DT action-values_NNS are_VBP updated_VVN using_VVG the_DT next_JJ state_NN and_CC the_DT greedy_JJ action_NN ._SENT 
When_WRB updating_VVG the_DT action-value_JJ function_NN ,_, the_DT agent_NN acts_VVZ greedily_RB by_IN choosing_VVG an_DT action_NN maximising_VVG the_DT next_JJ action-value_NN function_NN :_: @（15）_NN where_WRB s′_NN is_VBZ the_DT next_JJ state_NN ._SENT 
However_RB ,_, the_DT maximisation_NN operations_NNS involved_VVN in_IN the_DT construction_NN of_IN policy_NN and_CC the_DT ε-greedy_JJ action_NN selection_NN processes_NNS can_MD lead_VV to_TO poor_JJ learning_VVG performance_NN as_IN a_DT result_NN of_IN maximisation_NN bias_NN in_IN stochastic_JJ environments_NNS [_SYM 26_CD ]_SYM ._SENT 
This_DT study_NN takes_VVZ advantage_NN of_IN Double_NP Q-learning_NP (_( a_DT variant_NN of_IN Q-learning_NN )_) to_TO learn_VV optimal_JJ energy_NN management_NN policies_NNS for_IN the_DT sequential_JJ power_NN split_NN problem_NN between_IN multiple_JJ power_NN sources_NNS [_SYM 11_CD ]_SYM ._SENT 
Algorithm_NN 2_CD in_IN Appendix_NN A_DT shows_VVZ the_DT Double_NP Q-learning_JJ agent_NN [_SYM 27_CD ]_SYM ._SENT 
The_DT Double_NP Q_NP agent_NN reduces_VVZ the_DT maximisation_NN bias_NN by_IN using_VVG two_CD action-value_JJ estimates_NNS ,_, Q1_JJ and_CC Q2_JJ ._SENT 
For_IN each_DT update_NN ,_, with_IN 0.5_CD probability_NN ,_, Q2_NP is_VBZ used_VVN to_TO determine_VV maximising_VVG action_NN while_IN Q1_JJ updates_NNS its_PP$ value_NN :_: @（16）_JJ Otherwise_RB Q2_JJ is_VBZ updated_VVN with_IN Q1_JJ and_CC Q2_NP switched_VVD ._SENT 
Both_CC the_DT learning_VVG rate_NN α_NN and_CC ε_NN of_IN the_DT ε-greedy_JJ policy_NN decrease_NN linearly_RB with_IN the_DT increase_NN of_IN learning_VVG episodes_NNS ,_, and_CC stabilise_VVP at_IN fixed_VVN values_NNS after_IN rate_NN decaying_VVG episode_NN number_NN Nd_NN ._SENT 
4.5_CD ._SENT 
Environment_NN The_DT environment_NN of_IN the_DT reinforcement_NN learning_NN comprises_VVZ two_CD parts_NNS ,_, i._NP e._NP the_DT hybrid_JJ propulsion_NN system_NN model_NN [_SYM 19_CD ]_SYM and_CC historical_JJ power_NN profiles_NNS collected_VVD using_VVG continuous_JJ monitoring_NN of_IN operational_JJ power_NN demands_NNS [_SYM 5_CD ]_SYM ._SENT 
Algorithm_NN 1_CD depicts_VVZ how_WRB the_DT environment_NN of_IN the_DT optimal_JJ energy_NN management_NN problem_NN is_VBZ formulated_VVN ._SENT 
Using_VVG the_DT historical_JJ voyage_NN power_NN profiles_NNS ,_, in_IN each_DT learning_VVG episode_NN ,_, the_DT environment_NN randomly_RB samples_VVZ one_CD power_NN profile_NN from_IN the_DT historical_JJ data_NNS with_IN which_WDT the_DT agent_NN interacts_VVZ ._SENT 
Note_NN that_IN the_DT environment_NN would_MD carry_VV out_RP early_JJ termination_NN of_IN an_DT episode_NN if_IN the_DT agent_NN fully_RB discharges_VVZ the_DT battery_NN (_( SOC_NP <0) or over-charges the battery (SOC> 1_CD )_) ._SENT 
Normal_JJ termination_NN occurs_VVZ when_WRB the_DT final_JJ targeted_JJ time_NN step_NN has_VHZ been_VBN reached_VVN ._SENT 
An_DT episode_NN is_VBZ successful_JJ if_IN the_DT agent_NN manages_VVZ to_TO achieve_VV all_PDT the_DT required_VVN time_NN steps_NNS and_CC recharge_VV the_DT battery_NN to_TO a_DT SOC_NN of_IN SOCH_NP to_TO be_VB fully_RB prepared_VVN for_IN next_JJ voyage_NN ;_: otherwise_RB ,_, the_DT episode_NN terminates_VVZ and_CC is_VBZ recorded_VVN as_IN having_VHG failed_VVN ._SENT 
Algorithm_NN 1_CD Environment_NP of_IN the_DT optimal_JJ energy_NN management_NN problem_NN 4.6_CD ._SENT 
Agent_NN training_NN The_DT objective_NN of_IN the_DT on-line_JJ EMS_NP is_VBZ to_TO minimise_VV the_DT overall_JJ voyage_NN cost_NN in_IN an_DT environment_NN that_WDT is_VBZ not_RB pre-known_JJ ._SENT 
Such_PDT an_DT on-line_JJ EMS_NP is_VBZ intended_VVN to_TO manage_VV the_DT power_NN flows_VVZ within_IN the_DT hybrid_JJ power_NN system_NN effectively_RB for_IN future_JJ unknown_JJ voyages_NNS ._SENT 
The_DT learning_VVG process_NN is_VBZ an_DT episodic_JJ task_NN ._SENT 
In_IN each_DT episode_NN ,_, the_DT environment_NN randomly_RB samples_VVZ one_CD of_IN the_DT historical_JJ voyage_NN power_NN profiles_NNS for_IN the_DT agent_NN to_TO interact_VV with_IN to_TO learn_VV a_DT policy_NN minimising_VVG the_DT voyage_NN cost_NN ._SENT 
This_DT process_NN repeats_VVZ until_IN the_DT average_JJ episode_NN reward_NN converges_VVZ ._SENT 
Historical_JJ power_NN profiles_NNS need_VVP to_TO be_VB collected_VVN before_IN the_DT beginning_NN of_IN agent_NN training_NN procedure_NN ._SENT 
These_DT profiles_NNS will_MD be_VB an_DT inherent_JJ part_NN of_IN the_DT RL_NP environment_NN ._SENT 
Note_NN that_IN each_DT profile_NN is_VBZ unique_JJ although_IN there_EX are_VBP similarities_NNS ._SENT 
The_DT RL_NP agent_NN training_NN and_CC policy_NN application_NN follow_VV the_DT procedure_NN presented_VVN in_IN Fig_NN ._SENT 
7._CD Note_NN that_IN the_DT RL_NP training_NN parameters_NNS such_JJ as_IN the_DT learning_VVG rate_NN α_NN and_CC the_DT probability_NN of_IN exploration_NN ε_NN at_IN a_DT time_NN step_NN require_VVP careful_JJ tuning_VVG to_TO achieve_VV a_DT strategy_NN with_IN adequate_JJ performance_NN :_: •_NN the_DT agent_NN should_MD be_VB able_JJ to_TO complete_VV the_DT training_NN voyages_VVZ without_IN early_JJ terminations_NNS ._SENT 
•_JJ achieve_VVP minimum_JJ voyage_NN cost_NN with_IN minimum_JJ constraint_NN violations_NNS ._SENT 
Fig_NN ._SENT 
7._CD Reinforcement_NN learning_VVG agent_NN training_NN and_CC policy_NN application_NN procedure_NN ._SENT 
The_DT RL_NP EMS_NP is_VBZ acquired_VVN with_IN historical_JJ power_NN profiles_NNS ._SENT 
The_DT battery_NN over_IN discharge_NN protection_NN is_VBZ enabled_VVN in_IN the_DT application_NN phase_NN but_CC disabled_JJ during_IN training_NN ._SENT 
Once_RB the_DT training_NN is_VBZ converged_VVN ,_, the_DT learned_VVN policy_NN ,_, i._NP e._NP the_DT strategy_NN of_IN the_DT EMS_NP ,_, needs_VVZ to_TO be_VB validated_VVN using_VVG a_DT different_JJ set_NN of_IN power_NN profiles_NNS ._SENT 
In_IN the_DT application_NN phase_NN ,_, a_DT battery_NN over-discharge_NN protection_NN function_NN ensures_VVZ the_DT battery_NN modules_NNS are_VBP not_RB over-discharged_VVN ._SENT 
This_DT protection_NN mechanism_NN is_VBZ beyond_IN the_DT MDP_JJ agent-environment_NN interaction_NN framework_NN (_( Fig_NN ._SENT 
6_CD )_) and_CC is_VBZ not_RB functional_JJ during_IN agent_NN training_NN (_( see_VV Fig_NN ._SENT 
7_CD )_) ._SENT 
Such_JJ that_IN the_DT agent_NN can_MD learn_VV from_IN penalties_NNS during_IN training_NN without_IN external_JJ interventions_NNS ._SENT 
Actions_NNS leading_VVG to_TO penalties_NNS would_MD be_VB avoided_VVN due_RB to_TO their_PP$ lower_JJR Q_NP values_NNS in_IN corresponding_JJ states_NNS ._SENT 
<Section> 5._CD Agent_NP training_NN settings_NNS </Section> Table_NN 3_CD shows_NNS the_DT grids_NNS of_IN state_NN and_CC action_NN spaces_NNS for_IN both_CC the_DT Deterministic_JJ Dynamic_JJ Programming_NN (_( DDP_NP )_) strategy_NN (_( resolution_NN 1_CD )_) and_CC Double_NP Q_NP strategy_NN ._SENT 
Detailed_JJ agent_NN training_NN processes_NNS are_VBP presented_VVN in_IN Appendix_NN B._NP The_DT DDP_NN implementation_NN is_VBZ based_VVN upon_IN the_DT work_NN of_IN [_SYM 28_CD ]_SYM ._SENT 
The_DT results_NNS obtained_VVN via_IN DDP_NN are_VBP used_VVN to_TO evaluate_VV the_DT quality_NN of_IN the_DT strategy_NN generated_VVN by_IN the_DT Double_NP Q_NP agent_NN ._SENT 
Therefore_RB ,_, the_DT grids_NNS are_VBP defined_VVN the_DT same_JJ in_IN the_DT two_CD algorithms_NNS to_TO allow_VV a_DT fair_JJ comparison_NN between_IN on-line_JJ and_CC off-line_NN strategy_NN initially_RB ._SENT 
Note_NN that_IN developing_VVG a_DT strategy_NN by_IN DPP_NP requires_VVZ complete_JJ knowledge_NN of_IN the_DT profile_NN ,_, which_WDT is_VBZ not_RB possible_JJ for_IN actual_JJ applications_NNS ._SENT 
Therefore_RB DDP_NN strategy_NN is_VBZ only_RB valid_JJ as_IN an_DT off-line_NN benchmark_NN to_TO assess_VV the_DT performance_NN of_IN other_JJ on-line_JJ strategies_NNS ._SENT 
Table_NN 3._CD State_NN and_CC action_NN space_NN grids_NNS ._SENT 
To_TO further_RBR investigate_VV the_DT potential_NN for_IN cost_NN reduction_NN ,_, the_DT DDP_NP strategy_NN SOC_NN grid_NN length_NN was_VBD further_RBR refined_VVN to_TO 0.0125_CD ._SENT 
However_RB ,_, such_PDT a_DT refined_JJ SOC_NN resolution_NN was_VBD not_RB implemented_VVN in_IN Double_NP Q_NP strategy_NN due_JJ to_TO ‘_NN the_DT curse_NN of_IN dimensionality_NN ’_NP [_SYM 11_CD ]_SYM ,_, which_WDT would_MD make_VV the_DT problem_NN impossible_JJ to_TO solve_VV with_IN the_DT available_JJ computational_JJ resources_NNS ._SENT 
<Section> 6._CD Results_NNS </Section> 6.1_CD ._SENT 
Overview_NN of_IN results_NNS Table_NN 4_CD details_NNS the_DT two_CD different_JJ datasets_NNS which_WDT will_MD be_VB used_VVN in_IN this_DT section_NN ._SENT 
Dataset_NP A_NP is_VBZ used_VVN to_TO train_VV the_DT agent_NN to_TO generate_VV the_DT strategy_NN of_IN the_DT EMS_NP ._SENT 
Once_IN the_DT training_NN of_IN the_DT agent_NN has_VHZ converged_VVD ,_, the_DT strategy_NN is_VBZ verified_VVN by_IN removing_VVG the_DT random_JJ exploration_NN ε_NN adopted_VVN in_IN the_DT training_NN phase_NN ._SENT 
Subsequently_RB ,_, the_DT EMS_NP performance_NN is_VBZ validated_VVN using_VVG the_DT dataset_NP B_NP ,_, which_WDT have_VHP not_RB been_VBN applied_VVN to_TO the_DT agent_NN in_IN the_DT training_NN phase_NN ._SENT 
The_DT strategy_NN is_VBZ a_DT 4-dimensional_JJ action_NN map_NN over_IN the_DT four_CD state_NN parameters_NNS ._SENT 
With_IN the_DT system_NN state_NN observed_VVD ,_, the_DT optimal_JJ action_NN of_IN fuel_NN cell_NN power_NN control_NN can_MD then_RB be_VB found_VVN from_IN the_DT action_NN map_NN ._SENT 
Table_NN 4._CD Datasets_NNS of_IN load_NN profiles_NNS and_CC their_PP$ purposes_NNS ._SENT 
Dataset_NP A_NP is_VBZ used_VVN to_TO train_VV the_DT agent_NN to_TO generate_VV the_DT strategy_NN of_IN the_DT EMS_NP ._SENT 
The_DT EMS_NP is_VBZ then_RB applied_VVN to_TO load_VV profiles_NNS in_IN dataset_NP B_NP to_TO validate_VV the_DT EMS_NP performance_NN in_IN unseen_JJ voyages_NNS ._SENT 
To_TO verify_VV the_DT strategy_NN performance_NN learned_VVN by_IN the_DT Double_NP Q_NP learning_VVG agent_NN ,_, the_DT Double_NP Q_NP strategy_NN was_VBD applied_VVN directly_RB (_( without_IN any_DT exploration_NN )_) to_TO the_DT training_NN voyages_VVZ with_IN over-discharge_JJ protection_NN enabled_VVN ._SENT 
Such_PDT a_DT process_NN will_MD be_VB referred_VVN to_TO as_IN verification_NN in_IN the_DT following_VVG content_NN ._SENT 
Applying_VVG the_DT strategy_NN to_TO a_DT set_NN of_IN validation_NN voyages_NNS will_MD be_VB referred_VVN to_TO as_IN EMS_NP validation_NN ._SENT 
Table_NN 5_CD provides_VVZ a_DT summary_NN of_IN the_DT sample_NN voyages_VVZ with_IN low_JJ ,_, moderate_JJ and_CC high_JJ power_NN demands_NNS ,_, which_WDT will_MD be_VB discussed_VVN in_IN the_DT following_VVG analysis_NN ._SENT 
Table_NN 5._CD Summary_NN of_IN sample_NN voyages_NNS ._SENT 
As_IN depicted_VVN in_IN Table_NN 6_CD ,_, for_IN the_DT training_NN voyages_VVZ ,_, the_DT Double_NP Q_NP strategy_NN achieved_VVD 96.6_CD %_NN cost_NN minimisation_NN performance_NN of_IN the_DT off-line_NN strategy_NN solved_VVN by_IN DDP_NN (_( knowing_VVG complete_JJ profiles_NNS before_IN solving_VVG )_) ,_, both_CC with_IN the_DT SOC_NP grid_NN resolution_NN of_IN 0.05_CD ._SENT 
Note_NN that_IN state_NN space_NN resolution_NN also_RB limits_VVZ the_DT accuracy_NN of_IN DDP_NP [_SYM 29_CD ]_SYM ._SENT 
A_DT refined_JJ SOC_NN grid_NN resolution_NN of_IN 0.0125_CD yields_NNS an_DT average_JJ voyage_NN cost_NN of_IN $740.0_NN for_IN the_DT training_NN dataset_NN ._SENT 
The_DT Double_NP Q_NP strategy_NN achieves_VVZ 89.0_CD %_NN cost_NN minimisation_NN performance_NN of_IN the_DT refined_JJ DDP_NN solution_NN ._SENT 
For_IN the_DT validation_NN voyages_NNS ,_, similar_JJ performance_NN was_VBD achieved_VVN ._SENT 
The_DT DDP_JJ strategy_NN results_NNS presented_VVN in_IN following_VVG strategy_NN analysis_NN sections_NNS are_VBP all_RB solved_VVN with_IN SOC_NN resolution_NN of_IN 0.0125_CD ._SENT 
Table_NN 6._CD Double_NP Q_NP and_CC DDP_NP strategy_NN average_NN voyage_NN cost_NN comparison_NN ._SENT 
Fig_NN ._SENT 
8_CD presents_NNS the_DT voyage_NN cost_NN achieved_VVN by_IN the_DT Double_NP Q_NP strategy_NN in_IN comparison_NN with_IN that_DT solved_VVN via_IN DDP_NN ,_, for_IN the_DT training_NN (_( Fig_NN ._SENT 
8a_NP )_) and_CC validation_NN (_( Fig_NN ._SENT 
8b_NP )_) voyages_VVZ ._SENT 
The_DT Double_NP Q_NP strategy_NN has_VHZ achieved_VVN satisfactory_JJ cost_NN performance_NN (_( only_RB 3.2_CD %_NN higher_JJR than_IN DDP_NN strategy_NN )_) in_IN validation_NN voyages_NNS without_IN prior_JJ knowledge_NN of_IN future_JJ power_NN demands_NNS ._SENT 
Note_NN that_IN some_DT voyages_NNS in_IN the_DT training_NN dataset_NN have_VHP much_RB higher_JJR power_NN demands_NNS ,_, yielding_VVG a_DT maximum_JJ Double_NP Q_NP strategy_NN voyage_NN cost_NN close_NN to_TO $1600.0_NN ._SENT 
Fig_NN ._SENT 
8._CD Voyage_NN costs_NNS :_: (_( a_DT )_) training_NN voyages_NNS and_CC (_( b_LS )_) validation_NN voyages_NNS ._SENT 
The_DT DDP_NN costs_NNS are_VBP obtained_VVN with_IN a_DT SOC_NN resolution_NN of_IN 0.0125_CD ,_, while_IN it_PP is_VBZ 0.05_CD for_IN the_DT Double_NP Q_NP strategy_NN ._SENT 
6.2_CD ._SENT 
EMS_NP verification_NN In_IN this_DT section_NN ,_, the_DT Double_NP Q_NP agent_NN generated_VVD EMS_NP is_VBZ applied_VVN to_TO three_CD sample_NN voyages_NNS in_IN the_DT training_NN dataset_NN ._SENT 
The_DT three_CD sample_NN voyages_NNS are_VBP with_IN low_JJ ,_, moderate_JJ and_CC heavy_JJ power_NN demands_NNS ,_, respectively_RB ._SENT 
Details_NNS of_IN the_DT voyage_NN cost_NN and_CC emission_NN compositions_NNS are_VBP presented_VVN ._SENT 
Note_NN that_IN the_DT objective_NN of_IN the_DT EMS_NP is_VBZ to_TO minimise_VV voyage_NN costs_NNS ._SENT 
The_DT voyage_NN emissions_NNS are_VBP calculated_VVN via_IN electricity_NN usage_NN and_CC H2_JJ consumption_NN with_IN the_DT models_NNS presented_VVN in_RB [_SYM 19_CD ]_SYM ._SENT 
6.2.1_CD ._SENT 
Training_NN sample_NN 1_CD Fig_NN ._SENT 
9_CD shows_NNS the_DT DDP_NP and_CC Double_NP Q_NP strategies_NNS for_IN sample_NN verification_NN voyage_NN 1._CD This_DT voyage_NN has_VHZ comparatively_RB lower_JJR overall_JJ power_NN demands_NNS in_IN the_DT training_NN dataset_NN ._SENT 
It_PP starts_VVZ with_IN relatively_RB higher_JJR power_NN demands_NNS (_( 1600_CD kW_NNS )_) ._SENT 
During_IN cruising_VVG ,_, the_DT power_NN demand_NN stays_VVZ around_RB 1000_CD kW_NNS ._SENT 
Note_NN that_IN to_TO solve_VV for_IN the_DT DDP_NN strategy_NN requires_VVZ complete_JJ knowledge_NN of_IN the_DT power_NN profiles_NNS in_IN advance_NN ._SENT 
The_DT Double_NP Q_NP strategy_NN only_RB takes_VVZ actions_NNS in_IN each_DT time_NN step_NN by_IN observing_VVG current_JJ system_NN states_NNS ._SENT 
The_DT PEMFC_NP power_NN trajectory_NN in_IN the_DT DDP_NN strategy_NN (_( Fig_NN ._SENT 
9a_NP )_) is_VBZ relatively_RB smoother_JJR than_IN that_DT of_IN the_DT Double_NP Q_NP strategy_NN (_( Fig_NN ._SENT 
9b_NP )_) ._SENT 
The_DT Double_NP Q_NP strategy_NN tends_VVZ to_TO adjust_VV the_DT PEMFC_NN power_NN more_RBR frequently_RB within_IN a_DT narrow_JJ region_NN ,_, which_WDT could_MD be_VB due_JJ to_TO the_DT limited_JJ knowledge_NN of_IN future_JJ power_NN demands_NNS ._SENT 
Such_JJ behaviour_NN leads_VVZ to_TO higher_JJR PEMFC_NN degradation_NN and_CC H2_JJ costs_NNS (_( see_VV Table_NN 7_CD )_) ._SENT 
Also_RB ,_, the_DT Double_NP Q_NP strategy_NN rapidly_RB discharges_VVZ the_DT battery_NN SOC_NN to_TO 0.4_CD (_( at_IN 950_CD s_NNS )_) after_IN departure_NN and_CC then_RB gradually_RB recharges_VVZ the_DT battery_NN ._SENT 
In_IN contrast_NN ,_, the_DT minimum_JJ battery_NN SOC_NN in_IN the_DT DDP_NN strategy_NN is_VBZ 0.3_CD and_CC occurs_VVZ just_RB before_IN shore_NN charging_NN commences_VVZ (_( 2800_CD s_NNS )_) ._SENT 
Fig_NN ._SENT 
9._CD DDP_NP and_CC Double_NP Q_NP energy_NN management_NN strategies_NNS for_IN sample_NN training_NN voyage_NN 1_CD with_IN low_JJ power_NN demands_NNS :_: (_( a_DT )_) optimal_JJ off-line_NN strategy_NN solved_VVN by_IN DDP_NP ,_, (_( b_LS )_) on-line_JJ strategy_NN solved_VVN by_IN the_DT Double_NP Q_NP agent_NN ._SENT 
Table_NN 7._CD Double_NP Q_NP and_CC DDP_NP strategy_NN voyage_NN cost_NN and_CC GWP_NN emission_NN breakdown_NN of_IN training_NN sample_NN voyage_NN 1._CD Table_NN 7_CD details_NNS the_DT voyage_NN cost_NN and_CC emission_NN breakdowns_NNS of_IN the_DT sample_NN verification_NN voyage_NN 1._CD The_DT DDP_NN strategy_NN yields_NNS voyage_NN cost_NN of_IN $585.2_NP ,_, which_WDT is_VBZ 85.3_CD %_NN of_IN the_DT Double_NP Q_NP strategy_NN voyage_NN cost_NN ._SENT 
The_DT Double_NP Q_NP strategy_NN leads_VVZ to_TO higher_JJR costs_NNS from_IN PEMFC_NN degradation_NN and_CC H2_JJ consumption_NN ._SENT 
It_PP is_VBZ worth_JJ noting_VVG that_IN the_DT voyage_NN GWP_NN emission_NN of_IN the_DT DDP_NN strategy_NN is_VBZ 11.9_CD %_NN higher_JJR than_IN that_DT of_IN the_DT Double_NP Q_NP strategy_NN which_WDT is_VBZ due_JJ to_TO the_DT trade-off_NN between_IN voyage_NN cost_NN and_CC GWP_JJ emission_NN [_SYM 19_CD ]_SYM ._SENT 
6.2.2_CD ._SENT 
Training_NN sample_NN 2_CD Sample_NP voyage_NN 2_CD is_VBZ a_DT typical_JJ voyage_NN with_IN moderate_JJ power_NN demands_NNS in_IN the_DT training_NN dataset_NN ._SENT 
Fig_NN ._SENT 
10_CD compares_VVZ the_DT off-line_NN DDP_NN strategy_NN (_( Fig_NN ._SENT 
10a_NP )_) and_CC on-line_JJ Double_NP Q_NP strategy_NN (_( Fig_NN ._SENT 
10b_NP )_) for_IN this_DT voyage_NN ._SENT 
For_IN both_DT RL_NP and_CC DDP_NP strategies_NNS ,_, in_IN the_DT departure_NN phase_NN (_( 0–800_JJ s_NNS )_) ,_, the_DT batteries_NNS provide_VVP most_JJS of_IN the_DT power_NN from_IN the_DT beginning_NN ,_, while_IN the_DT fuel_NN cells_NNS come_VVN on_IN line_NN after_IN a_DT delay_NN ._SENT 
The_DT minimum_JJ SOC_NN of_IN the_DT DDP_JJ strategy_NN for_IN this_DT voyage_NN is_VBZ approximately_RB 0.25_CD (_( at_IN 2850_CD s_NNS )_) ._SENT 
As_IN the_DT RL_NP agent_NN does_VVZ not_RB exactly_RB know_VV the_DT future_JJ power_NN demands_NNS and_CC the_DT strategy_NN is_VBZ generic_JJ ,_, the_DT Double_NP Q_NP strategy_NN tends_VVZ to_TO adjust_VV fuel_NN cell_NN power_NN more_RBR frequently_RB ._SENT 
Also_RB ,_, the_DT fuel_NN cells_NNS delay_NN being_VBG switched_VVN to_TO idle_VV until_IN shore_NN power_NN is_VBZ available_JJ ,_, which_WDT is_VBZ because_IN the_DT agent_NN does_VVZ not_RB know_VV in_IN advance_NN if_IN shore_NN power_NN is_VBZ available_JJ ,_, and_CC the_DT environment_NN was_VBD designed_VVN to_TO force_VV the_DT fuel_NN cell_NN power_NN to_TO decrease_VV to_TO zero_VV only_RB after_IN shore_NN power_NN was_VBD being_VBG delivered_VVN ._SENT 
Note_NN that_IN ,_, because_IN the_DT ship_NN only_RB stays_VVZ in_IN port_NN for_IN a_DT short_JJ period_NN between_IN voyages_NNS ,_, the_DT batteries_NNS need_VVP to_TO be_VB charged_VVN at_IN high_JJ C-rates_NNS ,_, which_WDT could_MD pose_VV additional_JJ requirements_NNS on_IN the_DT charging_VVG infrastructure_NN ._SENT 
Fig_NN ._SENT 
10._CD DDP_NP and_CC Double_NP Q_NP energy_NN management_NN strategies_NNS for_IN sample_NN training_NN voyage_NN 2_CD with_IN moderate_JJ power_NN demands_NNS :_: (_( a_DT )_) optimal_JJ off-line_NN strategy_NN solved_VVN by_IN DDP_NP ,_, (_( b_LS )_) on-line_JJ strategy_NN solved_VVN by_IN the_DT Double_NP Q_NP agent_NN ._SENT 
Table_NN 8_CD depicts_VVZ the_DT cost_NN and_CC GWP_NN emission_NN breakdowns_NNS for_IN sample_NN voyage_NN 2_CD in_IN the_DT training_NN dataset_NN ._SENT 
The_DT Double_NP Q_NP strategy_NN achieves_VVZ 89.8_CD %_NN cost_NN performance_NN of_IN that_DT of_IN the_DT DDP_NN strategy_NN ._SENT 
Nevertheless_RB ,_, the_DT Double_NP Q_NP strategy_NN yields_NNS better_RBR GWP_JJ emission_NN performance_NN ,_, which_WDT has_VHZ also_RB been_VBN observed_VVN in_IN sample_NN voyage_NN 1_CD (_( Section_NP 6.2.1_CD )_) ._SENT 
The_DT H2_JJ costs_NNS account_VVP for_IN 55.4_CD %_NN and_CC 56.3_CD %_NN of_IN the_DT total_JJ voyage_NN costs_NNS for_IN the_DT DDP_NP and_CC Double_NP Q_NP strategies_NNS ,_, respectively_RB ._SENT 
PEMFC_NP degradation_NN costs_NNS are_VBP the_DT second_JJ highest_JJS cost_NN source_NN in_IN both_DT strategy_NN results_NNS ._SENT 
Table_NN 8._CD Double_NP Q_NP and_CC DDP_NP strategy_NN voyage_NN cost_NN and_CC GWP_NN emission_NN breakdown_NN of_IN training_NN sample_NN voyage_NN 2._CD 6.2.3_CD ._SENT 
Training_NN sample_NN 3_CD As_IN mentioned_VVN in_IN Section_NP 5_CD ,_, the_DT Double_NP Q_NP agent_NN failed_VVD to_TO provide_VV a_DT strategy_NN to_TO complete_VV the_DT voyage_NN in_IN less_JJR than_IN 0.5_CD %_NN of_IN the_DT training_NN voyages_VVZ as_IN a_DT consequence_NN of_IN final_JJ battery_NN SOC_NN constraint_NN being_VBG exceeded_VVN ._SENT 
When_WRB these_DT failed_JJ voyages_NNS were_VBD examined_VVN after_IN the_DT training_NN process_NN it_PP was_VBD noted_VVN that_IN they_PP had_VHD much_RB higher_JJR power_NN demands_NNS compared_VVN to_TO the_DT typical_JJ voyages_NNS in_IN the_DT training_NN dataset_NN ._SENT 
Fig_NN ._SENT 
11_CD presents_NNS a_DT sample_NN profile_NN when_WRB it_PP is_VBZ known_VVN that_IN the_DT ship_NN was_VBD heavily_RB laden_JJ (_( corresponds_VVZ the_DT voyage_NN with_IN maximum_JJ cost_NN in_IN Fig_NN ._SENT 
8a_NP )_) ,_, and_CC its_PP$ optimal_JJ EMS_NP solved_VVN via_IN DDP_NP (_( Fig_NN ._SENT 
11a_NP )_) ._SENT 
Unlike_IN the_DT profile_NN discussed_VVN in_IN Section_NP 6.2.2_CD ,_, the_DT fuel_NN cell_NN power_NN ramps_NNS up_RB immediately_RB after_IN departure_NN for_IN this_DT profile_NN ,_, in_IN contrast_NN to_TO the_DT more_RBR normal_JJ situation_NN where_WRB significant_JJ increase_NN in_IN fuel_NN cell_NN power_NN output_NN is_VBZ delayed_VVN as_IN shown_VVN in_IN a_DT typical_JJ profile_NN similar_JJ to_TO Fig_VV ._SENT 
10._CD Without_IN the_DT battery_NN over-discharge_NN protection_NN ,_, the_DT Double_NP Q_NP strategy_NN tends_VVZ to_TO discharge_VV the_DT battery_NN rapidly_RB to_TO a_DT SOC_NN below_IN 0.25_CD after_IN departure_NN from_IN the_DT port_NN ._SENT 
Fig_NN ._SENT 
11b_NP illustrates_VVZ how_WRB the_DT battery_NN over-discharge_NN protection_NN function_NN actuates_VVZ to_TO minimise_VV the_DT impact_NN and_CC shows_VVZ how_WRB such_PDT an_DT override_NN function_NN is_VBZ effective_JJ when_WRB tackling_VVG voyages_NNS with_IN very_RB high_JJ power_NN demands_NNS ._SENT 
Fig_NN ._SENT 
11._CD DDP_NP and_CC Double_NP Q_NP energy_NN management_NN strategies_NNS for_IN sample_NN training_NN voyage_NN 3_CD with_IN high_JJ power_NN demands_NNS :_: (_( a_DT )_) optimal_JJ off-line_NN strategy_NN solved_VVN by_IN DDP_NP ,_, (_( b_LS )_) on-line_JJ strategy_NN solved_VVN by_IN the_DT Double_NP Q_NP agent_NN ._SENT 
Table_NN 9_CD presents_VVZ a_DT detailed_JJ comparison_NN between_IN the_DT DDP_NP and_CC Double_NP Q_NP strategies_NNS in_IN terms_NNS of_IN voyage_NN cost_NN and_CC GWP_NN emissions_NNS ._SENT 
Such_PDT a_DT high_JJ power_NN profile_NN is_VBZ unusual_JJ in_IN the_DT training_NN dataset_NN ._SENT 
The_DT DDP_NN strategy_NN would_MD generate_VV a_DT voyage_NN cost_NN of_IN $1228.0_NP ,_, which_WDT is_VBZ 71.8_CD %_NN higher_JJR than_IN that_IN of_IN sample_NN voyage_NN 2_CD (_( discussed_VVN in_IN Section_NP 6.2.2_CD )_) ._SENT 
As_IN a_DT result_NN of_IN the_DT battery_NN over-discharge_NN protection_NN being_VBG triggered_VVN at_IN 450_CD s_NNS ,_, the_DT PEMFC_NP degradation_NN cost_NN of_IN the_DT Double_NP Q_NP strategy_NN is_VBZ less_JJR than_IN that_DT of_IN the_DT DDP_JJ strategy_NN as_IN frequent_JJ fuel_NN cell_NN power_NN adjustments_NNS have_VHP been_VBN avoided_VVN by_IN action_NN overrides_VVZ ._SENT 
However_RB ,_, the_DT Double_NP Q_NP strategy_NN outputs_NNS a_DT much_RB higher_JJR H2_NN cost_NN (_( 36_CD %_NN higher_JJR )_) ,_, which_WDT is_VBZ due_JJ to_TO the_DT PEMFC_NN being_VBG forced_VVN to_TO run_VV at_IN very_RB high_JJ load_NN regions_NNS where_WRB the_DT fuel_NN efficiency_NN is_VBZ reduced_VVN ._SENT 
Table_NN 9._CD Double_NP Q_NP and_CC DDP_NP strategy_NN voyage_NN cost_NN and_CC GWP_NN emission_NN breakdown_NN of_IN training_NN sample_NN voyage_NN 3._CD 6.3_CD ._SENT 
EMS_NP validation_NN As_IN the_DT EMS_NP has_VHZ been_VBN developed_VVN with_IN the_DT intent_NN to_TO achieve_VV minimum_JJ voyage_NN cost_NN for_IN un-predicted_JJ future_JJ voyages_NNS ,_, the_DT trained_JJ EMS_NP has_VHZ been_VBN validated_VVN by_IN a_DT set_NN of_IN power_NN profiles_NNS which_WDT have_VHP never_RB been_VBN included_VVN in_IN the_DT training_NN dataset_NN ._SENT 
6.3.1_CD ._SENT 
Validation_NN sample_NN 1_CD Fig_NN ._SENT 
12_CD shows_NNS the_DT comparison_NN between_IN the_DT DDP_NP and_CC Double_NP Q_NP strategies_NNS of_IN a_DT sample_NN validation_NN voyage_NN with_IN comparatively_RB lower_JJR power_NN demands_NNS ._SENT 
The_DT Double_NP Q_NP strategy_NN (_( Fig_NN ._SENT 
12b_NP )_) discharges_NNS the_DT battery_NN modules_NNS quickly_RB down_RB to_TO a_DT SOC_NN of_IN 0.4_CD in_IN the_DT first_JJ 1000_CD s_NNS ,_, and_CC maintains_VVZ the_DT fuel_NN cell_NN power_NN output_NN to_TO a_DT narrow_JJ region_NN during_IN sailing_NN ._SENT 
The_DT batteries_NNS satisfy_VV significant_JJ transients_NNS in_IN the_DT departing_VVG and_CC approaching_VVG phases_NNS ._SENT 
In_IN contrast_NN ,_, the_DT DDP_NN strategy_NN only_JJ discharges_NNS the_DT battery_NN rapidly_RB at_IN the_DT beginning_NN of_IN the_DT voyage_NN (_( 0–550_JJ s_NNS )_) ._SENT 
Similar_JJ trends_NNS have_VHP been_VBN observed_VVN in_IN the_DT sample_NN training_NN voyage_NN (_( Fig_NN ._SENT 
10_CD )_) ._SENT 
The_DT Double_NP Q_NP strategy_NN voyage_NN cost_NN is_VBZ 12.8_CD %_NN higher_JJR than_IN that_DT of_IN the_DT DDP_NN strategy_NN (_( Table_NN C.1_NN )_) ._SENT 
Nevertheless_RB ,_, the_DT Double_NP Q_NP strategy_NN performs_VVZ 10.1_CD %_NN better_JJR in_IN terms_NNS of_IN GWP_NN emission_NN ._SENT 
Such_PDT an_DT observation_NN reflects_VVZ the_DT trade-off_NN between_IN voyage_NN costs_NNS and_CC GWP_NN emissions_NNS ._SENT 
Note_NN that_IN similar_JJ observations_NNS have_VHP been_VBN found_VVN in_IN the_DT training_NN sample_NN voyages_VVZ (_( see_VV Section_NP 6.2.1_CD Training_NP sample_NN 1_CD ,_, 6.2.2_CD Training_NP sample_NN 2_CD )_) ._SENT 
Fig_NN ._SENT 
12._CD DDP_NP and_CC Double_NP Q_NP energy_NN management_NN strategies_NNS for_IN sample_NN validation_NN voyage_NN 1_CD with_IN low_JJ power_NN demands_NNS :_: (_( a_DT )_) optimal_JJ off-line_NN strategy_NN solved_VVN by_IN DDP_NP ,_, (_( b_LS )_) on-line_JJ strategy_NN solved_VVN by_IN the_DT Double_NP Q_NP agent_NN ._SENT 
6.3.2_CD ._SENT 
Validation_NN sample_NN 2_CD Fig_NN ._SENT 
13_CD presents_VVZ the_DT DDP_NP and_CC Double_NP Q_NP strategies_NNS of_IN a_DT sample_NN profile_NN with_IN moderate_JJ power_NN demands_NNS from_IN the_DT validation_NN dataset_NN ._SENT 
In_IN Fig_NN ._SENT 
13a_NP ,_, as_IN the_DT complete_JJ profile_NN is_VBZ known_VVN before_IN solving_VVG the_DT DDP_NN strategy_NN ,_, the_DT DDP_NN strategy_NN only_RB adjusts_VVZ PEMFC_NN power_NN output_NN when_WRB necessary_JJ ._SENT 
As_RB in_IN Fig_NN ._SENT 
13b_NP ,_, the_DT Double_NP Q_NP strategy_NN adjusts_VVZ PEMFC_NN power_NN more_RBR frequently_RB due_JJ to_TO uncertainty_NN regarding_VVG the_DT power_NN demands_NNS in_IN the_DT next_JJ time_NN steps_NNS ._SENT 
Such_PDT a_DT pattern_NN has_VHZ also_RB been_VBN observed_VVN in_IN the_DT first_JJ two_CD training_NN sample_NN profiles_NNS ._SENT 
The_DT Double_NP Q_NP strategy_NN voyage_NN cost_NN is_VBZ 11.2_CD %_NN higher_JJR than_IN that_DT of_IN the_DT DPP_NP strategy_NN ,_, which_WDT is_VBZ due_JJ to_TO frequent_JJ PEMFC_NN power_NN adjustments_NNS and_CC higher_JJR H2_JJ consumption_NN ._SENT 
Note_NN that_IN the_DT Double_NP Q_NP strategy_NN still_RB performs_VVZ better_JJR than_IN the_DT DDP_JJ strategy_NN in_IN terms_NNS of_IN GWP_JJ emissions_NNS (_( Table_NN C.2_NN )_) ._SENT 
Fig_NN ._SENT 
13._CD DDP_NP and_CC Double_NP Q_NP energy_NN management_NN strategies_NNS for_IN sample_NN validation_NN voyage_NN 2_CD with_IN moderate_JJ power_NN demands_NNS :_: (_( a_DT )_) optimal_JJ off-line_NN strategy_NN solved_VVN by_IN DDP_NP ,_, (_( b_LS )_) on-line_JJ strategy_NN solved_VVN by_IN the_DT Double_NP Q_NP agent_NN ._SENT 
6.3.3_CD ._SENT 
Validation_NN sample_NN 3_CD As_IN discussed_VVN in_IN Section_NP 6.2.3_CD ,_, the_DT RL_NP agent_NN failed_VVD in_IN training_NN voyages_NNS with_IN extremely_RB high_JJ power_NN demands_NNS ._SENT 
Nevertheless_RB ,_, the_DT Double_NP Q_NP strategy_NN managed_VVD to_TO complete_VV all_PDT the_DT validation_NN voyages_VVZ without_IN triggering_VVG the_DT battery_NN over-discharge_NN protection_NN function_NN ._SENT 
Fig_NN ._SENT 
14_CD compares_VVZ the_DT DDP_NP and_CC Double_NP Q_NP strategies_NNS ._SENT 
As_RB in_IN Fig_NN ._SENT 
14b_NP ,_, the_DT Double_NP Q_NP strategy_NN discharges_NNS the_DT battery_NN rapidly_RB to_TO a_DT SOC_NN of_IN 0.4_CD after_IN departure_NN with_IN a_DT delay_NN before_IN the_DT PEMFC_NN provides_VVZ any_DT power_NN output_NN ._SENT 
In_IN contrast_NN ,_, the_DT DDP_NN strategy_NN (_( Fig_NN ._SENT 
14a_NP )_) ramps_NNS the_DT PEMFC_NN output_NN immediately_RB at_IN departure_NN in_IN response_NN to_TO such_PDT a_DT high_JJ load_NN profile_NN ._SENT 
The_DT voyage_NN cost_NN of_IN the_DT DDP_NN strategy_NN is_VBZ 89.9_CD %_NN of_IN its_PP$ RL_NP counterpart_NN (_( Table_NN C.3_NN )_) ._SENT 
It_PP is_VBZ worth_JJ noting_VVG that_IN the_DT GWP_NN emissions_NNS produced_VVN by_IN the_DT two_CD strategies_NNS are_VBP very_RB close_JJ to_TO each_DT other_JJ (_( 0.7_CD %_NN difference_NN )_) ._SENT 
Although_IN the_DT Double_NP Q_NP strategy_NN consumes_VVZ more_JJR H2_NN than_IN the_DT DDP_NN strategy_NN ,_, it_PP requires_VVZ much_RB less_RBR shore_VV generated_VVN electricity_NN compared_VVN to_TO the_DT DDP_NN strategy_NN ._SENT 
Fig_NN ._SENT 
14._CD DDP_NP and_CC Double_NP Q_NP energy_NN management_NN strategies_NNS for_IN sample_NN validation_NN voyage_NN 3_CD with_IN high_JJ power_NN demands_NNS :_: (_( a_DT )_) optimal_JJ off-line_NN strategy_NN solved_VVN by_IN DDP_NP ,_, (_( b_LS )_) on-line_JJ strategy_NN solved_VVN by_IN the_DT Double_NP Q_NP agent_NN ._SENT 
6.4_CD ._SENT 
Summary_NN of_IN results_NNS Without_IN prior_JJ knowledge_NN of_IN future_JJ power_NN demands_NNS ,_, the_DT Double_NP Q_NP learning_NN based_VVN EMS_NP presented_VVN in_IN this_DT article_NN can_MD achieve_VV near-optimal_JJ cost_NN performance_NN (_( 96.9_CD %_NN )_) compared_VVN to_TO those_DT solved_VVN using_VVG DDP_NN with_IN the_DT same_JJ state_NN space_NN resolution_NN ._SENT 
Furthermore_RB ,_, the_DT Double_NP Q_NP strategy_NN has_VHZ achieved_VVN average_JJ costs_NNS which_WDT are_VBP 12.4_CD %_NN and_CC 12.5_CD %_NN higher_JJR than_IN that_DT of_IN the_DT refined_JJ DDP_NN strategy_NN across_IN training_NN and_CC validation_NN datasets_NNS ,_, respectively_RB ._SENT 
The_DT Double_NP Q_NP agent_NN presented_VVN in_IN this_DT article_NN can_MD achieve_VV near-optimal_JJ cost_NN performance_NN for_IN the_DT candidate_NN ship_NN in_IN a_DT stochastic_JJ environment_NN ._SENT 
Wu_NP et_NP al_NP ._SENT 
[_SYM 13_CD ]_SYM reported_VVD that_IN ,_, in_IN a_DT non-stochastic_JJ environment_NN with_IN a_DT single_JJ power_NN profile_NN ,_, their_PP$ Q_NP learning_NN agent_NN achieved_VVD a_DT fuel_NN cost_VVD 12.4_CD %_NN higher_JJR than_IN that_DT of_IN the_DT dynamic_JJ programming_NN strategy_NN in_IN their_PP$ road_NN vehicle-related_JJ study_NN ._SENT 
Consequently_RB ,_, the_DT proposed_VVN EMS_NP can_MD be_VB applied_VVN to_TO hybrid_JJ fuel_NN cell_NN and_CC battery_NN propulsion_NN system_NN ,_, providing_VVG reference_NN signals_NNS to_TO the_DT control_NN systems_NNS by_IN observing_VVG historical_JJ and_CC current_JJ power_NN demands_NNS ._SENT 
Although_IN the_DT objective_NN of_IN the_DT Double_NP Q_NP strategy_NN was_VBD designed_VVN to_TO minimise_VV voyage_NN costs_NNS ,_, due_JJ to_TO the_DT trade-off_NN between_IN costs_NNS and_CC GWP_NN emissions_NNS ,_, the_DT Double_NP Q_NP strategy_NN performs_VVZ even_RB better_JJR than_IN the_DT DDP_JJ strategy_NN in_IN terms_NNS of_IN GWP_JJ emissions_NNS (_( approximately_RB 6_CD %_NN less_JJR GWP_NN emissions_NNS for_IN both_DT training_NN and_CC validation_NN datasets_NNS )_) ._SENT 
More_RBR H2_JJ usage_NN would_MD result_VV in_IN higher_JJR voyage_NN costs_NNS but_CC lower_JJR GWP_NN emissions_NNS ._SENT 
<Section> 7._CD Conclusions_NNS </Section> This_DT work_NN has_VHZ formulated_VVN and_CC solved_VVN the_DT optimal_JJ energy_NN management_NN problem_NN of_IN plug-in_NP hybrid_JJ fuel_NN cell_NN and_CC battery_NN systems_NNS ,_, using_VVG the_DT novel_NN approach_NN of_IN Double_NP Q_NP reinforcement_NN learning_VVG to_TO achieve_VV near-optimal_JJ cost_NN performance_NN to_TO for_IN un-predicted_JJ future_JJ voyages_NNS ._SENT 
Using_VVG real_JJ ship_NN data_NNS collected_VVN from_IN the_DT candidate_NN ship_NN via_IN continuous_JJ monitoring_NN ,_, the_DT Double_NP Q_NP agent_NN has_VHZ been_VBN trained_VVN adequately_RB with_IN a_DT dataset_NN of_IN 1081_CD training_NN voyages_NNS and_CC subsequently_RB validated_VVD using_VVG another_DT dataset_NN of_IN 381_CD voyages_NNS collected_VVN over_IN a_DT separate_JJ time_NN period_NN ._SENT 
The_DT approach_NN is_VBZ novel_JJ and_CC can_MD be_VB adopted_VVN by_IN hybrid_JJ fuel_NN cell_NN and_CC battery_NN ships_NNS to_TO achieve_VV near-optimal_JJ use_NN of_IN the_DT energy_NN sources_NNS ._SENT 
The_DT results_NNS show_VVP that_IN the_DT Double_NP Q_NP agent_NN can_MD achieve_VV a_DT level_NN of_IN effectiveness_NN similar_JJ to_TO that_DT solved_VVN by_IN dynamic_JJ programming_NN with_IN the_DT identical_JJ settings_NNS in_IN state_NN and_CC action_NN spaces_NNS ._SENT 
Such_PDT a_DT similarity_NN indicate_VVP that_IN the_DT Double_NP Q_NP agent_NN is_VBZ effective_JJ in_IN dealing_VVG with_IN stochastic_JJ environments_NNS by_IN reducing_VVG maximisation_NN biases_NNS ._SENT 
Also_RB ,_, such_JJ performance_NN suggests_VVZ that_IN reinforcement_NN learning_NN is_VBZ a_DT viable_JJ approach_NN to_TO solve_VV the_DT optimal_JJ power_NN split_NN problem_NN in_IN a_DT hybrid_JJ propulsion_NN system_NN ,_, provided_VVD that_IN enough_JJ historical_JJ data_NNS has_VHZ been_VBN collected_VVN and_CC is_VBZ made_VVN available_JJ ._SENT 
In_IN contrast_NN ,_, the_DT Q_NP agent_NN which_WDT introduces_VVZ maximisation_NN biases_NNS fails_VVZ to_TO achieve_VV satisfactory_JJ performance_NN ,_, suggesting_VVG that_IN the_DT stochasticity_NN of_IN real-world_NN power_NN profiles_NNS needs_VVZ to_TO be_VB properly_RB addressed_VVN when_WRB developing_VVG energy_NN management_NN strategies_NNS using_VVG reinforcement_NN learning_NN ._SENT 
In_IN future_JJ work_NN ,_, the_DT gridded_VVD state_NN and_CC action_NN spaces_NNS will_MD be_VB extended_VVN to_TO continuous_JJ spaces_NNS with_IN deep_JJ neural_JJ networks_NNS as_IN function_NN approximators_NNS to_TO achieve_VV higher_JJR resolution_NN ._SENT 
<Section> CRediT_NN authorship_NN contribution_NN statement_NN </Section> Peng_NP Wu_NP :_: Conceptualization_NN ,_, Methodology_NN ,_, Software_NP ,_, Investigation_NP ,_, Validation_NN ,_, Formal_JJ analysis_NN ,_, Data_NP curation_NP ,_, Writing_VVG -_: original_JJ draft_NN ,_, Writing_VVG -_: review_NN &_CC editing_VVG ,_, Visualization_NN ._SENT 
Julius_NP Partridge_NP :_: Writing_NN -_: review_NN &_CC editing_VVG ,_, Formal_JJ analysis_NN ._SENT 
Richard_NP Bucknall_NP :_: Conceptualization_NN ,_, Resources_NP ,_, Writing_VVG -_: review_NN &_CC editing_VVG ,_, Resources_NP ,_, Supervision_NP ._SENT 
<Section> Declaration_NN of_IN Competing_VVG Interest_NN </Section> The_DT authors_NNS declare_VVP that_IN they_PP have_VHP no_RB known_VVN competing_VVG financial_JJ interests_NNS or_CC personal_JJ relationships_NNS that_WDT could_MD have_VH appeared_VVN to_TO influence_VV the_DT work_NN reported_VVD in_IN this_DT paper_NN ._SENT 
<Section> Acknowledgements_NNS </Section> The_DT authors_NNS thank_VVP Jens_NP Christian_NP Bjeldorf_NP and_CC Molslinje_NP A/S_NP for_IN approving_VVG using_VVG the_DT ship_NN data_NNS in_IN this_DT study_NN ._SENT 
The_DT authors_NNS are_VBP grateful_JJ to_TO Stig_NP Eriksen_NP and_CC his_PP$ colleagues_NNS for_IN collecting_VVG the_DT ship_NN data_NNS ._SENT 
The_DT authors_NNS are_VBP also_RB indebted_JJ to_TO Konrad_NP Yearwood_NP for_IN his_PP$ valuable_JJ critique_NN of_IN this_DT article_NN ._SENT 
<Section> Appendix_NN A._NP Double_NP Q_NP RL_NP agent_NN </Section> Algorithm_NN 2_CD Double_NP Q_NP RL_NP agent_NN [_SYM 27_CD ]_SYM Appendix_NN B._NP Agent_NP training_NN process_NN Table_NN B.1_NN shows_VVZ the_DT parameters_NNS used_VVN to_TO train_VV the_DT Double_NP Q_NP agent_NN ._SENT 
The_DT parameter_NN ε_NN represents_VVZ the_DT probability_NN of_IN exploration_NN at_IN a_DT time_NN step_NN ._SENT 
The_DT learning_VVG rate_NN α_NN determines_VVZ to_TO what_WP degree_NN the_DT temporal_JJ difference_NN is_VBZ acquired_VVN :_: α=1_JJ suggest_VVP that_IN only_RB the_DT most_RBS recent_JJ information_NN is_VBZ learned_VVN ,_, α=0_JJ nothing_NN new_JJ has_VHZ been_VBN learned_VVN ._SENT 
Both_DT α_NN and_CC ε_JJ decrease_NN linearly_RB from_IN their_PP$ initial_JJ values_NNS whilst_IN the_DT training_NN episode_NN number_NN is_VBZ less_JJR than_IN Ns_NN ._SENT 
Such_JJ settings_NNS reflect_VVP the_DT need_NN for_IN the_DT agent_NN to_TO explore_VV less_RBR frequently_RB and_CC learn_VV more_RBR cautiously_RB when_WRB enough_JJ experience_NN has_VHZ been_VBN gained_VVN ,_, whereas_IN more_RBR aggressive_JJ and_CC bold_JJ learning_VVG style_NN is_VBZ preferred_JJ at_IN the_DT beginning_NN to_TO quickly_RB gain_VV experience_NN ._SENT 
As_IN the_DT energy_NN management_NN problem_NN is_VBZ formulated_VVN with_IN an_DT average_JJ episode_NN length_NN of_IN 240_CD ,_, and_CC the_DT costs_NNS incurred_VVN in_IN all_DT steps_NNS are_VBP of_IN equal_JJ importance_NN ,_, the_DT discount_NN rate_NN γ_NN is_VBZ set_VVN at_IN 1_CD (_( i._NP e._NP un-discounted_VVD )_) ._SENT 
It_PP is_VBZ worth_JJ mentioning_VVG that_IN careful_JJ tuning_VVG of_IN these_DT parameters_NNS is_VBZ necessary_JJ to_TO balance_VV the_DT conflict_NN between_IN exploration_NN and_CC exploitation_NN [_SYM 11_CD ]_SYM ._SENT 
Table_NN B.1_NN ._SENT 
Reinforcement_NN learning_VVG parameters_NNS ._SENT 
Fig_NN ._SENT 
15_CD shows_NNS the_DT learning_VVG process_NN of_IN the_DT Double_NP Q_NP agent_NN ._SENT 
It_PP is_VBZ interesting_JJ that_IN the_DT mean_JJ episode_NN reward_NN decreases_VVZ to_TO -12_CD initially_RB (_( 0.6_CD ×_NN 105_CD episodes_NNS )_) ._SENT 
This_DT decrease_NN suggests_VVZ that_IN initially_RB a_DT divergent_JJ policy_NN was_VBD being_VBG learned_VVN before_IN the_DT agent_NN was_VBD able_JJ to_TO learn_VV towards_IN a_DT convergent_JJ policy_NN ._SENT 
The_DT training_NN was_VBD terminated_VVN after_IN 5_CD ×_NN 105_CD episodes_NNS (_( 4.8_CD h_NN on_IN an_DT Intel_NP i7-4790_JJ processor_NN using_VVG single_JJ thread_NN in_IN Matlab_NP 2019a_NP )_) ._SENT 
Fig_NN ._SENT 
15._CD Double_NP Q_NP agent_NN training_NN process_NN :_: (_( a_DT )_) average_JJ reward_NN ,_, (_( b_LS )_) maximum_JJ reward_NN ,_, (_( c_LS )_) average_NN penalised_VVN and_CC unpenalised_VVN costs_NNS and_CC (_( d_LS )_) average_JJ episode_NN steps_NNS of_IN every_DT 500_CD episodes_NNS ._SENT 
The_DT mean_JJ episode_NN reward_NN stabilised_VVD to_TO a_DT value_NN of_IN 88_CD after_IN about_RB 3_CD ×_NN 105_CD episodes_NNS of_IN training_NN (_( Fig_NN ._SENT 
15a_NP )_) ,_, while_IN the_DT maximum_JJ episode_NN reward_NN stabilised_VVN around_IN 120._CD Such_JJ stabilisation_NN suggests_VVZ that_IN the_DT algorithm_NN has_VHZ converged_VVD ._SENT 
The_DT average_JJ success_NN rates_NNS (_( see_VV Algorithm_NN 1_CD )_) were_VBD close_JJ to_TO 100_CD %_NN after_IN convergence_NN ._SENT 
Note_NN that_IN this_DT rate_NN is_VBZ not_RB exactly_RB 100_CD %_NN (_( Fig_NN ._SENT 
15b_NP )_) which_WDT is_VBZ mainly_RB due_JJ to_TO a_DT small_JJ exploration_NN probability_NN (_( 1.0_CD ×_NP 10−3_NP )_) that_WDT still_RB exists_VVZ and_CC a_DT minor_JJ fraction_NN of_IN training_NN voyages_NNS with_IN high_JJ power_NN demands_NNS vary_VVP significantly_RB from_IN other_JJ voyages_NNS ._SENT 
In_IN Fig_NN ._SENT 
15c_NP ,_, both_CC the_DT actual_JJ episode_NN cost_NN and_CC penalised_VVN episode_NN cost_NN increase_NN rapidly_RB in_IN the_DT first_JJ 1_CD ×_NN 105_CD episodes_NNS ._SENT 
The_DT reason_NN for_IN that_WDT is_VBZ early_JJ termination_NN frequently_RB occurs_VVZ and_CC at_IN the_DT initial_JJ stage_NN of_IN the_DT training_NN ._SENT 
In_IN other_JJ words_NNS ,_, the_DT agent_NN could_MD not_RB complete_VV most_JJS training_NN voyages_NNS in_IN the_DT initial_JJ stages_NNS of_IN training_NN (_( also_RB see_VV the_DT mean_JJ episode_NN steps_NNS in_IN Fig_NN ._SENT 
15d_NN )_) due_JJ to_TO the_DT policy’s_JJ tendency_NN to_TO drain_VV the_DT battery_NN aggressively_RB from_IN the_DT beginning_NN ._SENT 
As_IN the_DT training_NN goes_VVZ on_IN ,_, the_DT agent_NN managed_VVD to_TO complete_VV most_JJS of_IN the_DT training_NN voyages_VVZ from_IN 2_CD ×_NN 105_CD episodes_NNS onwards_RB ._SENT 
Also_RB ,_, the_DT average_JJ voyage_NN cost_NN starts_VVZ to_TO decrease_VV after_IN 2_CD ×_NN 105_CD episodes_NNS ._SENT 
The_DT actual_JJ cost_NN and_CC penalised_VVN cost_NN (_( including_VVG the_DT penalties_NNS caused_VVN by_IN exceeded_VVN constraints_NNS )_) overlap_VVP with_IN each_DT other_JJ ,_, suggesting_VVG infeasible_JJ actions_NNS have_VHP been_VBN reduced_VVN to_TO a_DT minimum_NN ._SENT 
In_IN summary_NN ,_, the_DT agent_NN appears_VVZ to_TO complete_VV voyages_NNS first_JJ ,_, then_RB learn_VVP to_TO minimise_VV voyages_NNS costs_NNS (_( maximum_JJ reward_NN )_) due_JJ to_TO the_DT reward_NN setup_NN ._SENT 
In_IN contrast_NN ,_, as_RB shown_VVN in_IN Appendix_NN Fig_NN ._SENT 
16_CD ,_, with_IN the_DT same_JJ hyperparameter_NN settings_NNS ,_, the_DT Q_NP agent_NN failed_VVD to_TO converge_VV to_TO a_DT policy_NN with_IN reasonable_JJ performance_NN ,_, owing_VVG to_TO the_DT presence_NN of_IN maximisation_NN biases_NNS throughout_IN the_DT learning_VVG process_NN (_( see_VV Eq_NP ._SENT 
15_CD )_) ._SENT 
These_DT biases_NNS cause_VVP over-estimation_NN of_IN action-value_JJ function_NN ,_, which_WDT leads_VVZ to_TO unstable_JJ trainings_NNS in_IN Q-learning_NN ._SENT 
The_DT Double_NP Q-learning_NP reduces_VVZ such_JJ biases_NNS by_IN using_VVG two_CD Q-functions_NNS ._SENT 
Fig_NN ._SENT 
16._CD Q_NP agent_NN training_NN process_NN :_: (_( a_DT )_) average_JJ reward_NN ,_, (_( b_LS )_) maximum_JJ reward_NN ,_, (_( c_LS )_) average_NN penalised_VVN and_CC unpenalised_VVN costs_NNS and_CC (_( d_LS )_) average_JJ episode_NN steps_NNS of_IN every_DT 500_CD episodes_NNS ._SENT 
The_DT Q_NP agent_NN failed_VVD to_TO converge_VV to_TO a_DT policy_NN with_IN reasonable_JJ cost_NN performance_NN and_CC the_DT constraints_NNS were_VBD violated_VVN frequently_RB in_IN late_JJ stage_NN of_IN training_NN ._SENT 
Note_NN that_IN the_DT environment_NN is_VBZ highly_RB stochastic_JJ ,_, a_DT small_JJ fraction_NN of_IN training_NN voyages_NNS with_IN high_JJ power_NN demands_NNS vary_VVP significantly_RB from_IN other_JJ voyages_NNS ;_: the_DT learned_VVN policy_NN fails_VVZ to_TO fulfil_VV the_DT final_JJ battery_NN SOC_NN constraint_NN of_IN SOC=SOCH_NP in_IN less_JJR than_IN 0.5_CD %_NN of_IN the_DT 1081_CD total_JJ training_NN voyages_NNS ._SENT 
This_DT failure_NN suggests_VVZ that_IN an_DT override_NN function_NN would_MD be_VB necessary_JJ to_TO make_VV the_DT learned_VVN policy_NN fully_RB compliant_JJ with_IN the_DT final_JJ battery_NN state_NN constraint_NN ._SENT 
A_DT battery_NN over-discharge_NN protection_NN ,_, as_RB in_IN Fig_NN ._SENT 
7_CD ,_, was_VBD proven_VVN to_TO be_VB effective_JJ ._SENT 
This_DT protection_NN is_VBZ realised_VVN by_IN forcing_VVG the_DT fuel_NN cell_NN power_NN to_TO increase_VV by_IN 5_CD %_NN of_IN rated_VVN power_NN in_IN one_CD time_NN step_NN when_WRB the_DT battery_NN SOC_NN drops_VVZ below_IN the_DT lower_JJR limit_NN (_( 0.25_CD )_) [_SYM 30_CD ]_SYM ._SENT 
Appendix_NN C._NP Cost_NN and_CC emission_NN breakdowns_NNS of_IN validation_NN sample_NN voyages_VVZ Table_NN C.1_NN ,_, Table_NN C.2_NN ,_, Table_NN C.3_NN ._SENT 
Table_NN C.1_NN ._SENT 
Double_JJ Q_NP and_CC DDP_NP strategy_NN voyage_NN cost_NN and_CC GWP_NN emission_NN breakdown_NN of_IN validation_NN sample_NN voyage_NN 1._CD Table_NN C.2_NN ._SENT 
Double_JJ Q_NP and_CC DDP_NP strategy_NN voyage_NN cost_NN and_CC GWP_NN emission_NN breakdown_NN of_IN validation_NN sample_NN voyage_NN 2._CD Table_NN C.3_NN ._SENT 
Double_JJ Q_NP and_CC DDP_NP strategy_NN voyage_NN cost_NN and_CC GWP_NN emission_NN breakdown_NN of_IN validation_NN sample_NN voyage_NN 3._CD <Section> References_NNS </Section> [_SYM 1_CD ]_SYM L._NP van_NP Biert_NP ,_, M._NP Godjevac_NP ,_, K._NP Visser_NP ,_, P._NP V._NP Aravind_VVD A_DT review_NN of_IN fuel_NN cell_NN systems_NNS for_IN maritime_JJ applications_NNS J_NP Power_NP Sources_NNS ,_, 327_CD (_( Supplement_VV C_NP )_) (_( 2016_CD )_) ,_, pp_NP ._SENT 
345-364_CD ,_, 10.1016/j_NP ._SENT 
jpowsour.2016.07.007_JJ ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 2_CD ]_SYM D._NP Larcher_NP ,_, J._NP -M_NP ._SENT 
Tarascon_NN Towards_IN greener_JJR and_CC more_JJR sustainable_JJ batteries_NNS for_IN electrical_JJ energy_NN storage_NN Nat_NP Chem_NP ,_, 7_CD (_( 1_LS )_) (_( 2015_CD )_) ,_, p._NP 19_CD ,_, 10.1038/nchem.2085_NP CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 3_CD ]_SYM P._NP Wu_NP ,_, R._NP Bucknall_NP On_IN the_DT design_NN of_IN plug-in_NP hybrid_JJ fuel_NN cell_NN and_CC lithium_NN battery_NN propulsion_NN systems_NNS for_IN coastal_JJ ships_NNS P._NP Kujala_NP ,_, L._NP Lu_NP (_( Eds_NPS ._SENT 
)_) ,_, 13th_JJ international_JJ marine_JJ design_NN conference_NN (_( IMDC_NP 2018_CD )_) ,_, vol_NP ._SENT 
2_LS ,_, CRC_NP Press/Balkema_NP ,_, London_NP (_( 2018_CD )_) ,_, pp_NP ._SENT 
941-951_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 4_CD ]_SYM J._NP J._NP de-Troya_NP ,_, C._NP Álvarez_NP ,_, C._NP Fernández-Garrido_NP ,_, L._NP Carral_NP Analysing_VVG the_DT possibilities_NNS of_IN using_VVG fuel_NN cells_NNS in_IN ships_NNS Int_NP J_NP Hydrogen_NN Energy_NP ,_, 41_CD (_( 4_LS )_) (_( 2016_CD )_) ,_, pp_NP ._SENT 
2853-2866_CD ,_, 10.1016/j_NP ._SENT 
ijhydene.2015.11.145_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 5_CD ]_SYM S._NP Eriksen_NP ,_, M._NP Lützen_NP ,_, J._NP B._NP Jensen_NP ,_, J._NP C._NP Sørensen_NP Improving_VVG the_DT energy_NN efficiency_NN of_IN ferries_NNS by_IN optimizing_VVG the_DT operational_JJ practices_NNS Proceedings_NNS of_IN the_DT full_JJ scale_NN ship_NN performance_NN conference_NN 2018_CD :_: The_DT Royal_NP Institution_NP of_IN Naval_NP Architects_NPS ,_, The_DT Royal_NP Institution_NP of_IN Naval_NP Architects_NPS (_( 2018_CD )_) ,_, pp_NP ._SENT 
101-111_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 6_CD ]_SYM N._NP Sulaiman_NP ,_, M._NP Hannan_NP ,_, A._NP Mohamed_NP ,_, E._NP Majlan_NP ,_, W._NP Wan_NP Daud_NP A_DT review_NN on_IN energy_NN management_NN system_NN for_IN fuel_NN cell_NN hybrid_JJ electric_JJ vehicle_NN :_: Issues_NNS and_CC challenges_NNS Renew_VV Sustain_VV Energy_NP Rev_NP ,_, 52_CD (_( 2015_CD )_) ,_, pp_NP ._SENT 
802-814_CD ,_, 10.1016/j_NP ._SENT 
rser.2015.07.132_NP ISSN_NP 1364-0321_CD ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 7_CD ]_SYM Y._NP Wang_NP ,_, Z._NP Sun_NP ,_, X._NP Li_NP ,_, X._NP Yang_NP ,_, Z._NP Chen_NP A_DT comparative_JJ study_NN of_IN power_NN allocation_NN strategies_NNS used_VVN in_IN fuel_NN cell_NN and_CC ultracapacitor_JJ hybrid_JJ systems_NNS Energy_NP ,_, 189_CD (_( 2019_CD )_) ,_, p._NP 116142_CD ,_, 10.1016/j_NP ._SENT 
energy.2019.116142_NP ArticleDownload_NP PDFGoogle_JJ Scholar_NN [_SYM 8_CD ]_SYM Y._NP Wang_NP ,_, X._NP Li_NP ,_, L._NP Wang_NP ,_, Z._NP Sun_NP Multiple-grained_VVD velocity_NN prediction_NN and_CC energy_NN management_NN strategy_NN for_IN hybrid_JJ propulsion_NN systems_NNS J_NP Energy_NP Storage_NP ,_, 26_CD (_( 2019_CD )_) ,_, p._NP 100950_CD ,_, 10.1016/j_NP ._SENT 
est.2019.100950_NP ArticleDownload_NP PDFGoogle_JJ Scholar_NN [_SYM 9_CD ]_SYM P._NP M._NP Muñoz_NP ,_, G._NP Correa_NP ,_, M._NP E._NP Gaudiano_NP ,_, D._NP Fernández_NP Energy_NP management_NN control_NN design_NN for_IN fuel_NN cell_NN hybrid_JJ electric_JJ vehicles_NNS using_VVG neural_JJ networks_NNS Int_NP J_NP Hydrogen_NN Energy_NP ,_, 42_CD (_( 48_CD )_) (_( 2017_CD )_) ,_, pp_NP ._SENT 
28932-28944_CD ,_, 10.1016/j_NP ._SENT 
ijhydene.2017.09.169_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 10_CD ]_SYM T._NP Fletcher_NP ,_, R._NP Thring_NP ,_, M._NP Watkinson_NP An_DT Energy_NP Management_NP Strategy_NP to_TO concurrently_RB optimise_VV fuel_NN consumption_NN &_CC PEM_NN fuel_NN cell_NN lifetime_NN in_IN a_DT hybrid_JJ vehicle_NN Int_NP J_NP Hydrogen_NN Energy_NP ,_, 41_CD (_( 46_CD )_) (_( 2016_CD )_) ,_, pp_NP ._SENT 
21503-21515_CD ,_, 10.1016/j_NP ._SENT 
ijhydene.2016.08.157_JJ ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 11_CD ]_SYM Sutton_NP RS_NP ,_, Barto_NP AG_NP ._SENT 
Reinforcement_NN learning_NN :_: An_DT introduction_NN ;_: 2018._CD Google_JJ Scholar_NN [_SYM 12_CD ]_SYM Y._NP Hu_NP ,_, W._NP Li_NP ,_, K._NP Xu_NP ,_, T._NP Zahid_NP ,_, F._NP Qin_NP ,_, C._NP Li_NP Energy_NP management_NN strategy_NN for_IN a_DT hybrid_JJ electric_JJ vehicle_NN based_VVN on_IN deep_JJ reinforcement_NN learning_VVG Appl_NP Sci_NP ,_, 8_CD (_( 2_LS )_) (_( 2018_CD )_) ,_, p._NP 187_CD ,_, 10.3390/app8020187_JJ CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 13_CD ]_SYM J._NP Wu_NP ,_, H._NP He_PP ,_, J._NP Peng_NP ,_, Y._NP Li_NP ,_, Z._NP Li_NP Continuous_JJ reinforcement_NN learning_VVG of_IN energy_NN management_NN with_IN deep_JJ Q_NP network_NN for_IN a_DT power_NN split_VVD hybrid_JJ electric_JJ bus_NN Appl_NP Energy_NP ,_, 222_CD (_( 2018_CD )_) ,_, pp_NP ._SENT 
799-811_CD ,_, 10.1016/j_NP ._SENT 
apenergy.2018.03.104_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 14_CD ]_SYM R._NP Xiong_NP ,_, J._NP Cao_NP ,_, Q._NP Yu_NP Reinforcement_NN learning-based_JJ real-time_JJ power_NN management_NN for_IN hybrid_JJ energy_NN storage_NN system_NN in_IN the_DT plug-in_NP hybrid_JJ electric_JJ vehicle_NN Appl_NP Energy_NP ,_, 211_CD (_( 2018_CD )_) ,_, pp_NP ._SENT 
538-548_CD ,_, 10.1016/j_NP ._SENT 
apenergy.2017.11.072_NP ISSN_NP 0306-2619_CD ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 15_CD ]_SYM M._NP Kalikatzarakis_NP ,_, R._NP Geertsma_NP ,_, E._NP Boonen_NP ,_, K._NP Visser_NP ,_, R._NP Negenborn_NP Ship_NP energy_NN management_NN for_IN hybrid_JJ propulsion_NN and_CC power_NN supply_NN with_IN shore_NN charging_VVG Contr_NP Eng_NP Pract_NP ,_, 76_CD (_( 2018_CD )_) ,_, pp_NP ._SENT 
133-154_CD ,_, 10.1016/j_NP ._SENT 
conengprac.2018.04.009_NP ISSN_NP 0967-0661_CD ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 16_CD ]_SYM A._NP M._NP Bassam_NP ,_, A._NP B._NP Phillips_NP ,_, S._NP R._NP Turnock_NP ,_, P._NP A._NP Wilson_NP Development_NP of_IN a_DT multi-scheme_NN energy_NN management_NN strategy_NN for_IN a_DT hybrid_JJ fuel_NN cell_NN driven_VVN passenger_NN ship_NN Int_NP J_NP Hydrogen_NN Energy_NP ,_, 42_CD (_( 1_LS )_) (_( 2017_CD )_) ,_, pp_NP ._SENT 
623-635_CD ,_, 10.1016/j_NP ._SENT 
ijhydene.2016.08.209_NP ISSN_NP 0360–3199_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 17_CD ]_SYM C._NP H._NP Choi_NP ,_, S._NP Yu_NP ,_, I._NP -S_NP ._SENT 
Han_NP ,_, B._NP -K_NP ._SENT 
Kho_NP ,_, D._NP -G_NP ._SENT 
Kang_NP ,_, H._NP Y._NP Lee_NP ,_, et_NP al_NP ._SENT 
Development_NN and_CC demonstration_NN of_IN PEM_NP fuel-cell-battery_NP hybrid_JJ system_NN for_IN propulsion_NN of_IN tourist_NN boat_NN Int_NP J_NP Hydrogen_NN Energy_NP ,_, 41_CD (_( 5_LS )_) (_( 2016_CD )_) ,_, pp_NP ._SENT 
3591-3599_CD ,_, 10.1016/j_NP ._SENT 
ijhydene.2015.12.186_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 18_CD ]_SYM J._NP Han_NP ,_, J._NP -F_NP ._SENT 
Charpentier_NP ,_, T._NP Tang_NP An_DT energy_NN management_NN system_NN of_IN a_DT fuel_NN cell/battery_NN hybrid_JJ boat_NN Energies_NNS ,_, 7_CD (_( 5_LS )_) (_( 2014_CD )_) ,_, p._NP 2799_CD ,_, 10.3390/en7052799_NP CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 19_CD ]_SYM P._NP Wu_NP ,_, R._NP Bucknall_NP Hybrid_JJ fuel_NN cell_NN and_CC battery_NN propulsion_NN system_NN modelling_VVG and_CC multi-objective_JJ optimisation_NN for_IN a_DT coastal_JJ ferry_NN Int_NP J_NP Hydrogen_NN Energy_NP ,_, 45_CD (_( 4_LS )_) (_( 2020_CD )_) ,_, pp_NP ._SENT 
3193-3208_CD ,_, 10.1016/j_NP ._SENT 
ijhydene.2019.11.152_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 20_CD ]_SYM H._NP Chen_NP ,_, P._NP Pei_NP ,_, M._NP Song_NP Lifetime_NN prediction_NN and_CC the_DT economic_JJ lifetime_NN of_IN proton_NN exchange_NN membrane_NN fuel_NN cells_NNS Appl_NP Energy_NP ,_, 142_CD (_( 2015_CD )_) ,_, pp_NP ._SENT 
154-163_CD ,_, 10.1016/j_NP ._SENT 
apenergy.2014.12.062_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 21_CD ]_SYM X._NP Hu_NP ,_, L._NP Johannesson_NP ,_, N._NP Murgovski_NP ,_, B._NP Egardt_NP Longevity-conscious_NP dimensioning_VVG and_CC power_NN management_NN of_IN the_DT hybrid_JJ energy_NN storage_NN system_NN in_IN a_DT fuel_NN cell_NN hybrid_JJ electric_JJ bus_NN Appl_NP Energy_NP ,_, 137_CD (_( 2015_CD )_) ,_, pp_NP ._SENT 
913-924_CD ,_, 10.1016/j_NP ._SENT 
apenergy.2014.05.013_NP ISSN_NP 0306-2619_CD ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 22_CD ]_SYM F._NP Zheng_NP ,_, Y._NP Xing_NP ,_, J._NP Jiang_NP ,_, B._NP Sun_NP ,_, J._NP Kim_NP ,_, M._NP Pecht_NP Influence_NN of_IN different_JJ open_JJ circuit_NN voltage_NN tests_NNS on_IN state_NN of_IN charge_NN online_JJ estimation_NN for_IN lithium-ion_NN batteries_NNS Appl_NP Energy_NP ,_, 183_CD (_( 2016_CD )_) ,_, pp_NP ._SENT 
513-525_CD ,_, 10.1016/j_NP ._SENT 
apenergy.2016.09.010_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 23_CD ]_SYM J._NP Kim_NP ,_, J._NP Shin_NP ,_, C._NP Chun_NP ,_, B._NP H._NP Cho_NP Stable_JJ configuration_NN of_IN a_DT li-ion_NN series_NN battery_NN pack_NN based_VVN on_IN a_DT screening_NN process_NN for_IN improved_VVN voltage/SOC_NN balancing_VVG IEEE_NP Trans_NP Power_NP Electron_NP ,_, 27_CD (_( 1_LS )_) (_( 2012_CD )_) ,_, pp_NP ._SENT 
411-424_CD ,_, 10.1109/TPEL.2011.2158553_NP ISSN_NP 0885–8993_NP CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 24_CD ]_SYM N._NP Omar_NP ,_, M._NP A._NP Monem_NP ,_, Y._NP Firouz_NP ,_, J._NP Salminen_NP ,_, J._NP Smekens_NP ,_, O._NP Hegazy_NP ,_, et_NP al_NP ._SENT 
Lithium_NN iron_NN phosphate_NN based_VVN battery–assessment_NN of_IN the_DT aging_VVG parameters_NNS and_CC development_NN of_IN cycle_NN life_NN model_NN Appl_NP Energy_NP ,_, 113_CD (_( 2014_CD )_) ,_, pp_NP ._SENT 
1575-1585_CD ,_, 10.1016/j_NP ._SENT 
apenergy.2013.09.003_NP ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 25_CD ]_SYM C._NP J._NP C._NP H._NP Watkins_NP Learning_NP from_IN delayed_JJ rewards_NNS Ph._NP D._NP thesis_NN King’s_NP College_NP ,_, Cambridge_NP (_( 1989_CD )_) Google_JJ Scholar_NN [_SYM 26_CD ]_SYM van_NP Hasselt_NP H_NP ,_, Guez_NP A_NP ,_, Silver_NP D._NP Deep_NP Reinforcement_NN Learning_NP with_IN Double_NP Q-learning_NP ;_: 2015._CD Google_JJ Scholar_NN [_SYM 27_CD ]_SYM van_NP Hasselt_NP H._NP Double_NP Q-learning_NP ._SENT 
In_RB :_: Lafferty_NP JD_NP ,_, Williams_NP CKI_NP ,_, Shawe-Taylor_NP J_NP ,_, Zemel_NP RS_NP ,_, Culotta_NP A_NP ,_, editors_NNS ._SENT 
Advances_NNS in_IN neural_JJ information_NN processing_NN systems_NNS ,_, vol_NP ._SENT 
23._CD Curran_NP Associates_NNS Inc_NP ;_: 2010._CD p._NN 2613–21_NN ._SENT 
Google_JJ Scholar_NN [_SYM 28_CD ]_SYM O._NP Sundström_NP ,_, D._NP Ambühl_NP ,_, L._NP Guzzella_NP On_IN implementation_NN of_IN dynamic_JJ programming_NN for_IN optimal_JJ control_NN problems_NNS with_IN final_JJ state_NN constraints_NNS Oil_NP Gas_NP Sci_NP Technol-Revue_NP de_NP l’Institut_NP Français_NP du_NP Pétrole_NP ,_, 65_CD (_( 1_LS )_) (_( 2010_CD )_) ,_, pp_NP ._SENT 
91-102_CD ,_, 10.2516/ogst/2009020_NP CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 29_CD ]_SYM X._NP Wang_NP ,_, H._NP He_PP ,_, F._NP Sun_NP ,_, J._NP Zhang_NP Application_NN study_NN on_IN the_DT dynamic_JJ programming_NN algorithm_NN for_IN energy_NN management_NN of_IN plug-in_NP hybrid_JJ electric_JJ vehicles_NNS Energies_NNS ,_, 8_CD (_( 4_LS )_) (_( 2015_CD )_) ,_, pp_NP ._SENT 
3225-3244_CD ,_, 10.3390/en8043225_NP CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 30_CD ]_SYM M._NP Rouholamini_NP ,_, M._NP Mohammadian_NP Heuristic-based_JJ power_NN management_NN of_IN a_DT grid-connected_JJ hybrid_JJ energy_NN system_NN combined_VVN with_IN hydrogen_NN storage_NN Renew_VV Energy_NP ,_, 96_CD (_( 2016_CD )_) ,_, pp_NP ._SENT 
354-365_CD ,_, 10.1016/j_NP ._SENT 
renene.2016.04.085_NP 