<title> Recognition_NN of_IN ships_NNS based_VVN on_IN vector_NN sensor_NN and_CC bidirectional_JJ long_JJ short-term_JJ memory_NN networks_NNS </title> <author> Li_NP ,_, SC_NP (_( Li_NP ,_, Sichun)[_NP 1,2,3_CD ]_SYM ;_: Yang_NP ,_, SY_NP (_( Yang_NP ,_, Shuyu)[_NP 1,2,3_CD ]_SYM ;_: Liang_NP ,_, JH_NP (_( Liang_NP ,_, Jinghan)[_NP 1,2,3_CD ]_SYM </author> <Affiliation> [_SYM 1_CD ]‎_NP Harbin_NP Engn_NP Univ_NP ,_, Acoust_NP Sci_NP &_CC Technol_NN Lab_NP ,_, Harbin_NP 150001_CD ,_, Peoples_NP R_NP China_NP [_SYM 2_CD ]‎_NP Harbin_NP Engn_NP Univ_NP ,_, Minist_NP Ind_NP &_CC Informat_NP Technol_NN ,_, Key_NP Lab_NP Marine_NP Informat_NP Acquisit_NP &_CC Secur_NP ,_, Harbin_NP 150001_CD ,_, Peoples_NP R_NP China_NP [_SYM 3_CD ]‎_NP Harbin_NP Engn_NP Univ_NP ,_, Coll_NP Underwater_JJ Acoust_NP Engn_NN ,_, Harbin_NP 150001_CD ,_, Peoples_NP R_NP China_NP </Affiliation> <year> 2020_CD </year> <Jounral> Applied_NP Acoustics_NN </Journal> <Publishing_house> ELSEVIER_NP SCI_NP LTD_NP ,_, THE_DT BOULEVARD_NN ,_, LANGFORD_NP LANE_NN ,_, KIDLINGTON_NP ,_, OXFORD_NP OX5_NP 1GB_NP ,_, OXON_NP ,_, ENGLAND_NP </Publishing_house> <Text_Collector> Wang_NP Shuaiyin，HEU_NP </Text_Collector> <DOI> 10.1016/j_NP ._SENT 
apacoust.2020.107248_JJ </DOI> <URL> https_NNS :_: //www-sciencedirect-com-443_NN ._SENT 
wvpn_NP ._SENT 
hrbeu_NP ._SENT 
edu_NP ._SENT 
cn/science/article/pii/S0003682X19310096_NP ?_SENT 
via%3Dihub_NP </URL> <Section> ABSTRAC_NP </Section> The_DT previous_JJ methods_NNS of_IN target_NN recognition_NN use_NN feature_NN parameters_NNS as_IN the_DT system_NN input_NN ._SENT 
Especially_RB in_IN a_DT better_RBR acoustic_JJ field_NN ,_, a_DT higher_JJR recognition_NN rate_NN can_MD be_VB obtained_VVN under_IN the_DT condition_NN of_IN obvious_JJ target_NN features_NNS ._SENT 
But_CC actually_RB ,_, the_DT acoustic_JJ field_NN is_VBZ complex_JJ due_RB to_TO the_DT multipath_NN effect_NN ,_, the_DT time-varying_VVG channel_NN characteristics_NNS ,_, the_DT variety_NN and_CC complexity_NN of_IN environmental_JJ background_NN noise_NN and_CC other_JJ factors_NNS ,_, which_WDT leads_VVZ to_TO a_DT difficulty_NN in_IN feature_NN extraction_NN ._SENT 
In_IN this_DT paper_NN ,_, a_DT method_NN named_VVN bi-LSTM_NP is_VBZ described_VVN and_CC firstly_RB used_VVN in_IN the_DT field_NN of_IN underwater_JJ acoustic_JJ to_TO recognize_VV ships_NNS without_IN pre-extracting_VVG feature_NN based_VVN on_IN vector_NN sensor_NN ._SENT 
Then_RB we_PP compared_VVD bi-LSTM_NP and_CC LSTM_NP with_IN SVM_NP and_CC the_DT impact_NN on_IN the_DT recognition_NN rate_NN with_IN some_DT parameters_NNS ._SENT 
Experimental_JJ results_NNS of_IN sea_NN trial_NN are_VBP given_VVN to_TO demonstrate_VV the_DT robust_JJ adaptation_NN ._SENT 
The_DT accuracy_NN of_IN both_DT bi-LSTM_NN and_CC LSTM_NN are_VBP higher_JJR than_IN SVM_NP and_CC the_DT accuracy_NN of_IN bi-LSTM_NN is_VBZ higher_JJR than_IN LSTM_NN with_IN a_DT long_JJ training_NN time_NN ._SENT 
The_DT recognition_NN result_NN of_IN testing_NN set_NN can_MD be_VB received_VVN in_IN few_JJ seconds_NNS which_WDT proves_VVZ the_DT real-time_JJ of_IN the_DT method_NN ._SENT 
Keywords_NNS :_: Bidirectional_JJ long_JJ short-term_JJ memory_NN networks；Vector_NN sensor；Target_NN recognition；Deep_NNS learning_VVG <Section> 1._CD Introduction_NN </Section> Target_NP recognition_NN is_VBZ divided_VVN into_IN two_CD kinds_NNS :_: active_JJ recognition_NN and_CC passive_JJ recognition_NN ._SENT 
Passive_JJ target_NN recognition_NN is_VBZ a_DT method_NN which_WDT classifies_VVZ targets_NNS through_IN the_DT radiated_VVN noise_NN received_VVN by_IN human_JJ or_CC machine_NN ._SENT 
At_IN present_NN ,_, how_WRB to_TO recognize_VV the_DT targets_NNS in_IN a_DT more_RBR effective_JJ and_CC accurate_JJ way_NN remains_VVZ difficult_JJ in_IN target_NN recognition_NN technology_NN ._SENT 
The_DT basic_JJ process_NN of_IN target_NN recognition_NN is_VBZ to_TO pre-process_VV the_DT received_VVN data_NNS ,_, extract_VV and_CC select_VV the_DT features_NNS in_IN time_NN domain_NN ,_, frequency_NN domain_NN ,_, auditory_JJ domain_NN ,_, image_NN ,_, etc_FW of_IN the_DT pre-processed_JJ data_NNS ,_, and_CC finally_RB get_VV the_DT target_NN recognition_NN results_NNS through_IN learning_VVG algorithm_NN and_CC classifier_NN ._SENT 
Feature_NN extraction_NN usually_RB loses_VVZ a_DT part_NN of_IN the_DT key_JJ information_NN inevitably_RB ._SENT 
If_IN the_DT original_JJ received_VVN information_NN can_MD be_VB used_VVN for_IN recognition_NN ,_, the_DT information_NN loss_NN caused_VVN by_IN feature_NN extraction_NN can_MD be_VB avoided_VVN to_TO a_DT certain_JJ extent_NN ._SENT 
The_DT target_NN recognition_NN based_VVN on_IN deep_JJ learning_NN can_MD directly_RB input_NN a_DT large_JJ amount_NN of_IN raw_JJ data_NNS received_VVN into_IN the_DT deep_JJ neural_JJ network_NN for_IN learning_VVG and_CC training_NN ,_, which_WDT avoid_VVP the_DT loss_NN of_IN information_NN caused_VVN by_IN feature_NN extraction_NN to_TO achieve_VV target_NN classification_NN and_CC recognition_NN ._SENT 
Long_JJ short-term_JJ memory_NN (_( LSTM_NP )_) [_SYM 1_CD ]_SYM networks_NNS ensure_VV the_DT output_NN of_IN each_DT moment_NN correlates_VVZ with_IN the_DT previous_JJ and_CC the_DT gradient_NN does_VVZ not_RB disappear_VV or_CC explode_VV after_IN a_DT long_JJ time_NN of_IN transmission_NN [_SYM 2_CD ]_SYM ,_, [_SYM 3_CD ]_SYM ._SENT 
LSTM_NP has_VHZ been_VBN successful_JJ in_IN many_JJ recent_JJ applications_NNS such_JJ as_IN video_JJ classification_NN [_SYM 4_CD ]_SYM ,_, language_NN modeling_NN [_SYM 5_CD ]_SYM ,_, [_SYM 6_CD ]_SYM ,_, acoustic_JJ modeling_NN [_SYM 7_CD ]_SYM ,_, [_SYM 8_CD ]_SYM ,_, [_SYM 9_CD ]_SYM and_CC so_RB on_IN ._SENT 
Zhang_NP X_NP and_CC Zou_NP ZX_NP ,_, etc_FW propose_VV a_DT two-level_JJ structure_NN with_IN LSTM_NN network_NN to_TO eliminate_VV noise_NN interference_NN and_CC detect_VV rail_NN crack_VV signal_NN [_SYM 10_CD ]_SYM ._SENT 
Ertam_NP F_NP predicts_VVZ the_DT gender_NN from_IN an_DT audio_JJ data_NNS set_VVN through_IN deeper_JJR LSTM_NP Networks_NPS structure_NN [_SYM 11_CD ]_SYM ._SENT 
Ibrahim_NP AK_NP and_CC Zhang_NP H_NP use_NN wavelet_NN denoising_VVG to_TO reduce_VV ambient_JJ ocean_NN noise_NN ,_, and_CC a_DT deep_JJ neural_JJ network_NN to_TO classify_VV sounds_NNS generated_VVN by_IN different_JJ species_NNS of_IN groupers_NNS [_SYM 12_CD ]_SYM ._SENT 
Unlike_IN LSTM_NN networks_NNS ,_, bidirectional_JJ long_JJ short-term_JJ memory_NN (_( bi-LSTM_NP )_) [_SYM 13_CD ]_SYM networks_NNS has_VHZ a_DT backward_RB layer_NN ,_, so_RB that_IN the_DT output_NN of_IN each_DT time_NN is_VBZ related_VVN not_RB only_RB to_TO the_DT output_NN of_IN the_DT previous_JJ time_NN ,_, but_CC also_RB to_TO the_DT output_NN of_IN the_DT subsequent_JJ time_NN ._SENT 
Bi-LSTM_NP is_VBZ mostly_RB used_VVN in_IN detection_NN [_SYM 14_CD ]_SYM and_CC information_NN fusion_NN [_SYM 15_CD ]_SYM ,_, but_CC there_EX are_VBP few_JJ researches_VVZ on_IN recognition_NN at_IN present_NN ._SENT 
Zhang_NP X_NP and_CC Miao_NP Z_NP introduce_VV bi-LSTM_NN for_IN automatic_JJ generation_NN of_IN Labanotation_NN from_IN motion_NN capture_NN data_NNS by_IN identifying_VVG human_JJ movements_NNS and_CC the_DT experiment_NN results_NNS show_VVP that_IN this_DT method_NN outperforms_VVZ state-of-the-art_JJ methods_NNS ,_, demonstrating_VVG its_PP$ effectiveness_NN [_SYM 16_CD ]_SYM ._SENT 
In_IN this_DT paper_NN ,_, we_PP discuss_VVP the_DT recognition_NN of_IN ships_NNS based_VVN on_IN vector_NN sensor_NN and_CC bi-LSTM_NN networks_NNS ,_, which_WDT compared_VVN with_IN LSTM_NN networks_NNS ._SENT 
<Section> 2._CD Structure_NN and_CC model_NN establishment_NN of_IN bi-LSTM_NP </Section> LSTM_NP networks_NNS are_VBP an_DT improvement_NN of_IN RNNs_NNS in_IN vanishing_VVG gradients_NNS ._SENT 
[_SYM 17_CD ]_SYM A_DT RNN_NP network_NN architecture_NN is_VBZ shown_VVN in_IN Fig_NN ._SENT 
1._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 116KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
1._CD A_NP RNN_NP network_NN architecture_NN ._SENT 
The_DT difference_NN between_IN LSTM_NN networks_NNS and_CC RNNs_NNS is_VBZ that_IN the_DT hidden_JJ nodes_NNS h(t_NN )_) in_IN RNNs_NNS are_VBP replaced_VVN by_IN memory_NN blocks_NNS in_IN LSTM_NN networks_NNS ._SENT 
A_DT memory_NN block_NN architecture_NN [_SYM 1_CD ]_SYM ,_, [_SYM 18_CD ]_SYM ,_, [_SYM 19_CD ]_SYM ,_, [_SYM 20_CD ]_SYM consists_VVZ of_IN one_CD or_CC more_JJR memory_NN cell_NN ,_, one_CD input_NN squashing_VVG unit_NN ,_, one_CD input_NN gating_VVG unit_NN ,_, one_CD input_NN gate_NN unit_NN ,_, one_CD output_NN gate_NN unit_NN ,_, one_CD output_NN squashing_VVG unit_NN ,_, one_CD output_NN gating_VVG unit_NN and_CC one_PP forget_VVP gate_NN unit_NN ,_, shown_VVN in_IN Fig_NN ._SENT 
2._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 279KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
2._CD A_DT memory_NN block_NN architecture_NN ._SENT 
In_IN the_DT figure_NN ,_, x(t_NP )_) is_VBZ the_DT input_NN at_IN time_NN t_NN ,_, g(t_NP )_) the_DT input_NN squashing_VVG unit_NN ,_, i(t_NP )_) the_DT input_NN gate_NN unit_NN ,_, f(t_NP )_) the_DT forget_VV gate_NN unit_NN ,_, s(t_NP )_) the_DT cell_NN state_NN ,_, o(t_NP )_) the_DT output_NN gate_NN unit_NN ,_, and_CC h(t_NP )_) the_DT output_NN gating_VVG unit_NN ,_, also_RB is_VBZ the_DT output_NN of_IN the_DT LSTM_NN layer_NN ._SENT 
Therefore_RB ,_, the_DT input_NN gating_VVG unit_NN can_MD be_VB represented_VVN as_IN it°gt_NP and_CC °_NP denotes_VVZ the_DT Hadamard_NN product_NN ._SENT 
In_IN addition_NN ,_, σ_NN and_CC tanh_NN represent_VVP a_DT sigmoid_JJ function_NN and_CC a_DT hyperbolic_JJ tangent_JJ function_NN separately_RB ._SENT 
The_DT expression_NN for_IN these_DT two_CD function_NN as_RB follows_VVZ :_: (_( 1)σ(z)=11+e−z_NP (_( 2)tanh(z)=ez−e−zez+e−z_NP Given_VVN an_DT input_NN data_NN sequence_NN x={x1_NN ,_, …_NP ,_, xT_NN }_) ,_, the_DT output_NN data_NN sequence_NN of_IN the_DT hidden_JJ layer_NN h={h1_NN ,_, …_NP ,_, hT_NP }_) ,_, the_DT computational_JJ process_NN of_IN the_DT memory_NN block_NN at_IN time_NN t_NN was_VBD shown_VVN as_RB follows_VVZ :_: (_( 3)gt=tanh(wxgxt+whght−1+bg_NP )_) (_( 4)it=σ(wxixt+whiht−1+bi_NP )_) (_( 5)ft=σ(wxfxt+whfht−1+bf_NP )_) (_( 6)st=st−1°ft+it°gt_NP (_( 7)ot=σ(wxoxt+whoht−1+bo_NP )_) (_( 8)ht=ot°tanh(st_NP )_) where_WRB w_NN and_CC b_LS terms_NNS denote_VVP weight_NN matrices_NNS and_CC bias_NN vectors_NNS separately_RB ._SENT 
The_DT output_NN of_IN LSTM_NN layers_NNS is_VBZ related_VVN to_TO the_DT input_NN at_IN time_NN t_NN and_CC the_DT output_NN at_IN time_NN t−1_NN ,_, t−2_NP ,_, t−3_NP ,_, …_NP ,_, t−N_NP ._SENT 
However_RB ,_, the_DT output_NN of_IN a_DT certain_JJ time_NN is_VBZ related_VVN to_TO the_DT previous_JJ time_NN and_CC the_DT subsequent_JJ time_NN ._SENT 
The_DT output_NN of_IN bi-LSTM_NN layers_NNS is_VBZ related_VVN to_TO not_RB only_RB the_DT input_NN at_IN time_NN t_NN and_CC the_DT output_NN at_IN time_NN t−1_NN ,_, t−2_NP ,_, t−3_NP ,_, …_NP ,_, t−N_NP ,_, but_CC also_RB the_DT output_NN at_IN time_NN t+_NP 1_CD ,_, t+_NP 2_CD ,_, t+_NP 3_CD ,_, …_NP ,_, t+N_NP ._SENT 
A_DT bi-LSTM_NP layer_NN architecture_NN [_SYM 21_CD ]_SYM is_VBZ shown_VVN in_IN Fig_NN ._SENT 
3._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 271KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
3._CD A_DT bi-LSTM_NN layer_NN architecture_NN ._SENT 
In_IN Fig_NN ._SENT 
3_LS ,_, w1_JJ includes_VVZ the_DT weight_NN matrices_NNS between_IN input_NN and_CC forward_JJ layer_NN (_( wxg_NP ,_, wxi_NP ,_, wxf_NP ,_, wxo_NP )_) ,_, w2_NP includes_VVZ the_DT weight_NN matrices_NNS between_IN input_NN and_CC backward_RB layer_NN (_( wbxg_NP ,_, wbxi_NP ,_, wbxf_NP ,_, wbxo_NP )_) ,_, w3_NP includes_VVZ the_DT weight_NN matrices_NNS in_IN forward_JJ layer_NN (_( whg_NP ,_, whi_NP ,_, whf_NP ,_, who_WP )_) ,_, w4_NP includes_VVZ the_DT weight_NN matrices_NNS in_IN backward_RB layer_NN (_( wbhg_NP ,_, wbhi_NP ,_, wbhf_NP ,_, wbho_NP )_) ,_, w5_NP is_VBZ the_DT weight_NN matrices_NNS between_IN forward_JJ layer_NN and_CC output_NN ,_, while_IN w6_NP is_VBZ the_DT weight_NN matrices_NNS between_IN backward_RB layer_NN and_CC output_NN ._SENT 
wb_NN in_IN backward_RB layer_NN has_VHZ the_DT same_JJ meaning_NN with_IN w_NN in_IN forward_JJ layer_NN ._SENT 
In_IN the_DT figure_NN ,_, we_PP can_MD find_VV the_DT difference_NN between_IN LSTM_NN layers_NNS and_CC bi-LSTM_NN layers_NNS is_VBZ that_IN the_DT bi-LSTM_NN layers_NNS have_VHP a_DT backward_RB layer_NN in_IN it_PP ._SENT 
The_DT equations_NNS from_IN to_TO show_VV the_DT process_NN of_IN the_DT forward_JJ layer_NN in_IN bi-LSTM_NN layers_NNS ._SENT 
As_IN the_DT computational_JJ equation_NN of_IN the_DT forward_JJ layer_NN ,_, the_DT computational_JJ process_NN of_IN the_DT memory_NN block_NN at_IN time_NN t_NN in_IN backward_RB layer_NN was_VBD shown_VVN as_RB follows_VVZ :_: (_( 9)gbt=tanh(wbxgxt+wbhght+1+bbg_NP )_) (_( 10)ibt=σ(wbxixt+wbhiht+1+bbi_NP )_) (_( 11)fbt=σ(wbxfxt+wbhfht+1+bbf_NP )_) (_( 12)sbt=sb(t+1)°fbt+ibt°gbt_NN (_( 13)obt=σ(wbxoxt+wbhoht+1+bbo_NP )_) (_( 14)hbt=obt°tanh(sbt_NN )_) In_IN the_DT bi-LSTM_NN layer_NN ,_, the_DT output_NN of_IN the_DT memory_NN block_NN consists_VVZ of_IN ht_NN and_CC hbt_NN ,_, which_WDT can_MD also_RB be_VB called_VVN the_DT output_NN of_IN the_DT bi-LSTM_NN layer_NN ._SENT 
After_IN the_DT bi-LSTM_NN layer_NN ,_, a_DT fully_RB connected_VVN layer_NN ,_, a_DT softmax_NP layer_NN ,_, and_CC a_DT classification_NN layer_NN are_VBP used_VVN to_TO determine_VV the_DT class_NN of_IN the_DT input_NN data_NNS ._SENT 
A_DT bi-LSTM_NP network_NN architecture_NN of_IN signal_NN bi-LSTM_NN layers_NNS is_VBZ shown_VVN in_IN Fig_NN ._SENT 
4._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 323KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
4._CD A_DT bi-LSTM_NN network_NN architecture_NN of_IN signal_NN stacked_VVN bi-LSTM_NP layers_NNS ._SENT 
The_DT parameter_NN adjustment_NN is_VBZ based_VVN on_IN back_JJ propagation_NN algorithm_NN and_CC adaptive_JJ adjustment_NN method_NN besides_IN ._SENT 
<Section> 3._CD Experimental_JJ study_NN and_CC result_NN analysis_NN </Section> 3.1_CD ._SENT 
Explanation_NN and_CC pretreatment_NN of_IN experimental_JJ data_NNS The_DT experimental_JJ data_NNS used_VVN in_IN this_DT study_NN are_VBP derived_VVN from_IN sea_NN trial_NN ._SENT 
Choose_VV two_CD kinds_NNS of_IN targets_NNS called_VVD Class_NP A_NP and_CC Class_NP B._NP Class_NP A_NP is_VBZ a_DT tourist_NN boat_NN and_CC Class_NP B_NP is_VBZ a_DT warship_NN ._SENT 
In_IN this_DT section_NN ,_, the_DT radiated_VVN noise_NN of_IN ships_NNS acquired_VVN by_IN vector_NN sonar_NN system_NN is_VBZ used_VVN to_TO recognize_VV ._SENT 
The_DT trial-channel_NN receives_VVZ data_NNS simultaneously_RB from_IN vector_NN sonar_NN system_NN using_VVG 40_CD kHz_NP sampling_NN rate_NN and_CC transfers_VVZ the_DT data_NNS to_TO Matlab_VV for_IN processing_NN ._SENT 
Selecting_VVG a_DT sample_NN from_IN each_DT class_NN of_IN targets_NNS ._SENT 
The_DT time-domain_NN waveforms_NNS after_IN normalizing_VVG the_DT amplitude_NN and_CC frequency_NN spectra_NN for_IN each_DT target_NN are_VBP shown_VVN in_IN Fig_NN ._SENT 
5_LS ,_, Fig_VV ._SENT 
6._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 391KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
5._CD The_DT time-domain_NN waveforms_NNS for_IN the_DT two_CD ships_NNS ._SENT 
Download_NN :_: Download_NP high-res_NP image_NN (_( 331KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
6._CD The_DT frequency_NN spectra_NN for_IN the_DT two_CD ships_NNS ._SENT 
Pass_VV the_DT radiated_VVN noise_NN through_IN the_DT band-pass_NN filter_NN to_TO get_VV the_DT frequency_NN band_NN which_WDT need_VVP to_TO be_VB analyzed_VVN and_CC sample_NN down_IN the_DT signal_NN to_TO 2_CD kHz_NN ._SENT 
Actually_RB ,_, vector_NN sensor_NN can_MD measure_VV not_RB only_RB sound_JJ pressure_NN p_NN ,_, but_CC also_RB two_CD orthogonality_NN components_NNS particle_NN velocity_NN vx_NN and_CC vy_NNS [_SYM 22_CD ]_SYM ._SENT 
Considering_VVG the_DT influence_NN of_IN environmental_JJ noise_NN n_NN ,_, the_DT vector_NN signal_NN can_MD be_VB represented_VVN as_RB follows_VVZ :_: (_( 15)⎧⎩⎨⎪⎪p(t)=ps(t)+np(t)vx(t)=ps(t)cosθ+nvx(t)vy(t)=ps(t)sinθ+nvy(t_NP )_) where_WRB θ∈[0,2π_NP )_) is_VBZ horizontal_JJ angle_NN of_IN acoustic_JJ wave_NN ._SENT 
It_PP is_VBZ assumed_VVN that_IN the_DT signal_NN and_CC noise_NN are_VBP not_RB correlated_VVN ,_, while_IN the_DT sound_JJ pressure_NN and_CC particle_NN velocity_NN of_IN the_DT noise_NN are_VBP not_RB correlated_VVN ._SENT 
If_IN limited_VVN to_TO two-dimensional_JJ horizontal_JJ plane_NN ,_, the_DT beam_NN can_MD be_VB rotated_VVN in_IN it_PP using_VVG the_DT weight_NN linear_JJ combination_NN of_IN two_CD orthogonality_NN components_NNS particle_NN velocity_NN to_TO get_VV the_DT synthetic_JJ velocity_NN ._SENT 
The_DT synthetic_JJ velocity_NN can_MD be_VB expressed_VVN as_RB :_: (_( 16)v(t)=vx(t)cosψ+vy(t)sinψ=(ps(t)cosθ+nvx(t))cosψ+(ps(t)sinθ+nvy(t))sinψ=ps(t)cos(θ−ψ)sinθ+nvx(t)cosψ+nvy(t)sin=vs(t)+nv(t_NP )_) where_WRB vs(t)=ps(t)cos(θ−ψ)sinθ_NP ,_, nv(t)=nvx(t)cosψ+nvy(t)sinψ_NP ,_, ψ_NP is_VBZ the_DT horizontal_JJ rotation_NN angle_NN ._SENT 
Therefore_RB ,_, the_DT expression_NN of_IN average_JJ acoustic_JJ energy_NN flux_NN I(t_NN )_) is_VBZ :_: (_( 17)I(t_NP )_) =p(t)⋅v(t_NP )_) ¯¯=[ps(t)+np(t)]⋅[vs(t)+nv(t_NP )_) ¯¯¯¯¯]=ps(t)⋅vs(t_NP )_) ¯¯¯¯¯+ps(t)⋅nv(t_NP )_) ¯¯¯¯¯+np(t)⋅vs(t_NP )_) ¯¯¯¯¯+np(t)⋅nv(t_NP )_) ¯¯¯¯¯≈ps(t)⋅vs(t_NP )_) ¯¯¯¯¯_NP Vector_NP sensor_NN has_VHZ the_DT characteristics_NNS of_IN directivity_NN and_CC inhibiting_VVG isotropic_JJ ._SENT 
In_IN this_DT study_NN ,_, I(t_NP )_) is_VBZ selected_VVN as_IN the_DT input_NN of_IN network_NN ._SENT 
3.2_CD ._SENT 
Recognition_NN of_IN ships_NNS based_VVN on_IN LSTM_NP Selecting_VVG 100_CD sampling_NN points_NNS as_IN a_DT sample_NN ,_, we_PP can_MD get_VV 10,000_CD samples_NNS for_IN each_DT class_NN of_IN targets_NNS and_CC the_DT total_JJ number_NN of_IN samples_NNS is_VBZ 20000._CD Divide_NP the_DT dataset_NN into_IN training_NN set_NN and_CC testing_NN set_NN ._SENT 
Choose_VV 7000_CD samples_NNS in_IN each_DT category_NN ,_, 14,000_CD in_IN total_NN as_IN training_NN set_NN and_CC the_DT rest_NN as_IN testing_NN set_NN ._SENT 
The_DT training_NN set_NN is_VBZ inputted_VVN into_IN the_DT LSTM_NN networks_NNS with_IN parameters_NNS initialization_NN ._SENT 
The_DT process_NN of_IN training_NN using_VVG LSTM_NN which_WDT consists_VVZ of_IN accuracy_NN and_CC loss_NN is_VBZ shown_VVN in_IN Fig_NN ._SENT 
7._CD The_NP parameters_NNS are_VBP set_VVN as_RB follows_VVZ :_: the_DT maximum_NN of_IN epoch_NN is_VBZ 200_CD ,_, the_DT input_NN layer_NN has_VHZ 100_CD units_NNS due_JJ to_TO the_DT sample_NN size_NN ,_, the_DT LSTM_NP layer_NN has_VHZ 120_CD units_NNS and_CC the_DT output_NN layer_NN has_VHZ 2_CD units_NNS due_JJ to_TO the_DT number_NN of_IN class_NN ,_, the_DT initial_JJ learning_NN rate_NN is_VBZ 0.01_CD and_CC learning_VVG rate_NN will_MD be_VB decreased_VVN gradually_RB as_IN the_DT epoch_NN number_NN increases_NNS ._SENT 
Download_NN :_: Download_NP high-res_NP image_NN (_( 171KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
7._CD The_DT process_NN of_IN training_NN set_VVD using_VVG LSTM_NN ._SENT 
The_DT training_NN set_NN and_CC the_DT testing_NN set_NN are_VBP inputted_VVN into_IN the_DT LSTM_NN networks_NNS with_IN adjusted_JJ parameters_NNS ._SENT 
The_DT recognition_NN results_NNS and_CC statistical_JJ bar_NN chart_NN of_IN recognition_NN rates_NNS of_IN training_NN set_NN and_CC the_DT testing_NN set_VVD using_VVG LSTM_NN are_VBP shown_VVN in_IN Fig_NN ._SENT 
8_CD ,_, Fig_NN ._SENT 
9_CD and_CC Table_NN 2._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 355KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
8._CD The_DT recognition_NN results_NNS and_CC statistical_JJ bar_NN chart_NN of_IN recognition_NN rates_NNS of_IN the_DT training_NN set_VVD using_VVG LSTM_NN ._SENT 
Download_NN :_: Download_NP high-res_NP image_NN (_( 394KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
9._CD The_DT recognition_NN results_NNS and_CC statistical_JJ bar_NN chart_NN of_IN recognition_NN rates_NNS of_IN the_DT testing_NN set_VVD using_VVG LSTM_NN ._SENT 
In_IN Fig_NN ._SENT 
8_CD ,_, (_( a_DT )_) shows_VVZ the_DT discriminant_NN results_NNS of_IN training_NN set_NN ._SENT 
And_CC in_IN the_DT figure_NN ,_, black_JJ point_NN means_VVZ correct_JJ judgement_NN ,_, while_IN the_DT red_JJ cross_NN means_VVZ wrong_JJ judgement_NN ._SENT 
(_( b_LS )_) shows_VVZ the_DT total_JJ number_NN of_IN correct_JJ judgement_NN and_CC wrong_JJ judgement_NN for_IN each_DT class_NN ._SENT 
It_PP can_MD be_VB derived_VVN that_IN 6592_CD samples_NNS are_VBP correctly_RB judged_VVN as_IN Class_NP A_NP while_IN 408_CD samples_NNS are_VBP misjudged_VVN as_IN Class_NP B_NP in_IN the_DT 7000_CD samples_NNS of_IN Class_NP A._NP Similarly_RB ,_, 6911_CD samples_NNS are_VBP correctly_RB judged_VVN as_IN Class_NP B_NP while_IN 89_CD samples_NNS are_VBP misjudged_VVN as_IN Class_NP A_NP in_IN the_DT 7000_CD samples_NNS of_IN Class_NP B._NP (_( c_LS )_) shows_VVZ the_DT recognition_NN rate_NN of_IN training_NN set_NN ,_, also_RB called_VVN recall_NN ratio_NN of_IN training_NN set_NN ,_, a_DT kind_NN of_IN model_NN evaluation_NN criteria_NNS ._SENT 
The_DT expression_NN for_IN recall_NN ratio_NN R_NN is_VBZ (_( 18)R=TPTP+FN_NP In_IN Eq_NP ._SENT 
(_( 18_CD )_) ,_, TP_NP is_VBZ the_DT number_NN of_IN sample_NN which_WDT is_VBZ judged_VVN to_TO be_VB a_DT positive_JJ and_CC actual_JJ is_VBZ a_DT positive_JJ ,_, called_VVD true_JJ positive_NN ;_: FN_NP is_VBZ the_DT number_NN of_IN sample_NN which_WDT is_VBZ judged_VVN to_TO be_VB a_DT positive_JJ and_CC actual_JJ is_VBZ a_DT negative_JJ ,_, called_VVD false_JJ negative_NN ._SENT 
It_PP also_RB has_VHZ FP_NP and_CC TN_NP which_WDT have_VHP the_DT similar_JJ meaning_NN with_IN TP_NP and_CC FN_NP ,_, called_VVD true_JJ positive_JJ and_CC false_JJ negative_JJ respectively_RB ._SENT 
Therefore_RB ,_, we_PP may_MD get_VV a_DT confusion_NN matrix_NN of_IN classification_NN ,_, shown_VVN in_IN Table_NN 1._CD Table_NN 1._CD Confusion_NN matrix_NN of_IN classification_NN ._SENT 
Actual_JJ Predict_VVP Positive_JJ Negative_JJ Positive_JJ TP_NP FN_NP Negative_JJ FP_NP TN_NP Table_NN 2._CD The_DT recognition_NN results_NNS using_VVG LSTM_NN for_IN the_DT two_CD ships_NNS ._SENT 
Class_NP Training_NP set_VVD Testing_NP set_VVD The_DT number_NN of_IN training_NN set_VVN Correct_JJ number_NN Recall_VVP The_DT number_NN of_IN testing_VVG set_VVN Correct_JJ number_NN Recall_NN Class_NN A_DT 7000_CD 6592_CD 94.17_CD %_NN 3000_CD 2315_CD 77.17_CD %_NN Class_NN B_NP 7000_CD 6911_CD 98.72_CD %_NN 3000_CD 2199_CD 73.30_CD %_NN For_IN an_DT example_NN ,_, we_PP firstly_RB analyze_VVP the_DT recognize_VVP result_NN of_IN Class_NP A._NP So_IN we_PP treat_VVP Class_NP A_NP as_IN positive_JJ and_CC Class_NP B_NP as_IN negative_JJ ._SENT 
According_VVG to_TO the_DT Table_NN 1_CD ,_, TP=6592_NP ,_, FN=408_NP ,_, FP=89_NP ,_, TN=6911_JJ ,_, and_CC recall_VV ratio_NN of_IN Class_NP A_NP based_VVN on_IN Eq_NP ._SENT 
is_VBZ 94.14_CD %_NN ._SENT 
Similarly_RB ,_, if_IN the_DT Class_NP B_NP is_VBZ analyzed_VVN ,_, we_PP treat_VVP Class_NP B_NP as_IN positive_JJ and_CC Class_NN A_DT as_RB negative_JJ ._SENT 
From_IN Table_NN 1_CD ,_, TP=6911_JJ ,_, FN=89_NP ,_, FP=408_NP ,_, TN=6592_NP ,_, recall_NN ratio_NN of_IN Class_NP B_NP is_VBZ 98.72_CD %_NN ._SENT 
The_DT expression_NN for_IN accuracy_NN is_VBZ (_( 19)Accuracy=TP+TNTP+TN+FN+FP_VV The_DT following_VVG figures_NNS have_VHP the_DT same_JJ meaning_NN ._SENT 
3.3_CD ._SENT 
Recognition_NN of_IN ships_NNS based_VVN on_IN bi-LSTM_NP To_TO compare_VV with_IN the_DT LSTM_NN networks_NNS ,_, use_VVP the_DT same_JJ dataset_NN and_CC parameters_NNS ._SENT 
The_DT training_NN set_NN is_VBZ inputted_VVN into_IN the_DT bi-LSTM_NN networks_NNS with_IN parameters_NNS initialization_NN ._SENT 
The_DT process_NN of_IN training_NN using_VVG bi-LSTM_NN which_WDT consists_VVZ of_IN accuracy_NN and_CC loss_NN is_VBZ shown_VVN in_IN Fig_NN ._SENT 
10._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 194KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
10._CD The_DT process_NN of_IN training_NN using_VVG bi-LSTM_NN ._SENT 
The_DT training_NN set_NN and_CC the_DT testing_NN set_NN are_VBP inputted_VVN into_IN the_DT bi-LSTM_NN networks_NNS with_IN adjusted_JJ parameters_NNS ._SENT 
The_DT recognition_NN results_NNS and_CC statistical_JJ bar_NN chart_NN of_IN recognition_NN rates_NNS of_IN training_NN set_NN and_CC the_DT testing_NN set_VVD using_VVG bi-LSTM_NN are_VBP shown_VVN in_IN Fig_NN ._SENT 
11_CD ,_, Fig_NN ._SENT 
12_CD and_CC Table_NN 3._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 343KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
11._CD The_DT recognition_NN results_NNS and_CC statistical_JJ bar_NN chart_NN of_IN recognition_NN rates_NNS of_IN the_DT training_NN set_VVD using_VVG bi-LSTM_NN ._SENT 
Download_NN :_: Download_NP high-res_NP image_NN (_( 362KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
12._CD The_DT recognition_NN results_NNS and_CC statistical_JJ bar_NN chart_NN of_IN recognition_NN rates_NNS of_IN the_DT testing_NN set_VVD using_VVG bi-LSTM_NN ._SENT 
Table_NN 3._CD The_DT recognition_NN results_NNS using_VVG bi-LSTM_NN for_IN the_DT two_CD targets_NNS ._SENT 
Class_NP Training_NP set_VVD Testing_NP set_VVD The_DT number_NN of_IN training_NN set_VVN Correct_JJ number_NN Recall_VVP The_DT number_NN of_IN testing_VVG set_VVN Correct_JJ number_NN Recall_NN Class_NN A_DT 7000_CD 6692_CD 95.6_CD %_NN 3000_CD 2409_CD 80.30_CD %_NN Class_NN B_NP 7000_CD 6938_CD 99.11_CD %_NN 3000_CD 2457_CD 81.90_CD %_NN 3.4_CD ._SENT 
Result_NN analysis_NN In_IN this_DT paper_NN ,_, the_DT choice_NN of_IN network_NN parameters_NNS is_VBZ finally_RB determined_VVN through_IN a_DT large_JJ number_NN of_IN experiments_NNS after_IN realizing_VVG ship_NN recognition_NN by_IN LSTM_NP and_CC bi-LSTM_NP ._SENT 
Firstly_RB ,_, in_IN the_DT selection_NN of_IN sample_NN time_NN ,_, if_IN the_DT sample_NN time_NN is_VBZ too_RB short_JJ ,_, with_IN the_DT number_NN of_IN feature_NN points_NNS for_IN each_DT sample_NN less_RBR ,_, and_CC the_DT accuracy_NN for_IN both_DT training_NN set_NN and_CC testing_NN set_NN are_VBP low_JJ ._SENT 
If_IN the_DT sample_NN time_NN is_VBZ too_RB long_RB ,_, it_PP is_VBZ easy_JJ to_TO cause_VV over_IN fitting_NN ,_, that_WDT is_VBZ ,_, the_DT accuracy_NN for_IN training_NN set_NN and_CC testing_NN set_NN are_VBP very_RB different_JJ ._SENT 
By_IN comparing_VVG multiple_JJ parameters_NNS ,_, we_PP choose_VVP 0.05_CD s_JJ data_NNS as_IN a_DT sample_NN ,_, which_WDT means_VVZ a_DT sample_NN contains_VVZ 100_CD sample_NN points_NNS ._SENT 
Therefore_RB ,_, the_DT number_NN of_IN nodes_NNS in_IN input_NN layer_NN is_VBZ 100._CD The_DT number_NN of_IN output_NN nodes_NNS is_VBZ equal_JJ to_TO the_DT number_NN of_IN class_NN ,_, which_WDT is_VBZ 2_CD in_IN this_DT experiment_NN ._SENT 
We_PP also_RB discussed_VVD the_DT number_NN of_IN LSTM_NN or_CC bi-LSTM_NN layers_NNS which_WDT is_VBZ variable_JJ from_IN 1_CD to_TO 4._CD By_IN constructing_VVG network_NN models_NNS with_IN different_JJ layers_NNS and_CC comparing_VVG the_DT results_NNS of_IN training_NN set_VVN with_IN different_JJ models_NNS ,_, it_PP can_MD be_VB found_VVN that_IN in_IN a_DT short_JJ training_NN time_NN ,_, the_DT training_NN results_NNS of_IN network_NN with_IN single_JJ LSTM_NN layer_NN or_CC bi_NP LSTM_NP layer_NN are_VBP the_DT best_JJS ._SENT 
If_IN a_DT multi-layer_NP network_NN structure_NN wants_VVZ to_TO get_VV a_DT better_JJR recognition_NN result_NN ,_, it_PP may_MD take_VV a_DT long_JJ training_NN time_NN ,_, but_CC the_DT more_JJR network_NN layers_NNS ,_, the_DT longer_RBR the_DT training_NN time_NN will_MD be_VB ._SENT 
Since_IN the_DT training_NN set_VVD we_PP selected_VVN is_VBZ not_RB so_RB large_JJ ,_, a_DT network_NN with_IN single_JJ LSTM_NN layer_NN or_CC Bi_NP LSTM_NP layer_NN was_VBD selected_VVN ._SENT 
By_IN comparing_VVG the_DT effects_NNS of_IN different_JJ learning_VVG rates_NNS on_IN recognition_NN results_NNS ,_, we_PP find_VVP that_IN when_WRB the_DT learning_VVG rate_NN is_VBZ small_JJ ,_, the_DT network_NN learning_VVG speed_NN is_VBZ very_RB slow_JJ ,_, and_CC it_PP may_MD take_VV a_DT long_JJ training_NN time_NN to_TO reduce_VV the_DT loss_NN to_TO a_DT smaller_JJR value_NN ._SENT 
When_WRB the_DT learning_VVG rate_NN is_VBZ large_JJ ,_, the_DT loss_NN decreases_VVZ rapidly_RB ,_, but_CC with_IN the_DT increase_NN of_IN the_DT number_NN of_IN epochs_NNS ,_, the_DT loss_NN oscillates_VVZ all_PDT the_DT time_NN and_CC cannot_MD converge_VV ._SENT 
Therefore_RB ,_, a_DT larger_JJR initial_JJ learning_VVG rate_NN was_VBD chosen_VVN to_TO make_VV the_DT loss_NN decline_NN rapidly_RB and_CC a_DT smaller_JJR learning_NN rate_NN to_TO be_VB stable_JJ gradually_RB ._SENT 
In_IN this_DT paper_NN ,_, we_PP choose_VVP 0.01_CD as_IN the_DT initial_JJ learning_VVG rate_NN to_TO learning_VVG the_DT training_NN set_VVN more_RBR quickly_RB but_CC the_DT loss_NN and_CC accuracy_NN will_MD sharply_RB fluctuate_VV ._SENT 
After_IN a_DT certain_JJ number_NN of_IN epochs_NNS ,_, the_DT learning_VVG rate_NN will_MD decrease_VV and_CC the_DT loss_NN and_CC accuracy_NN will_MD be_VB steady_JJ ._SENT 
The_DT number_NN of_IN nodes_NNS in_IN LSTM_NP or_CC bi-LSTM_NP layers_NNS Nn_NP was_VBD set_VVN to_TO 50_CD initially_RB according_VVG to_TO the_DT average_NN of_IN the_DT number_NN of_IN input_NN nodes_NNS and_CC output_NN nodes_NNS ._SENT 
Increase_VV Nn_NP until_IN the_DT accuracy_NN did_VVD not_RB have_VH an_DT obvious_JJ improve_VV ._SENT 
From_IN the_DT result_NN ,_, we_PP can_MD find_VV that_IN an_DT acceptable_JJ result_NN was_VBD provided_VVN when_WRB Nn_NP is_VBZ 120_CD and_CC the_DT accuracy_NN did_VVD not_RB change_VV much_RB with_IN the_DT number_NN of_IN layers_NNS increase_NN ._SENT 
Putting_VVG the_DT training_NN set_NN and_CC the_DT testing_NN set_VVN into_IN the_DT LSTM_NN networks_NNS or_CC bi-LSTM_NN networks_NNS with_IN adjusted_JJ parameters_NNS ,_, we_PP can_MD get_VV the_DT discriminant_NN results_NNS and_CC statistical_JJ bar_NN chart_NN of_IN recognition_NN rate_NN ,_, shown_VVN in_IN Fig_NN ._SENT 
8_CD ,_, Fig_NN ._SENT 
9_CD and_CC Fig_NN ._SENT 
11_CD ,_, Fig_NN ._SENT 
12_CD ,_, and_CC the_DT number_NN of_IN correct_JJ judgement_NN and_CC recognition_NN rate_NN was_VBD recorded_VVN in_IN Table_NN 2_CD ,_, Table_NN 3._CD In_IN order_NN to_TO compare_VV these_DT two_CD methods_NNS ,_, the_DT accuracy_NN and_CC loss_NN are_VBP put_VVN together_RB ,_, shown_VVN in_IN Fig_NN ._SENT 
13._CD Download_NN :_: Download_NP high-res_NP image_NN (_( 216KB)Download_NP :_: Download_NP full-size_JJ image_NN Fig_NN ._SENT 
13._CD Comparison_NN of_IN accuracy_NN and_CC loss_NN for_IN these_DT two_CD methods_NNS ._SENT 
In_IN Fig_NN ._SENT 
13_CD ,_, the_DT blue_JJ line_NN represents_VVZ LSTM_NN and_CC red_JJ line_NN is_VBZ bi-LSTM_NN ._SENT 
When_WRB the_DT number_NN of_IN epochs_NNS is_VBZ 200_CD ,_, the_DT accuracy_NN of_IN bi-LSTM_NN is_VBZ higher_JJR than_IN LSTM_NN with_IN the_DT loss_NN of_IN bi-LSTM_NN is_VBZ smaller_JJR than_IN LSTM_NP ._SENT 
The_DT rising_VVG speed_NN of_IN accuracy_NN curve_NN and_CC the_DT falling_VVG speed_NN of_IN loss_NN curve_NN of_IN bi-LSTM_NN are_VBP faster_JJR than_IN that_DT of_IN LSTM_NP ._SENT 
As_IN the_DT number_NN of_IN epochs_NNS increases_NNS ,_, the_DT accuracy_NN curve_NN and_CC loss_NN curve_NN fluctuate_VVP slightly_RB ._SENT 
When_WRB the_DT learning_VVG rate_NN decreases_NNS ,_, the_DT curve_NN tends_VVZ to_TO be_VB stable_JJ gradually_RB ._SENT 
Finally_RB ,_, the_DT accuracy_NN is_VBZ higher_JJR with_IN the_DT loss_NN is_VBZ lower_JJR of_IN bi-LSTM_NN than_IN that_DT of_IN LSTM_NP ._SENT 
Compare_VV bi-LSTM_NN and_CC LSTM_NN with_IN the_DT method_NN which_WDT needs_VVZ to_TO extract_VV features_NNS first_RB and_CC recognize_VV by_IN learning_VVG algorithm_NN or_CC classifier_NN ._SENT 
The_DT auditory_JJ perception_NN features_NNS are_VBP extracted_VVN from_IN 14,000_CD samples_NNS and_CC input_NN into_IN SVM_NP ._SENT 
The_DT accuracy_NN and_CC running_VVG time_NN are_VBP shown_VVN in_IN the_DT Table_NN 4._CD The_DT running_NN time_NN for_IN training_NN set_VVN of_IN SVM_NP includes_VVZ the_DT time_NN of_IN feature_NN extraction_NN and_CC training_NN time_NN of_IN network_NN ._SENT 
The_DT running_VVG time_NN of_IN LSTM_NP and_CC bi-LSTM_NP just_RB includes_VVZ the_DT training_NN time_NN of_IN network_NN ,_, because_IN LSTM_NP and_CC bi-LSTM_NP do_VVP not_RB need_VV to_TO extract_VV features_NNS ._SENT 
The_DT running_VVG time_NN for_IN testing_NN set_NN is_VBZ the_DT time_NN to_TO get_VV the_DT recognition_NN result_NN of_IN input_NN data_NNS and_CC the_DT sample_NN size_NN of_IN testing_NN set_NN is_VBZ 6000._CD Table_NN 4._CD Comparison_NN of_IN accuracy_NN and_CC running_VVG time_NN for_IN different_JJ methods_NNS ._SENT 
Method_NN Training_NP set_VVD Testing_NP set_VVD Accuracy_NN Running_VVG time_NN Accuracy_NN Running_NN time_NN SVM_NP 85.71_CD %_NN 320_CD s_NN 69.4_CD %_NN 157_CD s_NNS LSTM_NP 96.45_CD %_NN 134_CD s_NN 75.24_CD %_NN 10_CD s_NNS bi-LSTM_NP 97.36_CD %_NN 245_CD s_NN 81.1_CD %_NN 11_CD s_NNS It_PP can_MD be_VB seen_VVN from_IN the_DT Table_NN 4_CD that_WDT the_DT accuracy_NN of_IN LSTM_NP and_CC bi-LSTM_NP is_VBZ obviously_RB higher_JJR than_IN SVM_NP and_CC bi-LSTM_NP is_VBZ higher_JJR than_IN LSTM_NN in_IN training_NN set_NN and_CC testing_NN set_NN ._SENT 
It_PP shows_VVZ that_IN bi-LSTM_NP can_MD recognize_VV ships_NNS with_IN better_JJR recognition_NN result_NN ._SENT 
With_IN the_DT accuracy_NN of_IN bi-LSTM_NN is_VBZ higher_JJR than_IN LSTM_NP ,_, the_DT running_VVG time_NN of_IN bi-LSTM_NN is_VBZ longer_RBR than_IN LSTM_NP ._SENT 
This_DT is_VBZ because_IN bi-LSTM_NP has_VHZ a_DT backward_RB layer_NN which_WDT makes_VVZ the_DT network_NN model_NN complex_NN ,_, and_CC the_DT training_NN time_NN is_VBZ longer_RBR ._SENT 
Although_IN the_DT running_VVG time_NN of_IN SVM_NN is_VBZ long_JJ ,_, feature_NN extraction_NN takes_VVZ 264_CD s_NNS and_CC the_DT training_NN time_NN of_IN network_NN is_VBZ only_RB 56_CD s._NN In_IN practical_JJ engineering_NN application_NN ,_, the_DT training_NN process_NN of_IN network_NN is_VBZ carried_VVN out_RP in_IN advance_NN ,_, but_CC the_DT running_VVG time_NN of_IN testing_NN set_NN is_VBZ the_DT real_JJ time_NN spent_VVN in_IN the_DT experiment_NN to_TO get_VV target_NN recognition_NN results_NNS ._SENT 
It_PP can_MD be_VB seen_VVN from_IN the_DT table_NN that_IN the_DT running_VVG time_NN for_IN testing_NN set_VVN of_IN LSTM_NP and_CC bi-LSTM_NP is_VBZ close_JJ ,_, but_CC SVM_NP needs_VVZ to_TO extract_VV features_NNS of_IN testing_NN set_VVN so_RB that_IN the_DT running_VVG time_NN for_IN testing_NN set_NN is_VBZ very_RB long_JJ ._SENT 
Therefore_RB ,_, for_IN the_DT projects_NNS with_IN real-time_JJ requirements_NNS ,_, LSTM_NP and_CC bi-LSTM_NP that_WDT do_VVP not_RB need_VV to_TO extract_VV features_NNS are_VBP good_JJ choices_NNS with_IN short_JJ testing_NN time_NN and_CC high_JJ recognition_NN rate_NN ._SENT 
<Section> 4._CD Conclusion_NN </Section> In_IN this_DT paper_NN ,_, a_DT method_NN named_VVN bi-LSTM_NP was_VBD described_VVN and_CC firstly_RB used_VVN for_IN recognizing_VVG the_DT ships_NNS based_VVN on_IN vector_NN sensor_NN ._SENT 
We_PP also_RB contrasted_VVD LSTM_NN networks_NNS and_CC bi-LSTM_NN networks_NNS ._SENT 
It_PP was_VBD shown_VVN through_IN experimental_JJ studies_NNS that_IN both_DT bi-LSTM_NN and_CC LSTM_NN can_MD be_VB used_VVN for_IN recognition_NN of_IN ships_NNS based_VVN on_IN vector_NN sensor_NN without_IN pre-extracting_VVG feature_NN ._SENT 
In_IN the_DT process_NN of_IN data_NN training_NN and_CC testing_NN ,_, it_PP was_VBD demonstrated_VVN the_DT two_CD methods_NNS have_VHP strong_JJ adaptability_NN ._SENT 
In_IN addition_NN ,_, after_IN a_DT long_JJ period_NN of_IN training_NN ,_, bi-LSTM_NP shows_VVZ better_JJR recognition_NN rate_NN than_IN LSTM_NP ._SENT 
The_DT SVM_NN was_VBD chosen_VVN to_TO compared_VVN with_IN bi-LSTM_NP and_CC LSTM_NP ,_, and_CC the_DT experimental_JJ results_NNS shows_VVZ the_DT accuracy_NN of_IN both_DT bi-LSTM_NN and_CC LSTM_NN are_VBP higher_JJR and_CC the_DT running_VVG time_NN for_IN testing_VVG set_NN are_VBP shorter_JJR than_IN SVM_NP ,_, which_WDT proves_VVZ the_DT bi-LSTM_NP and_CC LSTM_NP have_VHP real-time_JJ performance_NN ._SENT 
<Section> Declaration_NN of_IN Competing_VVG Interest_NN </Section> The_DT authors_NNS declare_VVP that_IN they_PP have_VHP no_RB known_VVN competing_VVG financial_JJ interests_NNS or_CC personal_JJ relationships_NNS that_WDT could_MD have_VH appeared_VVN to_TO influence_VV the_DT work_NN reported_VVD in_IN this_DT paper_NN ._SENT 
<Section> Acknowledgments_NNS </Section> This_DT work_NN was_VBD supported_VVN by_IN Research_NP and_CC Development_NP of_IN Surface_NP Environment_NP Monitoring_NN System_NN Based_VVN on_IN Acoustic_JJ Vector_NP under_IN Grand_NP No._NN 2018GXB01-04-001_NN ._SENT 
<Section> References_NNS </Section> [_SYM 1_CD ]_SYM S._NP Hochreiter_NP ,_, J._NP S._NP Huber_NP Long_NP short-term_JJ memory_NN Neural_JJ Comput_NN ,_, 9_CD (_( 8_CD )_) (_( 1997_CD )_) ,_, pp_NP ._SENT 
1735-1780_CD CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 2_CD ]_SYM F._NP Gers_NP ,_, J._NP Schmidhuber_NP ,_, F._NP Cummins_NP Learning_NP to_TO forget_VV :_: continual_JJ prediction_NN with_IN LSTM_NP Proc_NP ._SENT 
9th_JJ ICANN_NP (_( 1999_CD )_) ,_, pp_NP ._SENT 
850-855_CD CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 3_CD ]_SYM G._NP E._NP Hinton_NP ,_, R._NP R._NP Salakhutdinov_NP Reducing_VVG the_DT dimensionality_NN of_IN data_NNS with_IN neural_JJ networks_NNS Sci_NP Citation_NP Index_NP ,_, 313_CD (_( 9_CD )_) (_( 2006_CD )_) ,_, pp_NP ._SENT 
504-507_CD CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 4_CD ]_SYM J._NP Ng_NP ,_, M._NP Hausknecht_NP ,_, S._NP Vijayanarasimhan_NP ,_, O._NP Vinyals_NP ,_, R._NP Monga_NP ,_, G._NP Toderici_NP Beyond_IN short_JJ snippets_NNS :_: deep_JJ networks_NNS for_IN video_JJ classification_NN Proc_NP CVPR_NP (_( 2015_CD :_: )_) ,_, pp_NP ._SENT 
4694-4702_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 5_CD ]_SYM C._NP X._NP Feng_NP ,_, B._NP Qin_NP ,_, T._NP Liu_NP A_DT language-independent_JJ neural_JJ network_NN for_IN event_NN detection_NN Sci_NP China_NP (_( Inf_NP Sci_NP )_) ,_, 61_CD (_( 09_CD )_) (_( 2018_CD )_) ,_, pp_NP ._SENT 
81-92_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 6_CD ]_SYM M._NP Sundermeyer_NP ,_, H._NP Ney_NP ,_, R._NP Schluter_NP From_IN feedforward_NP to_TO recurrent_JJ LSTM_NN neural_JJ networks_NNS for_IN language_NN modeling_VVG IEEE/ACM_NP Trans_NP Audio_NN ,_, Speech_NN ,_, Lang_NP Process_NN ,_, 23_CD (_( 2015_CD )_) ,_, pp_NP ._SENT 
517-529_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 7_CD ]_SYM J._NP T._NP Chen_NP ,_, D._NP L._NP Wang_NP Long_NP short-term_JJ memory_NN for_IN speaker_NN generalization_NN in_IN supervised_JJ speech_NN separation_NN J_NP Acoust_NP Soc_NP Am_NP ,_, 141_CD (_( 2017_CD )_) ,_, pp_NP ._SENT 
4705-4714_CD CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 8_CD ]_SYM A._NP Graves_NP ,_, A._NP Mohamed_NP ,_, G._NP Hinton_NP Speech_NN recognition_NN with_IN deep_JJ recurrent_JJ neural_JJ networks_NNS Proc_NP ICASSP_NP (_( 2013_CD )_) ,_, pp_NP ._SENT 
6645-6649_CD CrossRefView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 9_CD ]_SYM H._NP Sak_NP ,_, A._NP W._NP Senior_NP ,_, F._NP Beaufays_NPS Long_NP short-term_JJ memory_NN recurrent_JJ neural_JJ network_NN architectures_NNS for_IN large_JJ scale_NN acoustic_JJ modeling_NN Proc_NP Interspeech_NP (_( 2014_CD )_) ,_, pp_NP ._SENT 
338-342_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 10_CD ]_SYM X._NP Zhang_NP ,_, Z._NP X._NP Zou_NP ,_, K._NP W._NP Wang_NP ,_, Q._NP S._NP Hao_NP ,_, Y._NP Wang_NP ,_, Y._NP Shen_NP ,_, et_NP al_NP ._SENT 
A_DT new_JJ rail_NN crack_NN detection_NN method_NN using_VVG LSTM_NN network_NN for_IN actual_JJ application_NN based_VVN on_IN AE_NP technology_NN Appl_NP Acoust_NP ,_, 142_CD (_( 2018_CD )_) ,_, pp_NP ._SENT 
78-86_CD ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 11_CD ]_SYM F._NP Ertam_NP An_DT effective_JJ gender_NN recognition_NN approach_NN using_VVG voice_NN data_NNS via_IN deeper_JJR LSTM_NN networks_NNS Appl_NP Acoust_NP ,_, 156_CD (_( 2019_CD )_) ,_, pp_NP ._SENT 
351-358_CD ArticleDownload_NP PDFView_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 12_CD ]_SYM A._NP K._NP Ibrahim_NP ,_, L._NP H._NP Zhuang_NP ,_, M._NP Cherubin_NP ,_, M._NP T._NP Scharer-Umpierre_NP ,_, N._NP Erdol_NP Automatic_NP classification_NN of_IN grouper_NN species_NNS by_IN their_PP$ sounds_NNS using_VVG deep_JJ neural_JJ networks_NNS J_NP Acoust_NP Soc_NP Am_NP ,_, 144_CD (_( 3_LS )_) (_( 2018_CD )_) ,_, pp_NP ._SENT 
196-202_CD CrossRefGoogle_JJ Scholar_NN [_SYM 13_CD ]_SYM M._NP Schuster_NP ,_, K._NP K._NP Paliwal_NP Bidirectional_JJ recurrent_JJ neural_JJ networks_NNS IEEE_NP Trans_NP Signal_NP Process_NN ,_, 45_CD (_( 11_CD )_) (_( 1997_CD )_) ,_, pp_NP ._SENT 
2673-2681_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 14_CD ]_SYM P._NP Sangmin_NP ,_, O._NP Byungwon_NP ,_, L._NP Ryong_NP ,_, P._NP Minwoo_NP ,_, L._NP A._NP Sang-Hwan_NP Bi-LSTM_NP and_CC k-NN_NP based_VVN method_NN for_IN detecting_VVG major_JJ time_NN zones_NNS of_IN overloaded_VVN vehicles_NNS Symmetry_NN ,_, 11_CD (_( 9_CD )_) (_( 2019_CD )_) ,_, pp_NP ._SENT 
1-24_CD Google_JJ Scholar_NN [_SYM 15_CD ]_SYM Wei_NP Z_NP ,_, Peng_NP J_NP ,_, Cai_NP X_NP ,_, and_CC He_PP G._NP Target_NP Information_NP Fusion_NN Based_VVN on_IN Memory_NP Network_NP for_IN Aspect-Level_JJ Sentiment_NN Classification_NN ._SENT 
International_NP Conference_NP on_IN Security_NP with_IN Intelligent_JJ Computing_NP and_CC Big-data_NP Services_NPS ._SENT 
Springer_NP ,_, Cham_NP ,_, 2018._CD Google_JJ Scholar_NN [_SYM 16_CD ]_SYM Zhang_NP X_NP ,_, Miao_NP Z_NP ,_, Yang_NP X_NP ,_, and_CC Zhang_NP Q._NP An_DT Efficient_JJ Method_NN for_IN Automatic_NP Generation_NP of_IN Labanotation_NN Based_VVN on_IN Bi-Directional_JJ LSTM_NN ._SENT 
Journal_NP of_IN Physics_NN :_: Conference_NP Series_NP ,_, 2019._CD Google_JJ Scholar_NN [_SYM 17_CD ]_SYM F._NP A._NP Gers_NP ,_, N._NP N._NP Schraudolph_NP ,_, J._NP Schmidhuber_NP Learning_NP precise_JJ timing_NN with_IN LSTM_NP recurrent_JJ networks_NNS J_NP Mach_NP Learn_NP Res_NN ,_, 3_CD (_( 2003_CD )_) ,_, pp_NP ._SENT 
115-143_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 18_CD ]_SYM S._NP Hasim_NP ,_, S._NP Andrew_NP ,_, B._NP Francoise_NP Long_NP short-term_JJ memory_NN recurrent_JJ neural_JJ networks_NNS architecture_NN for_IN large_JJ scale_NN acoustic_JJ modeling_NN Proc_NP ACISCA_NP (_( 2014_CD )_) ,_, pp_NP ._SENT 
338-342_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 19_CD ]_SYM X._NP Chen_NP ,_, X._NP Qiu_NP ,_, C._NP Zhu_NP Long_NP short-term_JJ memory_NN neural_JJ networks_NNS for_IN Chinese_JJ word_NN segmentation_NN Proc_NP EMNLP_NP (_( 2015_CD )_) ,_, pp_NP ._SENT 
396-405_CD View_NP Record_NP in_IN ScopusGoogle_JJ Scholar_NN [_SYM 20_CD ]_SYM Sutskever_NP I_NP ,_, Vinyals_NP O_NP and_CC Le_NP Q._NP Sequence_NN to_TO sequence_NN learning_VVG with_IN neural_JJ networks_NNS ._SENT 
Proc_NP ._SENT 
IJCNLP_NP ,_, 2014_CD :_: 256-268_CD ._SENT 
Google_JJ Scholar_NN [_SYM 21_CD ]_SYM Grave_NP A._NP Towards_IN end-to-end_NN speech_NN recognition_NN with_IN recurrent_JJ neural_JJ networks_NNS ._SENT 
Proc_NP ._SENT 
31st_JJ ICML_NN ,_, 2014_CD :_: 1764-1772_CD ._SENT 
Google_JJ Scholar_NN [_SYM 22_CD ]_SYM Vladimir_NP A._NP S._NP Vector_NP Acoustics_NN of_IN The_DT Ocean_NP ._SENT 
Vladivostok_NP Dalnauka_NP ._SENT 
2006._CD Google_NN Scholar_NN 