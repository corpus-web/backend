<title>Influence of Pansharpening in Obtaining Accurate Vegetation Maps</title>
<author>Edurne Ibarrola-Ulzurrun, Consuelo Gonzalo-Martín & Javier Marcello</author>
<Affiliation>aInstituto de Oceanografía y Cambio Global (IOCAG), Universidad de Las Palmas de Gran Canaria (ULPGC), Parque Cientíﬁco Tecnológico Marino de Taliarte, s/n,, Telde, Las Palmas, Spain; bEscuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, UPM, Campus de Montegancedo,, Pozuelo de Alarcón, Madrid, Spain</Affiliation>
<year>2017</year>
<Jounral>Journal of Radiological Protection</Journal>
<Publishing_house>IOP Publishing</Publishing_house>
<Text_Collector>田苗，BFSU</Text_Collector>
<DOI>10.1080/07038992.2017.1371583</DOI>
<URL>http://dx.doi.org/10.1080/07038992.2017.1371583</URL>
ABSTRACT
In recent decades, there has been a decline in ecosystem services. Thus, the development of reli- able methodologies to monitor ecosystems is becoming important. In this context, the availabil-   ity of very high resolution sensors offer practical and cost-effective means for good environmen-   tal management. However, improvements in the data received are becoming necessary to obtain higher quality information in order to get reliable thematic maps. One improvement is pansharpen- ing, which enhances the spatial resolution of the multispectral bands by incorporating information from a panchromatic image. The main goal of this work was to assess the influence of pansharpening techniques in obtaining precise vegetation maps. Thus, pixel- and object-based classification tech- niques were implemented and applied to fused imagery using different pansharpening algorithms. Worldview-2 high resolution imagery was used due to its excellent spatial and spectral characteris- tics. The Teide National Park, in The Canary Islands (Spain), was chosen as the study area since it is a vulnerable heterogeneous ecosystem. The vegetation classes of interest considered were established by the National Park conservation managers. Weighted Wavelet ‘à trous’ through Fractal Dimension Maps pansharpening algorithm demonstrated a superior performance in the image fusion prepro- cessing step, while the most appropriate classifier to generate accurate vegetation thematic maps in heterogenic and mixed ecosystems was the Bayes method after the segmentation stage, even though Support Vector Machine achieved the highest overall accuracy.
RÉSUMÉ
Au cours des dernières décennies, les ressources naturelles ont diminué. Pour ces raisons, le développement de méthodologies fiables de surveillance des écosystèmes devient de plus en plus important. Dans ce contexte, la disponibilité de satellites à très haute résolution offre des moyens pratiques et rentables pour une bonne gestion environnementale. Cependant, il est d’abord néces- saire d’introduire des améliorations dans l’acquisition de données afin d’obtenir des informations de meilleure qualité permettant la création des cartes thématiques fiables. Une de ces améliorations est le “pansharpening”, qui augmente la résolution spatiale des bandes multispectrales en incorporant de l’information à partir de l’image panchromatique. Le but principal de ce travail était d’évaluer l’influence des techniques de pansharpening dans l’obtention de cartes de végétation précises. Pour ce faire, on a mis en place des techniques de classification par pixel et orientée-objet, et on    les a appliquées à l’imagerie fusionnée en utilisant différents algorithmes de “pansharpening”. L’imagerie à haute résolution Worldview-2 a été utilisée en raison de ses excellentes caractéristiques spatiales et spectrales. On a choisi le Parc National du Teide, aux Canaries (Espagne), comme zone d’étude, étant donné qu’il s’agit d’un écosystème vulnérable et hétérogène. Les classes de végétation considérées ont été établies par les responsables de la conservation du Parc National. L’algorithme de pansharpening “Weighted Wavelet ‘à trous’ through Fractal Dimension Maps” a démontré la précision la plus élevée à l’étape de prétraitement de fusion d’images, alors que le classificateur le plus approprié pour générer des cartes précises de végétation, dans les écosystèmes hétérogènes et mixtes, a été la méthode Bayes, après l’étape de segmentation, bien que Support Vector Machine a obtnenu le plus haut précision globale.
ARTICLE HISTORY
Received  February  Accepted  August 
Introduction
Biodiversity supports a wide variety of ecological func- tions together with the services provided by ecosystems (Isbell et al. 2011). Its conservation is related to global environmental changes, such as the land use changes,
climate change, and sustainable developments. How- ever, during the last century, human activity gave raise to alterations in ecosystems and thus, biodiversity is suffering a fast decline (Khare and Ghosh 2016). This creates a demand to preserve environmental resources
(Pakzad et al. 2003). Remote sensing has become an essential tool for evaluating and monitoring ecosystems. It is able to provide consistent data on the Earth at various scales, reducing the collection of field data and ground-based observations (Khare and Ghosh 2016), making it a cost-effective tool for land-cover classifi- cation, monitoring, and environmental management (Aplin 2004). Procedures for both classifying land cover and monitoring land cover changes are extensively used in environmental management. However, classifying remotely sensed data in a thematic map remains a chal- lenge because of the many factors involved, which may affect the success of the classification (Lu and Weng 2007), i.e., the complexity and heterogeneity of small species in the ecosystem, quality of the remotely sensed data avail- able, as well as the image preprocessing and classification approaches. Remote sensing classification involves the selection of training samples, image pre-processing, a suitable classification model, post-classification process- ing, and accuracy assessment (Lu and Weng 2007). In this context, pixel-based and object-based classification approaches can be distinguished.
In the traditional pixel-based classification approaches, each pixel is identified by comparing its spectral signa- ture value with the training samples and that pixel is labeled with the proper class based on a certain super- vised algorithm (Gao et al. 2009), but neither spatial con- cepts nor contextual information are incorporated. Thus, the misclassification rate could be high due to the spec- tral similarity characteristics of some classes, the spec- tral variability of the canopy reflectance and the pres- ence of mixed pixels located on the boundary between classes (Peña-Barragán et al. 2011). On the other hand, object-based image analysis or OBIA, in the geographic context (GEOBIA), was proposed as a new classifica- tion approach due to the launch of very high resolution (VHR) sensors. It offers a methodological framework, from a machine-based interpretation of complex classes, defined by the spectral, spatial, structural and hierarchi- cal properties (Blaschke et al. 2008; Goodin et al. 2015, Oruc et al. 2004). The idea of OBIA is the segmentation of the image followed by successive analyses, usually at different hierarchical levels, in order to create relation- ships within segments or objects (Garcia-Pedrero et al. 2015; Lantz and Wang, 2013; Peña-Barragán et al. 2011). Given that, segmentation could be defined as a bottom- up region-merging process in which the image is sub- divided into homogeneous regions according to several parameters (band weights, scale, color, shape, texture, etc.) defined by the operator, with the objective of creat- ing object delimiting borders (Peña-Barragán et al. 2011). However, segmentation could be a challenge because the quality of the classification results depends largely on the
segments obtained, thus, it is necessary to establish a bal- ance between efficacy and efficiency (Garcia-Pedrero et al. 2015).
As previously mentioned, remote sensing imagery requires a number of corrections and enhancements, before starting with the classification approach. Since, VHR sensors provide both a multispectral image and a panchromatic band, the quality enhancement would be carried out using an image fusion technique (pansharpen- ing algorithm) in which the spatial resolution of the mul- tispectral image can be improved by incorporating infor- mation from the panchromatic image (Carper et al. 1990; Chavez et al. 1991; Shettigara 1992). Extensive research into image fusion has been carried out during the last decades. Image fusion can be categorized into 3 levels: pixel level, feature level, and knowledge or decision level. Specifically, pansharpening is performed at pixel level and ideal pansharpening algorithm should have 2 main attributes (Li et al. 2012): (i) enhancing high spatial reso- lution; and (ii) reducing spectral distortion. The simplest pansharpening methods, at the conceptual and computa- tion level, are Intensity-Hue-Saturation (IHS; Carper et al. 1990; Shettigara 1992), Principal Component Analysis (PCA; Chavez et al. 1991) and Brovey Transforms (Gille- spie et al. 1987). However, these techniques have problems because they provide spectral distorted fused images. New approaches such as Wavelet transformation and the High Pass Filtering (Alimuddin et al. 2012; Alparone et al.  2016; Chavez et al. 1991; González-Audícana et al. 2004; Kpalma et al. 2014; Marcello et al. 2013; Pohl 2014; Vivone et al. 2015) have been proposed to address particular  problems with the previous techniques (Aiazzi et al. 2002, 2006; Nuñez et al. 1999).
In addition, images acquired from VHR sensors require atmospheric corrections to transform the top of atmosphere radiance into ground reflectance by remov- ing the atmosphere absorption and scattering effects (Marcello et al. 2016), and image orthorectification, as the topographic relief decreases or increases the radi- ance illuminated because of the difference in land ele- vation in some areas. Once images have been cor-  rected and enhanced, the generation of  products  for the management of natural resources can be carried  out.
In this context, the main goal in this study was to implement and assess pixel- and object-based classifiers on VHR imagery that were fused using different pan- sharpening techniques. Thus, the influence  of  fusion on the classification results was analyzed. The ultimate purpose was the development of a reliable processing methodology which, when applied to remote sensing imagery, serves to obtain accurate vegetation maps and information for the conservation of natural resources.Figure . Study area of Teide National Park (Canary Islands, Spain).
Specifically, a very complex shrubland ecosystem has been selected to perform the analysis.
The article is structured as follows: The 2nd section includes the study area and a description of the data sets, the image fusion methods, and the different classification techniques applied at pixel- and object-based levels. The analysis and evaluation of the different techniques, as well as the thematic maps obtained are presented in the 3rd section. Finally, the last section includes a critical analy- sis of the results and summarizes the main outcomes and contributions.
Material and methods
Study area and dataset
A heterogeneous ecosystem of The Canary Islands (28° 06j  N; 16° 33j  W) was selected for this study: the Teide National Park located on the island of Tenerife (Figure 1). The Teide National Park, created in 1954, is a protected area  with  18,990  hectares  (Martín-Osorio  et  al.  2005), located on the island of Tenerife. The Teide National Park area is a giant crater situated in the center of the island. Teide is made up by several overlapping volcanoes in the middle of the giant crater, making it the highest moun- tain in Spain (3,718 m; González-Lemus et al. 2009). As already mentioned, the vegetation is vulnerable to envi- ronmental changes. Thus, the plants respond to thermic and hydric stress, a characteristic of a mountain ecosys- tem  with  a  shrub  physiognomy  (Arozena-Concepción and Beltrán-Yanes 2006).
The following non-herbaceous vegetation species were selected for the study by the experts of the National Park, due to their abundance and importance at the ecological level: Spartocytisus supranubius (Teide broom), Ptero- cephalus lasiospermus (Rosalillo de cumbre), Descurainia bourgaeana (Hierba pajonera), and Pinus canariensis (Canarian pine; Figure 2). All  of  them  are addressed in this article as “vegetation classes.” Moreover, urban, road, and bare soil classes were also included in the classification.
The Teide broom (Spartocytisus supranubius; Bonet  et al. 2009) is  a  broom-like  shrub  reaching  a  height of 2 m–3 m, moreover it is a strong competitor and     its growth is a major factor  affecting  the  composi-  tion of plant species (Kyncl  et al. 2006). S. supranubius  is 1 of the most important plant species as is Ptero- cephalus lasiospermus (Rosalillo de cumbre) and Descura- nia bourgaeana (Hierba pajonera; Arozena-Concepción and Beltrán-Yanes 2006). P. lasiospermus is a small shrub characterized by pink flowers appearing in the spring and D. bourgaeana is a shrub that can be easily dis- tinguished by its semi-spherical shape and its flowers   of yellow petals. Another significant plant species is the Canary pine (Pinus canariensis), the only native pine in the archipelago, which is found in the northern area of the park. This species has a great resistance to fire and cold temperatures (Garzón-Machado et al. 2011; Otto et al. 2012; Wildpret de la Torre 2001). Other similar shrub- land ecosystems can be identified around the world, for example: Pico do Pico in the Azores, Mt. Halla in South Korea, and Hawaii or the Galapagos Islands, some areas
Figure . Vegetation ﬁeld campaign in the Teide National Park: (a) Spartocytisus supranubius; (b) Pterocephalus lasiospermus; (c) Descurainia bourgaeana; and (d) Pinus canariensis.
of Okanagan Desert in Canada. Thus, the importance of studying this ecosystem is its similarity to other Mediter- ranean, temperate or tropical parts of the world (Ruocco et al. 2014).
Worldview-2 (WV-2) orthoready imagery was used  in the study. The WV-2 satellite, launched by Digital- Globe on October 8, 2009, was the first commercial satel- lite to have a very high spatial resolution sensor with 1 panchromatic and8 multispectral bands. The Teide image was acquired on May 16, 2011, in the spring season as the vegetation species has greater spectral separability (González-Lemus et al. 2009; Wildpret de la Torre 2001).
Image corrections and enhancements
Numerous methodological problems are associated with the use of data from VHR sensors (Franklin and  Wulder 2002), thus, several image enhancements must be carried  out  in  order  to  reduce  these  problems  and to obtain high quality products which will allow      a comprehensive and useful analysis of the natural resources.
Pansharpening techniques
The first step was to generate a pixel-level fused image, with a high spatial and spectral quality, using a pansharp- ening process. The enhancement is important in this type of heterogeneous ecosystem due to the small size of some vegetation classes. After a comprehensive review of the state-of-art (Ibarrola-Ulzurrun et al. 2017), 7 pansharp- ening methods were applied (for detailed information see the references):
Gram-Schmidt (GS): A low-resolution PAN image is simulated and the GS transformation is performed on the simulated PAN plus the MS bands. Then, the original PAN replaces the first GS band and   the inverse transform is applied (Laben and Brower 2000).
Fast Intensity Hue Saturation (FIHS): It uses the spectral bands and the IHS transformation to esti- mate the new component I. The spatial detail is
extracted, computing the difference between the panchromatic band and I. Finally, it is injected into the multispectral bands (Marcello et al. 2013; Tu et al. 2001; Vivone et al. 2015).
Hyperspherical Color Sharpening (HCS): It is an algorithm specifically designed for the WV-2 sen- sor, based on the transformation between any native color space and the hyperspherical color space (Li et al. 2012, 2013; Padwick et al. 2010; Tu et al. 2012; Wu et al. 2015).
Based Modulation Transfer Function (MTF): The trendy implementations provided by Vivone et al. 2015	(http://openremotesensing.net/knowledgeba se/a-critical-comparison-among-pansharpening- algorithms/) of 2 different MTF fusion algorithms were used: the one based on Generalized Laplacian Pyramid (MTF_GLP; Aiazzi et al. 2002, 2006) and the Generalized Laplacian Pyramid plus a High Pass Modulation (MTF_GLP_HPM; Burt and Adelson 1983; Aiazzi et al. 2002, 2006; Amro et al. 2011).
Wavelet ‘à trous’ (WAVE_ATROUS): The fused images are obtained by adding the panchromatic wavelet planes to the multispectral image approx- imation (Amolins et al. 2007; Amro et al. 2011; Dutilleux et al. 1987; Gonzalo-Martín and Lillo- Saavedra 2008; Lillo-Saavedra and Gonzalo 2006; Marcello et al. 2013; Wald et al. 1997).
Weighted Wavelet ‘à trous’ method through Fractal Dimension Maps (WAT FRAC; Lillo-Saavedra and Gonzalo 2006): It is based on the wavelet ‘à trous’.A mechanism that controls the trade-off between the spatial and spectral quality by introducing a weight- ing factor for each band αi (x, y) for the panchro- matic wavelet coefficients is established and defined as Fractal Dimension Map with the same size as the original image (Lillo-Saavedra et al. 2011). These maps are generated for each of the source images with the box-counting algorithm and by applying a windowing process. Each element in these maps pro- vides a different weighting value for each pixel and each band.
Quality evaluation is a fundamental issue to bench- mark and optimize different pansharpening algorithms (Marcello et al. 2013; Rodríguez-Esparragón 2015; Wald 2000; Wang and Bovik 2002). A visual and quantitative assessment was undertaken in order to evaluate the pan- sharpening results in the different fused images. The qual- ity assessment was carried out for the whole set of bands. In the study, a number of statistical evaluation indices were used to measure the quality of the fused images at the spectral, spatial and global level (Alparone et al. 2008; Kpalma et al. 2014; Shridhar and Alvarinho 2013). The indices applied to measure the spectral quality of the fused images, which take the original multispectral bands as   a reference, were: Spectral Angle Mapper (Kruse et al. 1993; best value closer to 0) and Spectral ERGAS (Wald, 2000; best values closer to 0, but usually between 0–3). The spatial quality assesses the spatial detail injected and the panchromatic band was chosen as a reference. The indices considered were: Spatial ERGAS (Lillo-Saavedra et al. 2005; best values closer to 0, but usually between 0– 3); Frequency Comparison (Rodríguez-Esparragón et al. 2014; values between 0–1, best closer to 1); and Zhou Index (Zhou et al. 1998; values between 0–1, best closer to 1). Finally, at global level the Q8 index, which is a general- ization of the Q index, (Wang and Bovik 2002) and of the Q4 index (Alparone et al. 2004), with values between 0–1 (best closer to 1), was used to measure correlation, mean shifts, and radiometric distortion simultaneously (Mar- cello et al. 2013).
As the Teide ecosystem is very heterogeneous and com- posed by small shrubs, pansharpening will be very impor- tant to achieve reliable vegetation maps. Also, both qual- ities will be critical, the spatial to discriminate the small plants and the spectral to differentiate similar covers. As indicated in Thomas et al. (2008), the ideal fusion method does not exist yet, but the fused results generally corre- spond to a tradeoff between a good geometrical represen- tation of structures and a good representation of spectral information.
Orthorectification and atmospheric correction
After detailed assessment of different image and model- based atmospheric corrections algorithms using WV-2 imagery and field spectroradiometer data collected simul- taneously (Marcello et al. 2016), the FLAASH algorithm (Adler-Golden et al. 1999) achieved the best performance. The appropriate atmospheric parameters were adjusted (atmospheric model, aerosol model, aerosol optical thick- ness, adjacency, etc.) using climatologic information and field data and the average reflectance estimations achieved a Root Mean Square Error (RMSE) around 3% when compared to the in-situ measurements. Orthorectifica- tion, using the Rational Polymodal Coefficients model,
was carried out using ENVI 5.0 software (ENVI 2004) and the average RMSE after the orthorectification was 3.11 m for geodesic points located in the park.
Segmentation at object-based approach
The OBIA process starts with a segmentation of the input images into local groups of pixels (segments) that become spatial units in the later classifications and accu- racy assessment. The object shape, size and spectral prop- erties depend on both the segmentation approach and the research goals. The ideal purpose of the segmentation is to approximate meaningful landscape entities recogniz- able at a given image resolution (Dronova 2015). Image segmentation in eCognition is not a straightforward pro- cess and finding useful segmentation levels is an iterative process (Walsh et al. 2008). The most popular segmenta- tion carried out by eCognition users (Burnett et al. 2003; Dronova 2015; Lu and Weng 2007; Walsh et al. 2008) is Multiresolution Segmentation. It is regarded as a region- based algorithm, which starts by considering each pixel as a separate object. Subsequently, pairs of image seg- ments are merged to form bigger segments. The decision to merge is based on the homogeneity criterion, which measures how homogeneous or heterogeneous an image object is within itself. The derived image objects in eCog- nition are determined by the following parameters (Baatz et al. 2001):
Weight of image channels to assign different impor- tance to each image band.
Scale to determine the maximum heterogeneity of the objects allowed. Smaller scales increase the dimensionality and the division of the objects into the sub-groups, while larger scales combine the multi-segments into 1 (Marangoz et al. 2006).
Shape to adjust the homogeneity of the object generation.
Compactness to determine whether the objects will become more compact or smoother.
Once the Multiresolution Segmentation was performed, Spectral Difference algorithm was used to merge neighbor- ing image objects when the difference between their layers mean intensities are below the value given by the maxi- mum spectral difference (Baatz et al. 2001).
Classification models
Several classification techniques were applied in the study. The first step was to determine the classes appearing in the image and to obtain a set of training and testing samples. The size and representativeness of the set of the training samples are critical for image classification (Lu and Weng 2007). The second step was to determine the classification
Table . Pixel-based and object-based classiﬁcation algorithms and their parameters.
model to be used and which classifier apply in each model. An evaluation of the parameters chosen in each classi- fier was performed. However, these parameters are image dependent, and the user should analyze which parame- ters are more suitable for their images. The 2 classifica- tion approaches considered here were pixel-based, which was carried out using ENVI 5.0 image processing software (Exelis Visual Information Solutions, Inc., a subsidiary of Harris Corporation); and object-based using eCognition Developer (Trimble Geospatial). eCognition is optimized for the cost-effective OBIA classification of VHR imagery. The classification models selected for carrying out the pixel-based classification approach are Maximum
Likelihood, Mahalanobis Distance, and Support Vector Machine. Regarding the OBIA approach, Bayes, Near- est Neighbor, K-Nearest Neighbor, and Support Vector Machine were selected (Table 1). For choosing the classi- fiers’ parameters, different trials were performed and eval- uated until obtaining the most suitable parameter value for each classifier.
Thematic maps were obtained after applying the dif- ferent classification techniques using the same training samples. Afterwards, the accuracy of the classification was measured by using the testing samples collected.    In order to obtain a reliable thematic map, the training and testing samples were selected with the help of Teide
Figure . True color images of the Teide National Park: (a) original multispectral image; and fused imagery using: (b) GS; (c) FIHS; (d) HCS;
(e) MTF_GLP; (f ) MTF_GLP_HPM; (g) WAVE_ATROUS; and (h) WAT FRAC.
Figure . RGB color composite: (a) WAT FRAC fused image and (b) WAVE_ATROUS fused image; and thematic maps using: (c) Maxi- mum Likelihood in WAT FRAC fused image; (d) Mahalanobis Distance in WAVE_ATROUS fused image; and (e) Support Vector Machine in WAT FRAC fused image.
National Park experts from well-known sites around the park and using the ground truth samples obtained during the fieldwork carried out in the study area, which were used for the training and testing phases in the classifica- tion process. The method used for choosing the samples was a random method in which a total of 362,631 pixels (ca. 70% of the total samples) were chosen as training samples and 159,182 pixels (ca. 30% of the total samples) for the testing.
The statistical accuracy assessment technique used in the study was the standardized confusion Error Matrix which reports 2 measurements of accuracy: Overall Accuracy and Kappa coefficient (Congalton 1991). It is
more appropriate in difficult classification approaches, assuming that the map categories are mutually exclu- sive and exhaustive and that each location belongs to     a single category. On the other hand, the Kappa coeffi- cient is a measure of overall statistical agreement, which takes non-diagonal elements into account (Lu and Weng 2007).
Results and discussion
The following results are presented as: (i) analysis and evaluation of the fused images quality obtained through the different pansharpening techniques; (ii) accuracy of
Figure . Classiﬁcation overall accuracy in percentage (%) of each class and classiﬁer in the fused imagery. X axis: classes; Y axis: per- centage value.
the pixel-based thematic maps obtained for each fused image; and (iii) accuracy of the OBIA classification results obtained for each fused image.
Pansharpening results
In this section, a visual and a quantitative assessment of the fused images are presented. To facilitate the visual inspection and for a detailed spatial analysis, a zoom of the complete scene is shown in Figure 3.
The visual interpretation at the spectral level in the image indicates that every algorithm seems to correctly preserve the spectral information in the fused image.  Moreover, the differences are clearer spatially than spec- trally. For HCS and MTF-based techniques, although they maintain the spectral information well, the spatial details are not satisfactorily injected, thus not achieving a good spatial enhancement. This smoothed aspect appear- ing in the image is because the algorithm makes uni-  form the areas with a common texture. Thus, Dimen- sional Fractal Maps are calculated into the MS and the PAN image, giving information regarding roughness in the image areas. Then, a small amount of the spatial infor- mation is incorporated in homogeneous areas, maintain- ing a more homogeneous spectral response, closer to the original multispectral image, avoiding in this way, the ‘salt&pepper’ effect.
As it was mentioned, in order to carry out an objective evaluation of the pansharpening techniques,  6  qual-  ity indices were computed. The  results  are  presented in Table 2. Spectral Quality indices and  Q8  confirm that MTF methods provide better spectral performance while WAVE_ATROUS gets, in general, the lowest spec- tral quality, even though there is not great difference  between the highest and the lowest result. As regards  the spatial performance, WAVE_ATROUS is confirmed as the best spatial quality method. Furthermore, these
results confirm the trade-off between the spectral and spatial quality of pansharpening techniques. As next presented, WAT FRAC will be the most suitable tech- nique followed by WAVE_ATROUS, taking into account the balance between a good geometrical representa-  tion of structures and a good representation of spectral information (Thomas et al. 2008).
Pixel-based classification results
Before performing the classification process, the Jeffries- Matusita Distance algorithm was carried out in order to check the ROIs separability. This distance provides for most of the class pairs a value of higher than 1.8, indicat- ing a good separability for most of the ROIs.
Three supervised classification methods were applied to each fused image (Table 1). Table 3 shows the Overall Accuracy as well as the Kappa coefficient for each classi- fication technique applied to each fused image.
The best result for both Maximum Likelihood and Support Vector Machine classification is obtained in the WAT FRAC fused image, whereas the WAVE_ATROUS fused image obtains the best accuracy with Mahalanobis Distance classification. Every classifier performs a good classification, which is more significant both in Maximum Likelihood and Support Vector Machine, with Kappa coefficients of 0.76 and beyond. Furthermore, the Support Vector Machine achieves the highest accuracy with the WAT FRAC fused image. Finally, it is observed how the WAVE_ATROUS and WAT FRAC algorithms, which obtain higher values in the quantitative spatial indices (Table 2), improve the classification compared with the original multispectral image and the remaining pansharp- ening techniques. These results highlight the importance of the spatial information in the Teide National Park where vegetation species are mixed and are limited in size. In more detail, thematic maps for the best pansharp- ening algorithm are shown in Figure 4 for Maximum Likelihood, Mahalanobis Distance, and Support Vector
Machine.
According to Figure 4c, although the best Maximum Likelihood Classification obtains an Overall Accuracy of 89.12%, some misclassifications appear in this thematic map. For instance, some pixels which are classified as urban (red) appear in bare soil areas, as well as some  road pixels in areas of bare soil. Moreover, due to the field observations and information from the Teide man- agers, an excess of D. bourgaeana appears in the classified image (too many yellow pixels). In addition, S. supranu- bius must be less abundant around P. canariensis in the ecosystem (top left in the thematic map). For the best Mahalanobis Distance method, similar misclassified pix- els to those of the Maximum Likelihood Classification
Figure . Multiresolution segmentation and spectral diﬀerence segmentation results.
Table . Quality results for the complete WV- bands (best results in bold).
Table . Accuracy assessment of the pixel-based classiﬁcation algorithms for each fused image (the best results are in bold).
Figure . (a) WAT FRAC RGB color composite; and thematic maps: (b) Bayes; (c) Nearest Neighbor; (d) K-Nearest Neighbor; and (e) Support Vector Machine.
appear. Nevertheless, the abundance of pixels classified as
D. bourgaeana decreases compared with the Maximum Likelihood result while S. supranubius class increases in some areas where, according to expert opinion, it does not have to appear in these areas. Finally, the Support Vec- tor Machine thematic map achieves the highest Overall Accuracy (92.75%). Despite the improvement using the Support Vector Machine classifier, the computation time with it was significantly higher, more than 24 hours, than the other 2 classifiers, which took a few minutes in the same computer.
In order to identify the best methodology (pansharp- ening + classification model) to properly discriminate
the vegetation classes, Figure 5 displays the classifica- tion overall accuracy chart for each class in each pixel- based approach for the pansharpening algorithm achiev- ing the best performance. Observing the classes, it is noted that Maximum Likelihood classifier obtains higher val- ues in the different classes than other classifiers except for
P. lasiospermus and bare soil, even though the best Over- all Accuracy and Kappa coefficient is achieved by Sup- port Vector Machine classifier. This fact is important due to the aim of the study, which is to obtain the best plant species classification map. However, as it was mentioned, Figure 4c shows some misclassifications when using Max- imum Likelihood classifier.
Figure . Classiﬁcation overall accuracy in percentage (%) of each class and classiﬁer in the fused image. X axis: classes; Y axis: per- centage value.
Object-based classification results
Image segmentation
The image was segmented using the aforementioned Mul- tiresolution Segmentation technique to generate first, 8 dif- ferent object-oriented segmentations to select the most suitable Image Layer Weight and Scale parameters. The segmentation parameters were selected by a visual evalua- tion and applying a Support Vector Machine classification technique with the training and testing samples obtained in the field work. Both the Overall Accuracy and the Kappa coefficient were analyzed in order to evaluate the most suitable segmentation parameters. The greater the accuracy, the better the adjustment of the segmentation parameters with the image objects. Tables 4 and 5 details some of the Scale parameters and criterion combinations used, as well as the classification accuracy obtained in each segmentation. Test Number 8 shows the most suit- able segmentation for the Image Layer Weights and Scale parameters, which is revealed in the classification results. Figure 6 shows a zoom of the segmentation results, in which objects preserve small shrubs which are difficult to
delimitate.
OBIA classification
Once the objects are obtained from the segmentation techniques, classification algorithms can be applied. The classification algorithms analyzed and the parameters used are shown in Table 1.
Table 6 shows the Overall Accuracy and the Kappa coefficient for each object-based classification tech- nique applied to each fused image. By analyzing the table, every classifier obtains the best accuracy result in the WAT FRAC fused image. Overall Accuracy and Kappa coefficient values are similar to the pixel-based classification results (Table 3), with the Support Vector Machine classifier, once again, obtaining the best overall accuracy result. The table shows how the classification accuracy is, in general, improved in images fused with
algorithms that preserve the spatial and spectral quality (WAVE_ATROUS and WAT FRAC), compared  with the original multispectral image. The most accurate thematic maps of each classifier are shown in Figure 7.
Figure 7 shows the WAT FRAC fused image  and each classification map using Bayes, Nearest Neighbor, K- Nearest Neighbor, and Support Vector Machine. In the case of the Bayes classifier some objects which are clas- sified as urban areas appear as bare soil areas and road objects in areas of bare soil, like the Maximum Likelihood Classification in the pixel-based approach. In the Near- est Neighbor classification, the misclassifications obtained in the Bayes classifier are resolved, observing a more accurate thematic map at first sight, as well as K-Nearest Neighbor classifier, which shows a similar thematic map. Finally, the Support Vector Machine map is similar to the previous ones.
Figure 8 summarizes the classification overall accuracy, in percentage, of each class and for each OBIA classifica- tion approach applied to the WAT FRAC fused image. Bayes provides a high percentage of accuracy, obtain- ing the highest results for most of the vegetation classes. While the Nearest Neighbor, the vegetation classes have a lower percentage of accuracy, achieving the lowest for S. supranubius. Regarding the K-Nearest Neighbor classifier, it achieves a high degree of accuracy for P. lasiospermus, which is a significant class of interest for the ecosystem management of this region. On the other hand, the mis- classifications obtained in the other 3 types of vegetation improved with respect to the Nearest Neighbor classifica- tion. Support Vector Machine, even though achieving the highest Overall Accuracy and Kappa coefficient (Table 6), these results do not appear in the ones obtained in the classification accuracy of each class (Figure 8).
It is important to note the good results obtained using the WAT FRAC algorithm in both pixel-based and object-based approaches. Although the best overall accu- racy is obtained by the Support Vector Machine in both cases, not only the computation times for the pixel-based approach are much higher that for the OBIA approach but Maximum Likelihood Classification and Bayes clas- sifier obtain higher accuracies for the majority of vegeta- tion classes of interest. However, as it was mentioned, the visual assessment obtained with Maximum Likelihood classification does not fully correspond with the experts’ opinion. This leads to the Bayes classification, at OBIA approach, applied to the WAT FRAC fused image being the most suitable classifier in order to obtain fast and accurate thematic maps of these difficult heterogeneous shrub-land ecosystems. Even though it does not achieve the highest overall accuracy (Table 6), it is closer to the Support Vector Machine classifier but obtaining higher classification accuracies for each class.
Figure . Zoom of the thematic maps obtained by the SVM classiﬁer applied at pixel-based approach in: (a) Original multispectral image and (b) WAT FRAC fused image; and at OBIA approach in: (c) Original multispectral image and (d) WAT FRAC fused image.
Table . Accuracy assessment of Image Layer Weight (Worldview- bands), and scale segmentation parameters (best result appears in bold).
Table . Accuracy assessment of compactness and shape segmentation parameter using the Image Weight Layer:and with a Scale:  (best result appears in bold).
Table . Accuracy assessment of the object-based classiﬁcation algorithms for each fused and segmented (Multiresolution Segmentation and Spectral Diﬀerence) image (the best results are in bold).
Table . Computation times (minutes) of the diﬀerent classiﬁers in pixel based (using ENVI) and in OBIA (using eCognition) approaches.
Table 7 shows the computation times of each classifier in both approaches, using a computer with Windows 10 of 64 bits, Intel§R   CoreTM  i7-490 CPU @ 360 GHz with 32.0 GB of RAM. Note that the computation times of OBIA classifiers were significantly lower than the ones using the pixel-based approach, especially the Support Vector Machine, which took hours to obtain the classi- fication maps in the pixel-based approach.
In order to visually assess how the pansharpening pro- cess improves the result in the thematic maps, a final figure (Figure 9) shows zooms of the thematic maps obtained using both Support Vector Machine algorithm on the original multispectral and the WAT FRAC fused images in both pixel and OBIA approaches. We have decided to show Support Vector Machine results because it obtained the most suitable classification in the pixel- based approach and, thus, it is possible to compare the same classification result using the same classifier in the 2 different approaches (pixel- and object-based). The importance of pansharpening is observed as some classes
of interest are not well labeled in the original multispec- tral thematic maps (Figure 9a). On the other hand, build- ings are erroneously classified as bare soil in the original multispectral image and road limits are stepped due to the pixel size in the original image. Moreover, the poor qual- ity of the classification is appreciated when applying OBIA to the Multispectral image, however, when it is applied to the fused image, the contours of the covers are smoother and it reduces the salt and pepper effect.
Conclusions
The main objective of the presented work was to study the pansharpening influence on obtaining accurate thematic maps, applying pixel-based and OBIA classification tech- niques on VHR imagery from a complex and heteroge- neous ecosystem. Thus, 7 different pansharpening tech- niques  (GS,  FIHS,  HCS, MTF_GLP,  MTF_GLP_HPM,
WAVE_ATROUS, and WAT FRAC) were applied to achieve the highest spatial resolution of the multispectral
bands while preserving its original spectral information. Several classification algorithms were next applied at the pixel-based level (Maximum Likelihood Classification, Mahalanobis Distance, and Support Vector Machine) and at the object-based level (Bayes, Nearest Neighbor, K- Nearest Neighbor, and Support Vector Machine).
First, visual and quantitative quality assessment of the 7 pansharpening techniques was performed. A good compromise between the spatial and spectral quality is  a requirement of the study. This compromise is noted after analyzing the results from the 6 quality metrics.  MTF methods achieve the best spectral performance, while WAVE_ATROUS achieves the best spatial qual- ity. WAT FRAC provides a suitable balance between the geometrical representation of structures and representa- tion of original spectral information.
Next, detailed accuracy results were performed for the classified maps. We conclude the importance of the pan- sharpening step in ecosystems with small and mixed vege- tation, where the spatial information is critical and should be well incorporated in order to generate accurate the- matic maps. It  is important to highlight the difficulty   in classifying some types of vegetation due to the com- plexity of this heterogeneous shrubland ecosystem with small vegetation species such as D. bourgaeana. Hence, the major impact on the mapping of different types of vegetation is the misclassification created within the plant species, due to their spectral similarity  and  the  mix- ing contributions from different covers in some pixels. Thus, it is important to create a reliable training sample database, which allows an accurate supervised classifica- tion to be made. As mentioned, experts from the Teide National Park helped to obtain the ground truth samples used for training and testing. This assumption leads us back to the importance of obtaining a fused image with a high spatial quality that allows us to differentiate some species from others, avoiding pixel misclassification but also preserving the original spectral information.
In both classification approaches, the WAT FRAC fused image achieves the best thematic map with every classification method except for Mahalanobis Distance using the pixel-based approach. The highest Overall Accuracy is obtained by the Support Vector Machine, applied to the WAT FRAC fused image for both  approaches, having similar results with Maximum Like- lihood in the pixel-based approach and with Bayes in the OBIA approach. Moreover, Maximum Likelihood, as well as Bayes, obtained the highest accuracies for most vege- tation classes, even though the visual results in the Max- imum Likelihood classification are not fully satisfactory. In addition, the computation time of the Support Vector Machine is higher than other classifiers, being consider- ably high in the pixel-based approach. Thus, we conclude
that Bayes classifier applied in an object-based approach is the most suitable algorithm for this ecosystem area.
Despite the accurate classification results obtained, some limitations for both studied approaches have to  be mentioned. In the case of the pixel approach, the main limitation is the presence of mixed pixels located in boundaries between classes. Moreover, the quantity of data to be processed is higher than in the OBIA approach, in which objects are processed instead  of  pixels.  On the other hand, in the OBIA approach there is a high dependency on the segmentation parameters, which are specific for each image. There is no global protocol for setting the segmentation parameters and the user must analyze which segmentation parameters are more suitable depending on the image.
In conclusion, after an extensive testing of pansharp- ening and classification algorithms, we have obtained a methodology that provides a good performance in these heterogeneous regions with small and mixed shrubs, obtaining challenging thematic maps of land-protected areas for studying the state of conservation of natural resources.
Future research will include ancillary data, such as Lidar and SAR imagery, as  well  as  specific  vegeta-  tion indices and texture parameters in the classification approach in order to obtain more accurate thematic maps not only in shrubland ecosystems, but also in coastal and shallow water natural areas. This methodology could be applied not only to Teide National Park ecosystem but to other similar ecosystems around the world.
Acknowledgments
We wish to acknowledge the Teide National Park conserva- tion managers (Jose Luis Martín Esquivel and Manuel Marrero Gómez) for defining the classes of interest and examining the results obtained, and Ángel Garcia-Pedrero for his implemen- tation of the HCS code.
